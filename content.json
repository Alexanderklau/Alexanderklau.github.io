{"meta":{"title":"Yemilice","subtitle":null,"description":null,"author":"Yemilice lau","url":"https://yemilice.com"},"pages":[{"title":"","date":"2019-11-06T02:28:37.885Z","updated":"2019-11-06T02:28:37.461Z","comments":true,"path":"baidu_verify_kjucdQVPYU.html","permalink":"https://yemilice.com/baidu_verify_kjucdQVPYU.html","excerpt":"","text":"kjucdQVPYU"},{"title":"","date":"2019-10-28T05:11:59.061Z","updated":"2019-10-28T05:11:59.061Z","comments":true,"path":"google9c12e62c3231610a.html","permalink":"https://yemilice.com/google9c12e62c3231610a.html","excerpt":"","text":"google-site-verification: google9c12e62c3231610a.html"},{"title":"关于我","date":"2020-04-14T11:23:29.000Z","updated":"2020-04-14T11:47:54.774Z","comments":true,"path":"about/index.html","permalink":"https://yemilice.com/about/index.html","excerpt":"","text":"没什么优点，一个写代码的说唱歌手。 其实细细对比一下，写代码和玩说唱的开始的时间都差不多，都开始于2014年 那时候我还是个大二学生，哈哈，找到第一份兼职，那个夏天我不会忘记，蜗居在租来的小房子里，一台二手苹果电脑，风扇带着潮湿的味道，空气中，弥漫着回不去的美好。 人生如逆旅，我亦是行人。 2016顺利毕业，回到北京，无休止的加班，熬夜，加班，压力伴随着成长，16年，我得到很多，也失去很多。 玩音乐的年份可就久啦 小时候拿起的第一把吉它 弹奏的第一首钢琴曲 出师未捷身先死的小提琴 哈哈，一切都像是在昨天一样 2016年我写了自己的第一首说唱Demo，正式开始说唱之路，参加过八英里，参加过Diss，哈哈，是非成败转头空。 2020年，我将写出自己的第一首单曲。 我啊，依旧在不断的向前走，如果你看到了博客，说明你我很幸运能认识，感恩你来过，也感恩你的离开。 2020-04-13"},{"title":"分类","date":"2020-04-14T11:16:58.000Z","updated":"2020-04-14T11:17:49.391Z","comments":true,"path":"categories/index.html","permalink":"https://yemilice.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2019-10-28T05:12:54.658Z","updated":"2019-10-28T05:11:59.061Z","comments":true,"path":"images/google9c12e62c3231610a.html","permalink":"https://yemilice.com/images/google9c12e62c3231610a.html","excerpt":"","text":"google-site-verification: google9c12e62c3231610a.html"},{"title":"tags","date":"2020-04-14T11:21:09.000Z","updated":"2020-04-14T11:21:09.945Z","comments":true,"path":"tags/index.html","permalink":"https://yemilice.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Golang封装Elasticsearch常用功能","slug":"Golang封装Elasticsearch常用功能","date":"2020-05-14T01:45:49.000Z","updated":"2020-05-14T01:50:26.323Z","comments":true,"path":"2020/05/14/Golang封装Elasticsearch常用功能/","link":"","permalink":"https://yemilice.com/2020/05/14/Golang%E5%B0%81%E8%A3%85Elasticsearch%E5%B8%B8%E7%94%A8%E5%8A%9F%E8%83%BD/","excerpt":"","text":"前言（为什么要写这篇文章）首先看过我博客的都应该知道，我去年发了一篇Python封装Elasticsearch的文章。但那是去年了，今年我将我的检索服务后端用Golang全部重写了一波，相当于用Go重构了以前的Python代码，不过我个人感觉Golang的效率还是高于Python的，而且我还加了一些异常判断和处理，这次的代码只会比以前更好更牛逼，为了纪念这一个多月的重构历程，我将关键功能记录下来，方便自己复习和各位兄弟姐妹查看。 使用的Go包我的Elasticsearch版本是6.3.2，6系列了，现在（2020-05-13）最新版本应该是7，不过新版本和旧版本应该就是少了Type，我的6版本代码，请各位自己自行斟酌使用。安装指定的Go包 olivere/elastic，现在有官方驱动的包了，但是我这篇文章用的包是 olivere/elastic，所以一切的代码都是以olivere为主。 1go get github.com/olivere/elastic 基础的使用（Simple的使用）接下来我举几个例子来说下这个golang 如何驱动 elasticsearch的 连接Elasticserach1234567891011121314151617181920212223package elasticdbimport ( \"context\" \"fmt\" \"github.com/olivere/elastic\")func main() &#123; //连接127.0.0.1 client, err := elastic.NewClient(elastic.SetURL(\"http://127.0.0.1:9200\")) if err != nil &#123; fmt.Println(err) return &#125; //检查健康的状况，ping指定ip，不通报错 _, _, err = client.Ping(ip).Do(context.Background()) if err != nil &#123; fmt.Println(err) return &#125;&#125; 创建一个index索引这里我默认你们都有一定的Es基础，其实你把index想成Mysql里面的表就可以了。 123456789//indexname 你可以想成表名func CreateIndex(indexname string) &#123; client, err := elastic.NewClient(elastic.SetURL(\"http://127.0.0.1:9200\")) if err != nil &#123; fmt.Println(err) return &#125; client.CreateIndex(indexname).Do(context.Background())&#125; 删除一个index索引想成删除一张表 123456789//indexname 你可以想成表名func CreateIndex(indexname string) &#123; client, err := elastic.NewClient(elastic.SetURL(\"http://127.0.0.1:9200\")) if err != nil &#123; fmt.Println(err) return &#125; client.DeleteIndex(indexname).Do(context.Background())&#125; 往指定的index当中导一条数据想成往一张表里面导入一条数据，在Golang中，我们可以导入json的字符串，我们也可以导入golang的struct类型，例如 1234567//结构体type Task struct &#123; Taskid string `json:\"taskid\"` Taskname string `json:\"taskname\"`&#125;//字符串jsonmsg := `&#123;\"taskid\":\"123456\", \"taskname\":\"lwb\"&#125;` 1234567891011121314151617181920212223//导入数据，你需要index名，index的type，导入的数据func PutData(index string, typ string, bodyJSON interface&#123;&#125;) bool &#123; client, _ := elastic.NewClient(elastic.SetURL(\"http://127.0.0.1:9200\")) _, err := client.Index(). Index(index). Type(typ). BodyJson(bodyJSON). Do(context.Background()) if err != nil &#123; //验证是否导入成功 fmt.Sprintf(\"&lt;Put&gt; some error occurred when put. err:%s\", err.Error()) return false &#125; return true&#125;func main() &#123; //json字符串导入 jsonmsg = `&#123;\"taskid\":\"123456\", \"taskname\":\"hahah\"&#125;` status := PutData(\"test\", \"doc\", jsonmsg) //struct结构体导入 task := Task&#123;Taskid: \"123\", Taskname: \"hahah\"&#125; status := PutData(\"test\", \"doc\", task)&#125; 删除一条数据删除数据需要ID，这个ID是个啥玩意儿呢。。。就是咱们不是刚导了一条数据进去么，你可以设置这数据的唯一ID，也可以让Elasticsearch帮你自动生成一个，一般没事儿干谁自己设置啊，还容易重复，一重复就报错。。我在这里把这个删除的方法教给大家，记住这个ID一定是唯一的 12345678func DeleteData(index, typ, id string) &#123; client, _ := elastic.NewClient(elastic.SetURL(\"http://127.0.0.1:9200\")) _, err := client.Delete().Index(index).Type(typ).Id(id).Do(context.Background()) if err != nil &#123; fmt.Println(err) return &#125;&#125; 高阶使用（条件查询／封装等）简单讲了一下增删改，现在我们来讲一下高阶用法，高级增删改查吧，其实官方的文档讲的还算是比较清楚，不过我等大中华程序狗的姿势水平。。。至少我是图样图森破，看英文也算是废了九牛二虎之力，算是捋出来了一些高阶用法，顺手自己造了个轮子，现在我就来挑几点来说下吧。 自动选择可用的Es节点配合olivere的ping机制，可以做一个自动检测Es ip 是否可用的逻辑，这样可以增加我们put，updatge时候的稳定性 自动检测节点Elasticseach的IP是否可用olivere的Elasticserach sdk 限定了只能用一个ip，类似“http://127.0.0.1:9200”这样，我对原本的逻辑进行了一点改造，改成支持一个ip list，依次检测Es ip 是否可用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package elasticdbimport ( \"context\" \"fmt\" \"github.com/olivere/elastic\")//Elastic es的连接，type Elastic struct &#123; Client *elastic.Client host string&#125;//Connect 基础的连接代码func Connect(ip string) (*Elastic, error) &#123; //引入IP client, err := elastic.NewClient(elastic.SetURL(ip)) if err != nil &#123; return nil, err &#125; //Ping 的方式检查是否可用 _, _, err = client.Ping(ip).Do(context.Background()) if err != nil &#123; return nil, err &#125; //输出一个struct类型，可以被继承 es := &amp;Elastic&#123; Client: client, host: ip, &#125; return es, nil&#125;//InitES 初始化Es连接func InitES() (*Elastic, error) &#123; //host是一个列表 host := []string&#123;\"http://10.0.6.245:9200\",\"http://10.0.6.246:9200\",\"http://10.0.6.247:9200\"&#125; //统计host的数量 Eslistsnum := len(host) //如果为零就不继续接下来的逻辑 if Eslistsnum == 0 &#123; return nil, fmt.Errorf(\"Cluster Not Es Node\") &#125; //创建新的连接 for i, ip := range host &#123; //判断是不是最后一个节点ip if (Eslistsnum - 1) != i &#123; es, err := Connect(ip) //如果连接出错，则跳过 if err != nil &#123; fmt.Println(err) continue &#125; return es, nil //如果是最后一个节点 &#125; else &#123; es, err := Connect(ip) //输出错误 if err != nil &#123; return nil, err &#125; return es, nil &#125; &#125; return nil, nil&#125; 后续我们可以采用继承的方法调用Es的client的连接，这个在后面我就不详细说了，聪明的你，看代码一定能整明白，再整不明白，你就直接上Git拷贝我的代码就得了。 条件查询以前我写过一个Python的Elasticsearch Sdk，那里面的查询基本都用了query，简单来说，就是你，给Es的api发一个query，es给你返回一个查询结果。这里我会举几个常用的条件查询例子，然后用golang封装一波。这里我先定义一下数据结构，假设我们的Elasticsearch中，有一个叫做Task的index(索引)，其中存储着很多task的运行日志，它们的数据格式如下: 12345678&#123; \"taskid\": \"081c255b-936c-11ea-8001-000000000000\", \"starttime\": \"2020/05/13 18:38:21\", \"endtime\": \"2020/05/13 18:38:47\", \"name\": \"cifs01\", \"status\": 1, \"count\": 365&#125; 我们现在要做的就是围绕task这个index和其中的数据做条件查找的例子，我说的很明白了吧？开工了！ 查询时间范围/年龄大小的条件查询方法在业务需求中，我们经常会检索各种各样的数据，其中，范围查找应该是用的比较多的，所以我把它放到了最前面。 12345678910111213141516171819202122type Task struct &#123; TaskID string `json:\"taskid\"` StartTime string `json:\"starttime\"` EndTime string `json:\"endtime\"` Name string `json:\"name\"` Status int `json:\"status\"` Count int `json:\"count\"`&#125;//查找时间范围大于2020/05/13 18:38:21，并且小于2020/05/14 18:38:21的数据func (Es *Elastic) FindTime() &#123; var typ Task boolQ := elastic.NewBoolQuery() //生成查询语句，筛选starttime字段，查找大于2020/05/13 18:38:21，并且小于2020/05/14 18:38:21的数据 boolQ.Filter(elastic.NewRangeQuery(\"starttime\").Gte(\"2020/05/13 18:38:21\"), elastic.NewRangeQuery(\"starttime\").Lte(\"2020/05/14 18:38:21\")) res, _ := Es.Client.Search(\"task\").Type(\"doc\").Query(boolQ).Do(context.Background()) //从搜索结果中取数据的方法 for _, item := range res.Each(reflect.TypeOf(typ)) &#123; if t, ok := item.(Task); ok &#123; fmt.Println(t) &#125; &#125;&#125; 查询包含关键字的查询方法我们经常遇到那种，搜那么一两个字，让你展示所有包含这一两个字的结果，就像百度，你搜个”开发”，就能搜出来例如”软件开发”,”硬件开发”等。接下来咱们也实现一个这个功能 1234567891011121314//查找包含\"cifs\"的所有数据func (Es *Elastic) FindKeyword() &#123; //因为不确定cifs如何出现，可能是cifs01，也可能是01cifs，所以采用这种方法 keyword := \"cifs\" keys := fmt.Sprintf(\"name:*%s*\", keyword) boolQ.Filter(elastic.NewQueryStringQuery(keys)) res, _ := Es.Client.Search(\"task\").Type(\"doc\").Query(boolQ).Do(context.Background()) //从搜索结果中取数据的方法 for _, item := range res.Each(reflect.TypeOf(typ)) &#123; if t, ok := item.(Task); ok &#123; fmt.Println(t) &#125; &#125;&#125; 多条件查询如果说我们现在不仅仅需要找到符合时间的，也需要找到符合关键字的查询，那么就需要在查询条件上做文章。 12345678910111213func (Es *Elastic) FindAll() &#123; //因为不确定cifs如何出现，可能是cifs01，也可能是01cifs，所以采用这种方法 keyword := \"cifs\" keys := fmt.Sprintf(\"name:*%s*\", keyword) boolQ.Filter(elastic.NewRangeQuery(\"starttime\").Gte(\"2020/05/13 18:38:21\"), elastic.NewRangeQuery(\"starttime\").Lte(\"2020/05/14 18:38:21\"), elastic.NewQueryStringQuery(keys)) res, err := Es.Client.Search(\"task\").Type(\"doc\").Query(boolQ).Do(context.Background()) //从搜索结果中取数据的方法 for _, item := range res.Each(reflect.TypeOf(typ)) &#123; if t, ok := item.(Task); ok &#123; fmt.Println(t) &#125; &#125;&#125; 统计数量/多条件统计数量有些时候我们需要去统计符合查询条件的结果数量，做统计用，这里也有直接可用的Sdk 12345678910func (Es *Elastic) GetTaskLogCount() (int, error) &#123; boolQ := elastic.NewBoolQuery() boolQ.Filter(elastic.NewRangeQuery(\"starttime\").Gte(\"2020/05/13 18:38:21\"), elastic.NewRangeQuery(\"starttime\").Lte(\"2020/05/14 18:38:21\")) //统计count count, err := Es.Client.Count(\"task\").Type(\"doc\").Query(boolQ).Do(context.Background()) if err != nil &#123; return 0, nil &#125; return int(count), nil&#125; 总结我这边完成了几个查询/导入的基础功能，当然，我的代码大部分都放置在了github当中放置在: https://github.com/Alexanderklau/Go_poject/tree/master/Go-Elasticdb/Elasticsearch_sdk最近项目比较忙，我打算月中写一篇我开发的时候使用的一些Go特性，或者高级用法。如果喜欢的话麻烦Star我！最近压力颇大，想要换一个地方生活，所以也要准备离开了。如果大家有什么问题，可以直接给我提问，我看到了就会帮助大家的。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"这次绩效考评会成为压垮我的稻草么？","slug":"这次绩效考评会成为压垮我的稻草么？","date":"2020-04-14T02:06:30.000Z","updated":"2020-04-14T02:07:17.819Z","comments":true,"path":"2020/04/14/这次绩效考评会成为压垮我的稻草么？/","link":"","permalink":"https://yemilice.com/2020/04/14/%E8%BF%99%E6%AC%A1%E7%BB%A9%E6%95%88%E8%80%83%E8%AF%84%E4%BC%9A%E6%88%90%E4%B8%BA%E5%8E%8B%E5%9E%AE%E6%88%91%E7%9A%84%E7%A8%BB%E8%8D%89%E4%B9%88%EF%BC%9F/","excerpt":"","text":"写这篇文章的原因按理说，你们看过我博客的人，都知道，我是一个相当乐观的人，我从来都不会怎么丧气一些事儿，特别是在工作上，我永远都是顶在最前面，有困难bug我来，有难题我来攻关，按理说我就像是一个长者，身经百战，见的多了！那些naive的问题，我都不放在心上，可今天，恩，一个绩效考评，算是让我有了一些感到心累或者说是心寒吧。 发生了什么事儿说起来也是很尴尬，大家都知道，因为疫情，我整个二月和三月都在家办公，我那电脑没带回家，我用我家旧电脑和我舅舅的电脑，算是拼了个单片机，没图形界面那种，这是前提啊！本来我这边在开发一个比较大的项目，这项目，怎么说呢，用许嵩那句话就是 “作词作曲都是我自己”，咱不说别的，从策划，到架构涉及包括一些有的没的，都是我一个人搞定，那家伙，就差说我是CTO了哈哈，再一个，我作为整个项目组排头兵，第一个吃螃蟹涉足Golang开发，从一无所有，到文档齐备，就用了1月底，到2月底，这一个月时间，在家开发，日夜不眠不休，真正996，头发都给我掉了多少哈啊哈。这转折来了嘿，3月初，我有天正干活儿呢，你们知道，那开发机，一个人分好几台，我在我那几台开发机上正挥汗如雨呢，结果突然黑屏了，那一瞬间，我还傻x的拍了一下我电脑的后盖，我一寻思，不对啊，这不是电视，黑屏那就得是出事儿！果不其然，我把记录一发群里，才知道原来测试那边儿，有人在清理集群！一不小心把开发集群给清了！我勒个大擦！我寻思你这是灭霸啊，人灭霸打个响指，害得摆个造型。你这不声不响的，按个enter，就给我一个多月努力干没了，你可真是现代爆破专家啊你。这TM叫删库，你丫想跑路了吧！ 我当时的想法我当时脑子里先是一片空白，然后我脑子里一直弥漫着老八那句话，奥莉给！干他就完事儿了！是，我当时那个气啊，我就想给他丫干了，X的，小爷不说别的，以前也算是胡同口拍黑砖第一人啊！然后我的老大，紧急发来微信，问，你备份了吗？我说，没，那集群20多台机器呢，我在其中几台配了定时同步。我老大说，完了。我知道，我被删库了。 删库的损失不说别的，项目代码损失是最大的，2w行代码，一个月不眠不休的成果，完蛋了，等于这个月白干，是呗，是我倒霉么？人一倒霉，喝凉水都塞牙，给我气的。同时丢失的，还有Elasticsearch的work脚本，优化过后的ETCD封装代码，大部分文档，编译机的环境和包。 为什么不备份？首先开发集群有20多台机器，其中我的机器就用将近8台，8台机器啊老铁们，你会想到它们一瞬间都被干死么？好吧，我承认，我那个黑不溜秋的单片机linux只能处理一些逻辑问题，30G硬盘，安个Golang，python，jre都够呛了，害得跑个带gopls的Vim，备份？我这不寻思我过两天回去了备份么！ 绩效的定义写这个原因是，今儿（2020-4-13），考评下来，我老大找我谈话，说这次考评给了我C。也就是我绩效考核，3月份是C。我当时就疑惑了，删库的第一不是我，第二我不眠不休写的东西被人删了，我TM才是受害者！it‘s me！你给受害者考勤打C？我的项目都进测试部分了，你把开发机测试机一起干死了，当中是有我没备份的原因，但是你直接给我打C？？？我一打听，删库的人也是C，我勒个去，你这什么意思，删库的人和我都是C的评级？？那你是真的牛皮，感情我被删库我还成C了是吧！那你要追究责任，怎么不追究运维，为什么他会给删库的人那么大权限？让我背锅也太无耻了吧！ 结尾这次我感觉我有点寒心，是真的，我平常都写技术，很少写这种令人难过的玩意儿，但是我今天真的感觉心很累，也很寒心。看起来总是要人背锅，也就只有我了呗。呵呵。晚安了啊，如果哪位技术大佬或者是HR看到这篇文章，请不要误会，这只是我对这件事的一种寒心，我还是会继续输出高质量文章的。over","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"}],"keywords":[]},{"title":"Golang调用Rabbitmq消息队列和封装","slug":"Golang调用Rabbitmq消息队列和封装","date":"2020-04-13T02:11:00.000Z","updated":"2020-04-13T02:19:34.927Z","comments":true,"path":"2020/04/13/Golang调用Rabbitmq消息队列和封装/","link":"","permalink":"https://yemilice.com/2020/04/13/Golang%E8%B0%83%E7%94%A8Rabbitmq%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%92%8C%E5%B0%81%E8%A3%85/","excerpt":"","text":"前言介绍RabbimqRabbitmq消息队列是干嘛的？简单的说，消息队列，引申一下就是传递消息用的队列，也可以称为传递消息的通信方法。用争抢订单的快车举个例子，假如，A用户发送了一个用车的消息，那么消息队列要做的就是把A用户用车的这个消息广而告之，发送到一个公用队列当中，司机只管取到消息，而不管是谁发布的，这就是一个简单的消息队列例子，Rabbitmq其实就是消息队列的一种，用的比较多的还可能有Redis，kafka，ActiceMq等等，这个后面的博文里面我会说，这次我们只说Rabbimq消息队列 Rabbitmq消息队列的好处是什么？为什么我们要用他？这个网上有很多类似的玩意，我不说太多，就只说我在使用中感觉比较好的地方。 分布式，多节点部署。一个集群，保证消息的持久化和高可用，某节点挂了，其他节点可以结力。 路由Exchange，这个已经提供了内部的几种实现方法，可以指定路由，也就是指定传递的地址。 多语言支持，我以前干活儿用Python，现在用Go和java，人家无缝对接，多牛逼！ Ack的消息确认机制，这样就保证了，任务下发时候的稳定性，ack消息确认可以手动，也可以自动，这样就保证了任务下发时候的可控和监控。 初步开始简单的生产者和消费者的模型讲那么多废话理论，还不如直接开始写代码更直观是吧，所以，奥莉给，干了兄弟们！我们实现一个简答的生产者，消费者模型。这个不用我多解释吧，基础的流程就是，我们定义一个生产者，生产信息到Rabbitmq中，然后再定义一个消费者，把数据从Rabbitmq中取出来，就这么简单，下面咱们就干了，先讲几个基础。 Rabbitmq的基础知识发送 Publish发送，你可以理解为上传，意思就是，上传一个消息到Rabbitmq当中。它这块的基础代码比较简单 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( \"log\" \"github.com/streadway/amqp\")func main() &#123; //初始化一个Rabbimtq连接，后跟ip，user，password conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") if err != nil &#123; return &#125; defer conn.Close() //创建一个channel的套接字连接 ch, _ := conn.Channel() //创建一个指定的队列 q, _ := ch.QueueDeclare( \"work\", // 队列名 false, // durable false, // 不使用删除？ false, // exclusive false, // 不必等待 nil, // arguments ) //定义上传的消息 body := \"work message\" //调用Publish上传消息1到指定的work队列当中 err = ch.Publish( \"\", // exchange \"work\", // 队列名 false, // mandatory false, // immediate amqp.Publishing &#123; ContentType: \"text/plain\", //[]byte化body Body: []byte(body), &#125;)&#125; 这样就完成了上传消息到work队列当中。 接收 Consume接收，顾名思义，就是接收到指定队列中的信息，信息存在队列当中，总要被拿出来用吧，放那里又不能下崽儿，所以，拿出来感觉用了才是最重要的。这块的基础代码如下 1234567891011121314151617181920212223242526272829303132333435363738package mainimport ( \"log\" \"github.com/streadway/amqp\")func main() &#123; //初始化一个Rabbimtq连接，后跟ip，user，password conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") if err != nil &#123; return &#125; defer conn.Close() //创建一个channel的套接字连接 ch, _ := conn.Channel() msgs, err := ch.Consume( \"work\" // 队列名 \"\", // consumer true, // auto-ack false, // exclusive false, // no-local false, // 不等待 nil, // args ) //定义一个forever，让他驻留在后台，等待消息，来了就消费 forever := make(chan bool) //执行一个go func 完成任务消费 go func() &#123; for d := range msgs &#123; //打印body log.Printf(\"message %s\", d.Body) &#125; &#125;() &lt;-forever&#125; 生产者／消费者模型上面简单说了一下rabbimq的发送和接收，这下咱们就要实现一个生产者消费者模型了，这个模型的主要逻辑，就是生产者发送任务到指定的队列，有一个，或者多个消费者，会在此留守，一有任务，就争抢并且消费。 生产者逻辑其实生产者逻辑和上面的发送逻辑差不多，这里给出写法。 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( \"log\" \"github.com/streadway/amqp\")func main() &#123; //初始化一个Rabbimtq连接，后跟ip，user，password conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") if err != nil &#123; return &#125; defer conn.Close() //创建一个channel的套接字连接 ch, _ := conn.Channel() //创建一个指定的队列 q, _ := ch.QueueDeclare( \"work\", // 队列名 false, // durable false, // 不使用删除？ false, // exclusive false, // 不必等待 nil, // arguments ) //定义上传的消息 body := \"work message\" //调用Publish上传消息1到指定的work队列当中 err = ch.Publish( \"\", // exchange \"work\", // 队列名 false, // mandatory false, // immediate amqp.Publishing &#123; ContentType: \"text/plain\", //[]byte化body Body: []byte(body), &#125;)&#125; 消费者逻辑消费者逻辑这边，主要是加了一个qos控制和手动ack，代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package mainimport ( \"log\" \"github.com/streadway/amqp\")func main() &#123; //初始化一个Rabbimtq连接，后跟ip，user，password conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") if err != nil &#123; return &#125; defer conn.Close() //创建一个channel的套接字连接 ch, _ := conn.Channel() //创建一个qos控制 err = ch.Qos( 3, // 同时最大消费数量（意思就是最多能消费几个任务） 0, // prefetch size false, // 全局设定？ ) if err != nil &#123; return err &#125; msgs, err := ch.Consume( \"work\" // 队列名 \"\", // consumer true, // auto-ack false, // exclusive false, // no-local false, // 不等待 nil, // args ) //定义一个forever，让他驻留在后台，等待消息，来了就消费 forever := make(chan bool) //执行一个go func 完成任务消费 go func() &#123; for d := range msgs &#123; //打印body log.Printf(\"message %s\", string(d.Body)) //手动ack，不管是否发送完毕。 d.Ack(false) &#125; &#125;() &lt;-forever&#125; Golang封装Rabbitmq的基础接口Rabbitmq会用了吧，上面那个估计比较简单，但是估摸着你们还想要别的功能，好，那我就惯大家一次，干了兄弟们，奥莉给！ 初始化Rabbitmq连接为了避免每次重复调用Rabbitmq连接，我这里提供一个简单写法。 1234567891011121314151617181920212223242526package mainimport (\"context\"\"fmt\"\"github.com/streadway/amqp\")//Rabbitmq 初始化rabbitmq连接type Rabbitmq struct &#123; conn *amqp.Connection err error&#125;func New(ip string) (*Rabbitmq, error) &#123; amqps := fmt.Sprintf(\"amqp://guest:guest@%s:5672/\", ip) conn, err := amqp.Dial(amqps) if err != nil &#123; return nil, err &#125; rabbitmq := &amp;Rabbitmq&#123; conn: conn, &#125; return rabbitmq, nil&#125; 创建一个Queue队列12345678910111213141516171819func (rabbitmq *Rabbitmq) CreateQueue(id string) error &#123; ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return err &#125; _, err = ch.QueueDeclare( id, // name true, // durable false, // delete when unused false, // exclusive false, // no-wait nil, // arguments ) if err != nil &#123; return err &#125; return nil&#125; 上传消息到指定的queue中123456789101112131415161718192021func (rabbitmq *Rabbitmq) PublishQueue(id string, body string) error &#123; ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return err &#125; err = ch.Publish( \"\", // exchange id, // routing key false, // mandatory false, amqp.Publishing&#123; DeliveryMode: amqp.Persistent, ContentType: \"text/plain\", Body: []byte(body), &#125;) if err != nil &#123; return err &#125; return nil&#125; 从队列中取出消息并且消费123456789101112131415161718192021func (rabbitmq *Rabbitmq) PublishQueue(id string, body string) error &#123; ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return err &#125; err = ch.Publish( \"\", // exchange id, // routing key false, // mandatory false, amqp.Publishing&#123; DeliveryMode: amqp.Persistent, ContentType: \"text/plain\", Body: []byte(body), &#125;) if err != nil &#123; return err &#125; return nil&#125; 统计队列中预备消费的数据12345678910111213func (rabbitmq *Rabbitmq) GetReadyCount(id string) (int, error) &#123; count := 0 ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return count, err &#125; state, err := ch.QueueInspect(id) if err != nil &#123; return count, err &#125; return state.Messages, nil &#125; 统计消费者／正在消费的数据12345678910111213func (rabbitmq *Rabbitmq) GetConsumCount(id string) (int, error) &#123; count := 0 ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return count, err &#125; state, err := ch.QueueInspect(id) if err != nil &#123; return count, err &#125; return state.Consumers, nil&#125; 清理队列123456789101112func (rabbitmq *Rabbitmq) ClearQueue(id string) (string, error) &#123; ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return \"\", err &#125; _, err = ch.QueuePurge(id, false) if err != nil &#123; return \"\", err &#125; return \"Clear queue success\", nil&#125; 总结简单讲了一下Rabbimtq是啥，怎么用，我是怎么用的。完整代码请访问我的Github： https://github.com/Alexanderklau/Go_poject/blob/master/Go-Rabbitmq/rabbitmq.go如果有不懂的欢迎留言！如果能帮大家的我一定会帮！也希望你们指出我的错误！一起进步！","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang 完成一个 Crontab定时器（2）","slug":"Golang-完成一个-Crontab定时器（2）","date":"2020-03-23T01:14:40.000Z","updated":"2020-03-23T01:15:19.158Z","comments":true,"path":"2020/03/23/Golang-完成一个-Crontab定时器（2）/","link":"","permalink":"https://yemilice.com/2020/03/23/Golang-%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AA-Crontab%E5%AE%9A%E6%97%B6%E5%99%A8%EF%BC%882%EF%BC%89/","excerpt":"","text":"前言上篇文章，大概讲了一下robfig/cron 包的使用，怎么开始一个定时任务，那个东西比较简单，也就是调用函数而已，人家都给你把包都封装好了。鉴于上一章我没提到cron相关，这一章专门我写个cron相关，讲讲怎么cron语法，然后再实现一个自动生成cron语句的逻辑。 需求分析 cron的基础科普 根据时间自动生成可用的cron语句 Cron表达式的基础Go的Cron和linux的Cron的区别就是，linux只到分钟，但是Go的Cron可以通过我上一节描述的代码设置精确到秒。所以一般的Cron表达式就是 1* * * * * * command 可以看出来，这是一个时间集合，但是其中每个 * 代表什么含义呢？下面给出Golang的cron设置表 字段 需要的值 字符表示 秒 0-59 * / , - 分 0-59 * / , - 时 0-23 * / , - 日 1-31 * / , - 月 1-12 * / , - 星期 0-6 * / , - 下面举几个cron的具体例子每秒执行一次任务 1* * * * * * Command 每分钟执行一次任务 1* *／1 * * * * Command 每天12点执行一次任务 1* 0 12 * * * Command 每个月1号12点执行一次任务 1* 0 12 1 * * Command 2月14号12点执行一次任务（执行一次） 10 0 12 14 2 * Command 每周二12点执行一次任务 1* 0 12 * * 1 Command Golang 实现一个Cron表达式自动生成器Cron这个东西，其实没那么难，但是你每次让我们徒手撸，还是会有点烦，特别是现在网上基本没有在线自动生成Cron语法的网站了，所以我们还是站撸一个Cron自动生成器，首先咱们要明确一个重要东西,任务可能是循环的，也可能是只执行一次的，看到了么，这下我们就要针对不同的任务类型，输出不同的任务表达式。 规定输入的时间格式首先输入的时间有多种多样，我们没办法控制输入的时间表达，所以我在这里先行规定，我的代码也是按照这个规定来的，前提在此。 循环执行的任务对于循环执行的任务，可能有每月，每周，每日，每时等等，所以我在这里举例 每月3号12点执行 1m,03,12:00 每周三的12点执行 1w,3,12:00 每天的12点执行 1d,12:00 观察一下，聪明的你应该知道我要做什么，拿每天循环执行来举例 12345timelists := strings.Split(times, \",\")hours := strings.Split(timelists[1], \":\")[0]minutes := strings.Split(timelists[1], \":\")[1]crontab := fmt.Sprintf(\"* %s %s * * *\", minutes, hours)fmt.Println(crontab) 结合其他部分 1234567891011121314151617181920212223timelists := strings.Split(times, \",\")// 在这里判断类型，天，月，周if timelists[0] == \"d\" &#123; hours := strings.Split(timelists[1], \":\")[0] minutes := strings.Split(timelists[1], \":\")[1] crontab := fmt.Sprintf(\"* %s %s * * *\", minutes, hours) return crontab&#125; else if timelists[0] == \"w\" &#123; days := strings.Split(timelists[1], \",\")[0] hours := strings.Split(strings.Split(timelists[2], \",\")[0], \":\")[0] minutes := strings.Split(strings.Split(timelists[2], \",\")[0], \":\")[1] crontab := fmt.Sprintf(\"* %s %s * * %s\", minutes, hours, days) return crontab&#125; else if timelists[0] == \"m\" &#123; days := strings.Split(timelists[1], \",\")[0] hours := strings.Split(strings.Split(timelists[2], \",\")[0], \":\")[0] minutes := strings.Split(strings.Split(timelists[2], \",\")[0], \":\")[1] crontab := fmt.Sprintf(\"* %s %s %s * *\", minutes, hours, days) return crontab&#125; else &#123; crontab := \"* * * * * *\" return crontab&#125; 执行一发看看,生成个每月的cron表达式 1* 0 12 03 * * Command 诶，怎么多了个03。。。看起来咱们需要格式化一下，把它转换一下成可用的。 1234567891011121314func FkZero(times string) (fmttime string) &#123; // 如果第一个值不为0，直接认为是正常的 if string(times[0]) != \"0\" &#123; return times // 判断00的情况 &#125; else if strings.Split(times, \"0\")[1] == \"\" &#123; fkzero := \"0\" return fkzero // 清理03，为 3 &#125; else &#123; fkzero := strings.Split(times, \"0\")[1] return fkzero &#125;&#125; 执行一次的任务执行一次的任务表达方式 2020-03-20 12:00处理代码如下 12345678timelists := strings.Split(times, \" \")[0]month := strings.Split(timelists, \"-\")[1]day := strings.Split(timelists, \"-\")[2]timework := strings.Split(times, \" \")[1]hours := strings.Split(timework, \":\")[0]minutes := strings.Split(timework, \":\")[1]crontab := fmt.Sprintf(\"0 %s %s %s %s *\", minutes, hours, day, month)return crontab 总结其实这个代码主要就是一个strings的split切分，但是涉及到了crontab语言的输出，其实没那么难，也就是麻烦，我把它传到github上了，有需要可以自己get下来。https://github.com/Alexanderklau/Go_poject/tree/master/Go-Script/crontab","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang 完成一个 Crontab定时器（1）","slug":"Golang-完成一个-Crontab定时器（1）","date":"2020-03-23T01:12:36.000Z","updated":"2020-03-23T01:13:34.795Z","comments":true,"path":"2020/03/23/Golang-完成一个-Crontab定时器（1）/","link":"","permalink":"https://yemilice.com/2020/03/23/Golang-%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AA-Crontab%E5%AE%9A%E6%97%B6%E5%99%A8%EF%BC%881%EF%BC%89/","excerpt":"","text":"前言Linux的Crontab定时器似乎已经足够强大，但是我认为还是没有办法满足我们所有的需求，例如定时器某一瞬间需要动态添加／删除任务的功能，例如定时器只能在指定的节点上启动（主节点），其他节点不需要定时服务，这种情况Linux自带的Crontab就不能够满足我们的需求了，所以这次要徒手定义一个Crontab定时器，作为自己的备用。 需求分析看我博客的基本也都知道，做任何事，都要进行一个需求分析。既然是一个定时器，那么应该支持的功能如下 定时启动任务（废话） 支持基础的Crontab语法 支持将时间转换为Crontab语法 支持Crontab语法校验 记录日志的功能 支持crontab任务到秒级 综合上面的需求，不难看出，其实最重要的功能就是实现一个定时启动任务的玩意儿，在Go开发当中，也就是在某个时间点执行某个Go函数。说的简单点，就是，定时跑Go函数。也就是定时go func而已。 robfig/cron 包的使用安装robfig/cron包我这里默认你们都有go 基础,先安装个包，这玩意儿是驱动Golang 驱动 Crontab的重要框架。 1go get github.com/robfig/cron robfig/cron的使用举例启动一个定时任务其实很简单 123job := cron.New()job.AddFunc(\"* * * * *\", func() &#123;fmt.Println(\"Start job....\")&#125;)job.Start() 一个定时任务就这样被写好了，其实仔细琢磨一下，添加任务的方式就是 123456// 新任务job := cron.New()///任务添加job.AddFunc(\"Cronta 语句\", func() &#123;执行函数（）&#125;)//任务开始job.Start() 这样就完成了一个定时任务的添加 支持crontab任务到秒级估计你们看到这里一脸懵逼，为啥你个单独到秒级的也要整出来呢？其实我也表示，我也不想啊！奈何一点，robfig/cron这玩意有个很奇葩的一点，它只支持的分钟级别的任务，不支持到秒级别！！！！，它只支持的分钟级别的任务，不支持到秒级别！！！！，它只支持的分钟级别的任务，不支持到秒级别！！！！，重要的事儿说三遍！这里需要你自己定义秒级别的任务，在翻了一下它的test源码之后，拉到最底下，看到这么一行代码。 1234// newWithSeconds returns a Cron with the seconds field enabled.func newWithSeconds() *Cron &#123; return New(WithParser(secondParser), WithChain())&#125; 这行代码啥意思呢，意思就是启用返回seconds字段的任务，说白了就是，你要加这个，才能开启秒级别的任务网上好多博客写的，都是你抄我，我抄你，抄来抄去，没一个代码能用的，大家如果发现抄网上那帮人的代码，跑不起来，那绝对就是这个原因！人家只支持到分钟，网上给出的例子全都是秒级别的，并且没打开秒级别任务定义，还能跑起来？我都怀疑你们怎么写的代码。定义秒级别任务代码这段代码主要的意思就是，开放到秒级别的任务支持，看到了second么，这段代码在源码包的test下有，你们可以自己去看看。 1234567891011121314151617181920func newWithSeconds() *cron.Cron &#123; secondParser := cron.NewParser(cron.Second | cron.Minute | cron.Hour | cron.Dom | cron.Month | cron.DowOptional | cron.Descriptor) return cron.New(cron.WithParser(secondParser), cron.WithChain())&#125;func main() &#123; // 使用秒级别任务 job := newWithSeconds() // 任务定义,3s输出一个j1 start job,不停循环 job.AddFunc(\"0/3 * * * * ? \", func() &#123; fmt.Println(\"j1 start job....\", time.Now().Format(\"2020-03-20 15:04:05\")) &#125;) // 任务定义，每分钟的第三秒执行任务 job.AddFunc(\"3 * * * * ? \", func() &#123; fmt.Println(\"j2 start job....\", time.Now().Format(\"2020-03-20 15:04:05\")) &#125;) //开始任务 job.Start() select &#123;&#125;&#125; 输出的结果 1234j1 start job.... 2020-03-21 17:09:36j1 start job.... 2020-03-21 17:09:39j1 start job.... 2020-03-21 17:09:42j1 start job.... 2020-03-21 17:09:45 总结初步完成了crontab的基础功能，这篇文章默认，你们都比较懂crontab语法和go开发了，如果不懂就请期待下一篇，实现crontab语法自动生成和自动加载任务吧。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang利用context实现一个任务并发框架","slug":"Golang利用context实现一个任务并发框架","date":"2020-03-20T07:57:48.000Z","updated":"2020-03-20T08:52:52.514Z","comments":true,"path":"2020/03/20/Golang利用context实现一个任务并发框架/","link":"","permalink":"https://yemilice.com/2020/03/20/Golang%E5%88%A9%E7%94%A8context%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E4%BB%BB%E5%8A%A1%E5%B9%B6%E5%8F%91%E6%A1%86%E6%9E%B6/","excerpt":"","text":"Golang利用context实现一个任务并发框架消失这么久的原因疫情太严重，哥们本来打算在新疆滑雪+吃烤肉度过一个美好的假期，结果没成想给困那里了，这不就尴尬了么，这不，博客没更新，现在我又回来了，哈哈哈哈！ 我要实现个什么玩意儿有一个需求，简单的说就是我要写一个任务管理框架，主要功能有任务开启，任务关闭，任务监控等等。说的抽象点，就是我要用Golang写一个任务管理的功能，任务很可能有多个，并且我想停任务就停任务，想开始任务我就开始任务！我不要你觉得，我要我觉得！ 为什么我要用Golang众所周知，golang这东西，有个黑科技，叫goroutine，这东西很牛逼，牛逼在哪儿呢？简单的说，快，小，短！协程切换快，占用资源少，并且，异步的，可以开多个，直接一个go 关键字就给人家打开了，多棒！ 实际需求分析结合我们上面的任务需求，实现一个任务开始，任务停止的逻辑，这就说明，任务肯定不只有一个，并且任务都在后台，我们该怎么去监控，或者去管理这个go任务，或者go函数呢，golang提供了很多解决办法，例如WaitGroup，context等方法。思考一下，我们的这个需求，任务都是跑在后台的异步并发逻辑，这就说明不只一个任务会被启动和停止，这样对我们的任务管理是一个很大的挑战，因为任务都是在后台隐秘执行的，如果是一般逻辑，我们要停止任务，首先要找到任务的pid，然后kill任务进程，这是一个完整的结束任务的流程。回到我们这个需求，基本的流程就是： 发送一个任务请求(开启任务/停止任务) -&gt; 接收到任务请求 -&gt; 执行任务请求 思考一下，如果，我们开启任务之后，任务进入后台，那么，我们在停止任务的时候，怎么保证，能够找到这个任务，精准的打击（停止）它呢？看了题目你应该就知道了，用context就好了。下面我就来介绍一下它吧。 主角context介绍网上很多博客介绍它，我粗粗看了一眼，非常抽象，很多人再一描述，就更麻烦更抽象了。我这里不说的太麻烦，简单描述一下，这个东西context，是干嘛呢，你们理解一下株连，连坐这两个词汇，这个东西相当于就是锁链，铁锁连舟，不进则退，说明白点，就是一个串连上下文的类似信号传递的玩意儿。每个调用链上的函数都要以它作为函数进行传递，举个例子,”株九族”这个词，是因为一个人犯罪，结果家人都因为他被砍了头，这个犯罪的人，就是父context，其他因为他被杀的人，就是子context，还可能有孙context，他被砍头了，其他人也得跟着一起死，用代码表示一波 12345678910111213141516171819202122232425262728// 这是儿子函数func gen(ctx context.Context) &lt;-chan int &#123; dst := make(chan int) n := 1 go func() &#123; for &#123; select &#123; // 接收到爹挂了的消息 case &lt;-ctx.Done(): fmt.Println(\"儿子被砍头了。\") // 退出任务 return case dst &lt;- n: n++ time.Sleep(time.Second * 1) &#125; &#125; &#125;() return dst&#125;// 这是爹函数fun test() &#123; ctx, cancel := context.WithCancel(context.Background()) // 让我造个儿子，给我儿子传个ctx intChan := gen(ctx) // 我被干了，cancel是结束 defer Cancel()&#125; 这下说的明白了么？其实context还有很多别的，例如timeout之类的，但是那个是我后面准备写的，这一节就不写这些了。 实现我们的需求我们的武器context已经准备好了，大概的使用逻辑我们也明白了，现在你们可以看到，我们只要拿到主函数（爹函数）的ctx和cancel，我们就可以控制子函数（儿子函数）的死活，我们在开发当中，任务的状态是不断在变化的，一个爹对应一个儿子，但是可能有多个任务，多个任务我们该怎么管理它？在一般的开发任务中，我们习惯将任务记录到数据库当中，然后在开发当中不停的遍历数据库，去判断任务的状态到底是开启还是停止，这里我们要考虑到，频繁遍历数据库，会不会带来大量的访问堆积？还是否有别的解决办法？ 我的解决方案这次开发中，我选择定义一个全局变量的主map，并且定义一个任务的struct类型，代码如下 123456789// 全局mapvar jobmap = make(map[string]interface&#123;&#125;)//Job 任务type Jobs struct &#123; ID string Status int Ctx context.Context Cancel context.CancelFunc&#125; 然后我选择在任务开始的时候（创造儿子的时候），将信息填充，修改test代码如下 123456789101112131415161718192021func test() &#123; var jobs Jobs ctx, cancel := context.WithCancel(context.Background()) // 造一个儿子 intChan := gen(ctx) // 任务开始了 fmt.Println(\"start job\") // 重要的东西传进去 jobs.Status = 1 jobs.Cancel = cancel jobs.Ctx = ctx // 定义一个任务id，这个可以用uuid，或者随便整个别的 jobs.ID = \"sdads\" m1[\"sdads\"] = jobs // 阻塞任务，假装任务执行很久 for n := range intChan &#123; fmt.Println(n) if n == 1000 &#123; break &#125; &#125; 再然后，我选择写一个停止函数（砍头函数） 123456789func stopGetmi(id string) &#123; //把任务停掉 fmt.Println(\"stop jobs\") jobss := m1[id] //interface 转 struct op, ok := jobss.(Jobs) // 调用砍头函数cancel defer op.Cancel()&#125; 进行测试 12345func main() &#123; go test() go stopGetmi(\"sdads\") time.Sleep(time.Second * 200)&#125; 发现任务执行结果这样你就完成了干掉老爹，也干掉儿子的素质操作。 总结主要是context的基础和说明，其实context我还是推荐大家去看看原版，我这里写的太过于简单，不过这篇博客，也是我记录一下自己开发中遇到的难题，当时看网上没有类似的说明，于是写了这篇博客，希望大家多多包涵。祝大家都能躲过瘟疫，我们终究会在春花花开的地方相见。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"ETCD分布式锁实现选主机制(Golang)","slug":"ETCD分布式锁实现选主机制-Golang","date":"2019-12-13T07:41:04.000Z","updated":"2019-12-13T07:44:02.059Z","comments":true,"path":"2019/12/13/ETCD分布式锁实现选主机制-Golang/","link":"","permalink":"https://yemilice.com/2019/12/13/ETCD%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0%E9%80%89%E4%B8%BB%E6%9C%BA%E5%88%B6-Golang/","excerpt":"","text":"ETCD分布式锁实现选主机制(Golang)为什么要写这篇文章做架构的时候，涉及到系统的一个功能，有一个服务必须在指定的节点执行，并且需要有个节点来做任务分发，想了半天，那就搞个主节点做这事呗，所以就有了这篇文章的诞生，我把踩的坑和收获记录下来，方便未来查看和各位兄弟们参考。 选主机制是什么举个例子，分布式系统内，好几台机器，总得分个三六九等，发号施令的时候总得有个带头大哥站出来，告诉其他小弟我们今天要干嘛干嘛之类的，这个大哥就是master节点，master节点一般都是做信息处理分发，或者重要服务运行之类的。所以，选主机制就是，选一个master出来，这个master可用，并且可以顺利发消息给其他小弟，其他小弟也认为你是master，就可以了。 ETCD的分布式锁是什么首先认为一点，它是唯一的，全局的，一个key值为什么一定要强调这个唯一和全局呢，因为分布式锁就是指定只能让一个客户端访问这个key值，其他的没法访问，这样才能保证它的唯一性。再一个，认为分布式锁是一个限时的，会过期的的key值你创建了一个key，要保证访问它的客户端时刻online，类似一个“心跳”的机制，如果持有锁的客户端崩溃了，那么key值在过期后会被删除，其他的客户端也可以继续抢key，继续接力，实现高可用。 选主机制怎么设计其实主要的逻辑前面都说清楚了，我在这里叙述下我该怎么做。我们假设有三个节点，node1,node2,node3 三个节点都去创建一个全局的唯一key /dev/lock 谁先创建成功谁就是master主节点 其他节点持续待命继续获取，主节点继续续租key值（key值会过期） 持有key的节点down机，key值过期被删，其他节点创key成功，继续接力。ETCD分布式锁简单实现看一下ETCD的golang代码，还是给出了如何去实现一个分布式锁，这个比较简单，我先写一个简单的Demo说下几个接口的功能 创建锁123456789kv = clientv3.NewKV(client)txn = kv.Txn(context.TODO())txn.If(clientv3.Compare(clientv3.CreateRevision(\"/dev/lock\"),\"=\",0)).Then(clientv3.OpPut(\"/dev/lock\",\"占用\",clientv3.WithLease(leaseId))).Else(clientv3.OpGet(\"/dev/lock\"))txnResponse,err = txn.Commit()if err !=nil&#123; fmt.Println(err) return &#125; 判断是否抢到锁12345if txnResponse.Succeeded &#123; fmt.Println(\"抢到锁了\") &#125; else &#123; fmt.Println(\"没抢到锁\",txnResponse.Responses[0].GetResponseRange().Kvs[0].Value) &#125; 续租逻辑1234567891011for &#123; select &#123; case leaseKeepAliveResponse = &lt;-leaseKeepAliveChan: if leaseKeepAliveResponse != nil&#123; fmt.Println(\"续租成功,leaseID :\",leaseKeepAliveResponse.ID) &#125;else &#123; fmt.Println(\"续租失败\") &#125; &#125; time.Sleep(time.Second*1) &#125; 我的实现逻辑首先我的逻辑就是，大家一起抢，谁抢到谁就一直续，要是不续了就另外的老哥上，能者居之嘛！我上一下我的实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116package mainimport ( \"fmt\" \"context\" \"time\" //\"reflect\" \"go.etcd.io/etcd/clientv3\")var ( lease clientv3.Lease ctx context.Context cancelFunc context.CancelFunc leaseId clientv3.LeaseID leaseGrantResponse *clientv3.LeaseGrantResponse leaseKeepAliveChan &lt;-chan *clientv3.LeaseKeepAliveResponse leaseKeepAliveResponse *clientv3.LeaseKeepAliveResponse txn clientv3.Txn txnResponse *clientv3.TxnResponse kv clientv3.KV)type ETCD struct &#123; client *clientv3.Client cfg clientv3.Config err error&#125;// 创建ETCD连接服务func New(endpoints ...string) (*ETCD, error) &#123; cfg := clientv3.Config&#123; Endpoints: endpoints, DialTimeout: time.Second * 5, &#125; client, err := clientv3.New(cfg) if err != nil &#123; fmt.Println(\"连接ETCD失败\") return nil, err &#125; etcd := &amp;ETCD&#123; cfg: cfg, client: client, &#125; fmt.Println(\"连接ETCD成功\") return etcd, nil&#125;// 抢锁逻辑func (etcd *ETCD) Newleases_lock(ip string) (error) &#123; lease := clientv3.NewLease(etcd.client) leaseGrantResponse, err := lease.Grant(context.TODO(), 5) if err != nil &#123; fmt.Println(err) return err &#125; leaseId := leaseGrantResponse.ID ctx, cancelFunc := context.WithCancel(context.TODO()) defer cancelFunc() defer lease.Revoke(context.TODO(), leaseId) leaseKeepAliveChan, err := lease.KeepAlive(ctx, leaseId) if err != nil &#123; fmt.Println(err) return err &#125; // 初始化锁 kv := clientv3.NewKV(etcd.client) txn := kv.Txn(context.TODO()) txn.If(clientv3.Compare(clientv3.CreateRevision(\"/dev/lock\"), \"=\", 0)).Then( clientv3.OpPut(\"/dev/lock\", ip, clientv3.WithLease(leaseId))).Else( clientv3.OpGet(\"/dev/lock\")) txnResponse, err := txn.Commit() if err != nil &#123; fmt.Println(err) return err &#125; // 判断是否抢锁成功 if txnResponse.Succeeded &#123; fmt.Println(\"抢到锁了\") fmt.Println(\"选定主节点\", ip) // 续租节点 for &#123; select &#123; case leaseKeepAliveResponse = &lt;-leaseKeepAliveChan: if leaseKeepAliveResponse != nil &#123; fmt.Println(\"续租成功,leaseID :\", leaseKeepAliveResponse.ID) &#125; else &#123; fmt.Println(\"续租失败\") &#125; &#125; &#125; &#125; else &#123; // 继续回头去抢，不停请求 fmt.Println(\"没抢到锁\", txnResponse.Responses[0].GetResponseRange().Kvs[0].Value) fmt.Println(\"继续抢\") time.Sleep(time.Second * 1) &#125; return nil&#125;func main()&#123; // 连接ETCD etcd, err := New(\"xxxxxxxx:2379\") if err != nil &#123; fmt.Println(err) &#125; // 设定无限循环 for &#123; etcd.Newleases_lock(\"node1\") &#125;&#125; 总结相关代码写入到github当中，其中的地址是https://github.com/Alexanderklau/Go_poject/tree/master/Go-Etcd/lock_work实现这个功能废了不少功夫，好久没写go了，自己太菜了，如果有老哥发现问题请联系我，好改正。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"算法笔记-入门-数据结构篇","slug":"算法笔记-入门-数据结构篇","date":"2019-11-13T03:26:18.000Z","updated":"2019-12-13T08:04:45.414Z","comments":true,"path":"2019/11/13/算法笔记-入门-数据结构篇/","link":"","permalink":"https://yemilice.com/2019/11/13/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AF%87/","excerpt":"","text":"算法笔记-入门-数据结构篇从大学毕业之后就没研究过算法，都快忘光了，现在开个新坑，从头学起算法，哈哈，希望自己能够坚持住，不过我一定可以坚持住的，我就像易筋洗髓一样，将自己全身打断，重塑自己的一切，回归初心，以一个听者的名义对待一切，因为我做的都是我自己喜欢的事儿。 基本的数据结构类型什么是数据结构说白了很简单，数据存计算机里，总得有个存放规律，不能乱来，就像你查字典，你可以一页一页翻着找字儿，你也可以直接按拼音跳转找字儿，这就是查字典的数据结构，数据结构就是决定数据顺序和位置的关系。 数据结构的子类-链表链表，这玩意儿理解起来会抽象一些，大学课本上表示它的数据是一个线性排列的，要我说不用这么麻烦，链表其实就是一列火车，举例来说，现在有4节车厢，你必须通过一节车厢才能到下一节去，也就是说，车厢（链表）都有一个指示牌（指针），你必须一个个往下，到达下面的车厢（指向下一个地址）。链表这玩意儿吧，慢，查东西你得一个个往下，添加，删除数据都先要改变指针。查一个东西，拿大O表示法，它的复杂度是O(n)，算是相当慢的一种算法了。 数据结构的子类-数组数组，也是线性排列的数据结构，还记得链表么，链表是靠指针指向，告诉你我下一个老哥是谁，但是数组不一样，它是靠一个叫数组下标的东西来告诉你，我是第几个，在Python中，这玩意儿被运用在列表里，就像a = [1,2,3,4,5] 这种形式，a[0] = 1, a[1] = 2…….其实你想查一个数组里面的东西，一般都是随机访问，可以直接去访问数组下标，这东西就相当于你吃饭取的号儿，到你了，人家就喊“XXX号用餐了！”数组下标就这个功能。数组里面，你要添加或者删除一个元素，那可有点麻烦，你要先在数组尾部，加一个多的存储空间，总不可能让新元素没地方去吧，然后你要让旧元素给新朋友腾个位置，然后把旧朋友往后面赶，然后新朋友才能顺利插队。。。 数据结构的子类-栈栈这位老哥会理解麻烦一点，这么想，你随时随地都能吃到最新鲜的水果，每天都有新的水果，你总能拿到新水果，旧水果就只有在下面，所以你如果想吃旧水果，你就要把水果箱子一点点拿出来，被称为出栈，把水果放回去，叫进栈，这个东西就是你只能拿最新的，后进先出，LIFO结构，这玩意儿还是挺不方便的。不过在业务中，如果你需要时刻保持最新数据在前面，例如，时事热点，附近的人等等，拿这玩意儿就好用多了。 数据结构的子类-队列和上面的栈老哥相反，队列的意思就是，你先进来的啊，你边儿待着，该需要的时候要我旧数据先上，拿数据从最老的数据拿，新数据一边玩去。想拿新数据？不好意思，一个个出来吧你，直到该你出去为止。 数据结构的子类-哈希表这个在这说有点那啥，但是啊，你们写过Python的应该知到，Python里面有个dict（字典），字典这玩意儿就是一个key 对应 一个value，例如 1234&#123; &quot;蔡徐坤&quot; ：&quot;篮球&quot;， &quot;吴亦凡&quot; ：&quot;说唱&quot;&#125; 这就实现了一个字典，你会问，这和TM哈希表有啥关系，哈希表这玩意儿，是存dict的东西，它是个类数组的东西，但是存的东西很变态，一般我们会用hash函数，计算”蔡徐坤”的键,也就是”蔡徐坤”的哈希值，然后我们将得到的哈希值除以数组长度（哈希表长）取余数，计算出”蔡徐坤”在数组中的位置，然后把它放进去。这里比较抽象，后面会专门讲一下哈希这个算法。那么怎么查呢，首先我们拿到”蔡徐坤”的哈希值，然后通过刚才的计算就能找到”蔡徐坤”在哈希表中的位置了。 数据结构的子类-堆重头戏来了，这玩意儿是一个树形结构，树形，顾名思义，是分叉的，想象一下，一棵树的样子，这玩意儿是拿来搞优先队列用的，堆里面有个老大，叫结点，所有的数据都是结点的小弟，受他罩着，其中他有多个手下，叫子结点，子结点一般比父结点大，最小的值一般都在堆的顶点。堆中最顶端的数据始终最小，所以无论数据量有多少，取出最小值的时间复杂度都 为 O(1)。另外，因为取出数据后需要将最后的数据移到最顶端，然后一边比较它与子结点数据 的大小，一边往下移动，所以取出数据需要的运行时间和树的高度成正比。假设数据量为 n，根据堆的形状特点可知树的高度为 log2n ，那么重构树的时间复杂度便为 O(logn)。添加数据也一样。在堆的最后添加数据后，数据会一边比较它与父结点数据的大 小，一边往上移动，直到满足堆的条件为止，所以添加数据需要的运行时间与树的高度 成正比，也是 O(logn） 数据结构的子类-二叉查找树和楼上那位一样，也是个树形结构，不一样的是，二叉树每个结点的值大于左子树上任意一个结点的值，比较抽象对吧，来看个图意思就是，无论怎么样，左边老哥总会比我小。第二个分歧就是，右边老哥总比我大，继续看图这就是一部分基础，做了粗略写作，写得不好，见谅，over！","categories":[],"tags":[{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"},{"name":"算法","slug":"算法","permalink":"https://yemilice.com/tags/%E7%AE%97%E6%B3%95/"}],"keywords":[]},{"title":"Python高效率遍历文件夹寻找重复文件","slug":"Python高效率遍历文件夹寻找重复文件","date":"2019-10-28T04:31:15.000Z","updated":"2019-10-28T04:59:05.962Z","comments":true,"path":"2019/10/28/Python高效率遍历文件夹寻找重复文件/","link":"","permalink":"https://yemilice.com/2019/10/28/Python%E9%AB%98%E6%95%88%E7%8E%87%E9%81%8D%E5%8E%86%E6%96%87%E4%BB%B6%E5%A4%B9%E5%AF%BB%E6%89%BE%E9%87%8D%E5%A4%8D%E6%96%87%E4%BB%B6/","excerpt":"","text":"前言为什么要写这篇文章呢。。。主要还是业务中有个需求，遍历一个将近200w数据的文件夹，大部分还都是视频文件那种，但是这玩意用的次数还不多，做文件夹index也不是很ok，所以写了一个脚本来处理这个问题，从而发现了自己的一些薄弱点，将其记录下来，方便自己，也方便未来其他的兄弟使用 基本需求 把文件夹中的重复文件找出来 找出来之后用csv输出，左边是源文件，右边是重复文件 效率不能差，不能直接撑爆内存，不能占用过多资源 检测的文件夹和存放csv的地方可以自己定义，加上终端交互 重复文件筛选支持md5，大小等方式需求分析首先要分析一点，就是我们该如何去做重复文件的对比，并且效率还要高，首先网上过多的递归，os.walk的方法不可用，因为他们都会把遍历到的内容直接做成一个大列表，塞到内存里面，数据量大很容易爆掉，并且还要进行MD5，或者是大小比对，这个就非常难缠了。基础想法其实说白了，拿到所有文件列表file_list，把文件依次对比，这里我们可以用dict，分两种情况 按照文件名和大小设定两个dict，例如record和dup，遍历file_list,生成一个数组，比对其中的文件名和大小按照大小和MD5值设定两个dict，例如record和dup，遍历file_list,生成一个数组，比对其中的md5值和大小具体代码闲话休提，我们开始写代码吧定义遍历函数代码首先定义遍历文件夹的部分diskwalk.py 12345678910111213141516# coding: utf-8__author__ = \"lau.wenbo\"import os,sysclass diskwalk(object): def __init__(self, path): self.path = path def paths(self): path = self.path # 这里用了一个迭代器逻辑，防止所有数据塞内存爆掉 path_collection = (os.path.join(root,fn) for root,dirs,files in os.walk(path) for fn in files) return path_collection 定义检查md5值代码接着我们定义检查md5值的一个逻辑checksum.py 12345678910111213141516171819# coding: utf-8__author__ = \"lau.wenbo\"import hashlib,sys# 分块读MD，速度快def create_checksum(path): fp = open(path) checksum = hashlib.md5() while True: buffer = fp.read(8192) if not buffer: break checksum.update(buffer) fp.close() checksum = checksum.digest() return checksum 定义主函数代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# coding: utf-8__author__ = \"lau.wenbo\"from checksum import create_checksumfrom diskwalk import diskwalkfrom os.path import getsizeimport csvimport osimport sysreload(sys)sys.setdefaultencoding('utf8')def findDupes(path): record = &#123;&#125; dup = &#123;&#125; d = diskwalk(path) files = d.paths() for file in files: try: # 这里使用了大小，文件名的对比方式，如果你需要MD5值的对比方式，可以打开下面的注释 #compound_key = (getsize(file),create_checksum(file)) compound_key = (getsize(file), file.split(\"/\")[-1]) if compound_key in record: dup[file] = record[compound_key] else: record[compound_key]=file except: continue return dupif __name__ == '__main__': path = sys.argv[1] csv_path = sys.argv[2] if not os.path.isdir(path) or not os.path.isdir(csv_path) or csv_path[-1] != \"/\": print u\"参数不是一个有效的文件夹！\" exit() else: path = path.decode(\"utf-8\") print u\"待检测的文件夹为&#123;path&#125;\".format(path=path) with open(u\"&#123;csv_path&#125;重复文件.csv\".format(csv_path=csv_path),\"w+\") as csvfile: # 源文件 重复文件 header = [\"Source\", \"Duplicate\"] writer = csv.DictWriter(csvfile, fieldnames=header) writer.writeheader() print u\"开始遍历文件夹，寻找重复文件，请等待.........\" print u\"开始写入CSV文件，请等待........\" for file in findDupes(path).items(): writer.writerow(&#123;\"Source\":file[1],\"Duplicate\":file[0]&#125;) 结语实现了哪些功能呢，哈哈，结尾来说一下，其实核心就是我用了一个列表生成器，加了一个迭代器，迭代器可是好东西，不会撑内存，不错了，效率也还可以，200w数据判定也就20多分钟，支持大数据量，如果有什么不懂的，可以邮件联系我或者等待我的评论系统搞完，overgithub地址在这: https://github.com/Alexanderklau/Amusing_python/tree/master/File_operation/repeat","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"},{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"keywords":[]},{"title":"Elasticsearch for python API模块化封装","slug":"Elasticsearch-for-python-API模块化封装","date":"2019-10-25T01:57:50.000Z","updated":"2020-04-14T12:03:27.332Z","comments":true,"path":"2019/10/25/Elasticsearch-for-python-API模块化封装/","link":"","permalink":"https://yemilice.com/2019/10/25/Elasticsearch-for-python-API%E6%A8%A1%E5%9D%97%E5%8C%96%E5%B0%81%E8%A3%85/","excerpt":"","text":"Elasticsearch for python API模块化封装模块的具体功能 检测Elasticsearch节点是否畅通 查询Elasticsearch节点健康状态 查询包含的关键字的日志（展示前10条） 查询指定的索引下的数据，并且分页 输出所有日志(输出全部) 输出去重后的日志(分页，带关键字） 删除指定索引的值 往索引中添加数据 获取指定index、type、id对应的数据 更新指定index、type、id所对应的数据 批量插入数据 使用方法一般作为独立的包进行导入，并且对其进行了大数据预览的优化和处理作为一个独立Python模块进行导入，并且调取接口使用。调用方法 12import elasticdb.es_sysdb as esesdb = es.Es() 使用举例打印出索引（表）内的所有数据：需要index名，也就是指定索引名，在这里，假设我要查所有的monlog数据，那么查询语句如: 123a = esdb.search_all(client=esdb.conn, index=monlog, type=\"doc\")for i in a: c.append(i[\"_source\"][\"message\"]) 接口详情接口参数说明 参数 必选 类型 说明 index ture str 索引名 ，可认为是数据库 type true str 索引类型，可认为是表名 keywords ture str 关键字 page ture str 页数，分页逻辑 size ture str 每页展示条数，分页逻辑使用 查询包含的关键字的日志（展示前10条）123a = esdb.search_searchdoc(index=monlog, type=\"doc\", keywords=\"cpu\")for i in a: print i[\"_source\"][\"message\"] 查询指定的索引下的数据，并且分页示例：查询index为”oplog-2018-08,oplog-2018-12”，并且每页展示（size）5条，输出第二页（page） 12for i in esdb.serch_by_index(index=\"oplog-2018-08,oplog-2018-12\", page=2, size=5)[\"hits\"][\"hits\"]: print(i[\"_source\"][\"message\"]) 输出所有日志(输出全部)12for i in esdb.search_all(client=esdb.conn, index=\"monlog-*\", type=\"doc\"): print i 输出去重后的日志(分页，带关键字）示例：关键字为空，搜索monlog的所有数据，展示第一页，并且每页展示10条 12for i in esdb.serch_es_count(keywords = \"\", index=\"monlog-*\", type=\"doc\",page=1, size=10): print i 删除指定索引的值示例：删除monlog的所有值 1esdb.delete_all_index(index=\"monlog-*\", type=\"doc\") 查询集群健康状态1esdb.check_health() 往索引中添加数据12body = &#123;\"name\": 'lucy2', 'sex': 'female', 'age': 10&#125;print esdb.insertDocument(index='demo', type='test', body=body) 获取指定index、type、id对应的数据1print esdb.getDocById(index='demo', type='test', id='6gsqT2ABSm0tVgi2UWls') 更新指定index、type、id所对应的数据12body = &#123;\"doc\": &#123;\"name\": 'jackaaa'&#125;&#125;#修改部分字段print esdb.updateDocById('demo', 'test', 'z', body) 批量插入数据12345678910_index = 'demo'_type = 'test_df'import pandas as pdframe = pd.DataFrame(&#123;'name': ['tomaaa', 'tombbb', 'tomccc'], 'sex': ['male', 'famale', 'famale'], 'age': [3, 6, 9], 'address': [u'合肥', u'芜湖', u'安徽']&#125;)print esAction.insertDataFrame(_index, _type, frame) 代码示例1234567891011121314151617181920212223242526272829303132333435363738394041424344from elasticsearch import Elasticsearchfrom elasticsearch import helpersclass Es: def __init__(self): self.hosts = \"127.0.0.1\" self.conn = Elasticsearch(hosts=self.hosts, port=9200) def check(self): ''' 输出当前系统的ES信息 ''' return self.conn.info() def ping(self): return self.conn.ping() def check_health(self): ''' 检查集群的健康状态 :return: ''' status = self.conn.transport.perform_request('GET', '/_cluster/health', params=None)[\"status\"] return statuu def get_index(self): return self.conn.indices.get_alias(\"*\") def search_specify(self, index=None, type=None, keywords=None, page=None, size=None): # 查询包含的关键字的日志 query = &#123; 'query': &#123; 'match': &#123; 'message': keywords &#125; &#125;, 'from':page * size, 'size':size &#125; message = self.searchDoc(index, type, query) return message 完整的代码地址：https://github.com/Alexanderklau/elasticdb","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang 调用 aws-sdk 操作 S3对象存储","slug":"Golang-调用-aws-sdk-操作-S3对象存储","date":"2019-10-25T01:55:52.000Z","updated":"2019-10-25T02:33:06.939Z","comments":true,"path":"2019/10/25/Golang-调用-aws-sdk-操作-S3对象存储/","link":"","permalink":"https://yemilice.com/2019/10/25/Golang-%E8%B0%83%E7%94%A8-aws-sdk-%E6%93%8D%E4%BD%9C-S3%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/","excerpt":"","text":"Golang 调用 aws-sdk 操作 S3对象存储前言因为业务问题，要写一个S3对象存储管理代码，由于一直写Go，所以这次采用了Go，Go嘛，快，自带多线程，这种好处就不用多说了吧。 基础的功能 查看S3中包含的bucket bucket中的文件/文件夹 bucket的删除 bucket的创建 bucket的文件上传 bucket的文件下载 bucket的文件删除 aws-sdk 的安装玩Golang你还能不会那啥？对吧，那啥？那飞机！那飞机场，安上~ 1go get github.com/aws/aws-sdk-go aws-sdk-go 的基础使用构建基础的S3连接访问S3的时候，咱们需要access_key，secret_key，对象存储访问IP这三个参数，我们首先要创建一个aws的config，说白了，我们需要定义aws的配置，这样它才知道要怎么访问，去哪里访问等问题。构建一个S3连接代码如下 123456789101112131415161718192021222324package mainimport ( \"fmt\" \"os\" \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/credentials\" _ \"github.com/aws/aws-sdk-go/service/s3/s3manager\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/service/s3\")func main() &#123; access_key := \"xxxxxxxxxxxxx\" secret_key := \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\" end_point := \"http://xx.xx.xx.xx:7480\" //endpoint设置，不要动 sess, err := session.NewSession(&amp;aws.Config&#123; Credentials: credentials.NewStaticCredentials(access_key, secret_key, \"\"), Endpoint: aws.String(end_point), Region: aws.String(\"us-east-1\"), DisableSSL: aws.Bool(true), S3ForcePathStyle: aws.Bool(false), //virtual-host style方式，不要修改 &#125;)&#125; 这时候需要你自己去定义一下access_key，secret_key，end_point这三个参数接下来所有的代码，都是以这个连接模板，为核心，后面我就用同上代替配置，请注意！所有的代码都传到GIT上了，到时候会给出地址，不懂得copy下来吧！ 查看S3中包含的bucket查看所有的bucket 1234567891011121314151617181920212223242526272829303132package mainimport ( 导入包同上)func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 svc := s3.New(sess) result, err := svc.ListBuckets(nil) if err != nil &#123; exitErrorf(\"Unable to list buckets, %v\", err) &#125; fmt.Println(\"Buckets:\") for _, b := range result.Buckets &#123; fmt.Printf(\"* %s created on %s\\n\", aws.StringValue(b.Name), aws.TimeValue(b.CreationDate)) &#125; for _, b := range result.Buckets &#123; fmt.Printf(\"%s\\n\", aws.StringValue(b.Name)) &#125; &#125; 列出bucket中的文件/文件夹查看某个bucket中包含的文件/文件夹 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/aws/credentials\" \"github.com/aws/aws-sdk-go/service/s3\" \"fmt\" \"os\")func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 // bucket后跟，go run ....go bucketname bucket := os.Args[1] fmt.Printf(bucket) fmt.Printf(\"\\n\") svc := s3.New(sess) params := &amp;s3.ListObjectsInput&#123; Bucket: aws.String(bucket), &#125; resp, err := svc.ListObjects(params) if err != nil &#123; exitErrorf(\"Unable to list items in bucket %q, %v\", bucket, err) &#125; for _, item := range resp.Contents &#123; fmt.Println(\"Name: \", *item.Key) fmt.Println(\"Last modified:\", *item.LastModified) fmt.Println(\"Size: \", *item.Size) fmt.Println(\"Storage class:\", *item.StorageClass) fmt.Println(\"\") &#125; &#125; bucket的创建创建bucket 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( 导包同上)func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 bucket := os.Args[1] if len(os.Args) != 2 &#123; exitErrorf(\"Bucket name required\\nUsage: %s bucket_name\", os.Args[0]) &#125; // Create S3 service client svc := s3.New(sess) params := &amp;s3.CreateBucketInput&#123; Bucket: aws.String(bucket), &#125; _, err = svc.CreateBucket(params) if err != nil &#123; exitErrorf(\"Unable to create bucket %q, %v\", bucket, err) &#125; // Wait until bucket is created before finishing fmt.Printf(\"Waiting for bucket %q to be created...\\n\", bucket) err = svc.WaitUntilBucketExists(&amp;s3.HeadBucketInput&#123; Bucket: aws.String(bucket), &#125;) if err != nil &#123; exitErrorf(\"Error occurred while waiting for bucket to be created, %v\", bucket) &#125; fmt.Printf(\"Bucket %q successfully created\\n\", bucket)&#125; bucket的文件上传往某个固定的bucket里传文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/aws/credentials\" \"github.com/aws/aws-sdk-go/service/s3/s3manager\" \"fmt\" \"os\")func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 if len(os.Args) != 3 &#123; exitErrorf(\"bucket and file name required\\nUsage: %s bucket_name filename\", os.Args[0]) &#125; bucket := os.Args[1] filename := os.Args[2] file, err := os.Open(filename) if err != nil &#123; exitErrorf(\"Unable to open file %q, %v\", err) &#125; defer file.Close() uploader := s3manager.NewUploader(sess) _, err = uploader.Upload(&amp;s3manager.UploadInput&#123; Bucket: aws.String(bucket), Key: aws.String(filename), Body: file, &#125;) if err != nil &#123; // Print the error and exit. exitErrorf(\"Unable to upload %q to %q, %v\", filename, bucket, err) &#125; fmt.Printf(\"Successfully uploaded %q to %q\\n\", filename, bucket)&#125; bucket的文件下载下载某个bucket中的某个文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/aws/credentials\" \"github.com/aws/aws-sdk-go/service/s3\" \"github.com/aws/aws-sdk-go/service/s3/s3manager\" \"fmt\" \"os\")func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 if len(os.Args) != 3 &#123; exitErrorf(\"Bucket and item names required\\nUsage: %s bucket_name item_name\", os.Args[0]) &#125; bucket := os.Args[1] item := os.Args[2] file, err := os.Create(item) if err != nil &#123; exitErrorf(\"Unable to open file %q, %v\", err) &#125; defer file.Close() downloader := s3manager.NewDownloader(sess) numBytes, err := downloader.Download(file, &amp;s3.GetObjectInput&#123; Bucket: aws.String(bucket), Key: aws.String(item), &#125;)if err != nil &#123; exitErrorf(\"Unable to download item %q, %v\", item, err)&#125;fmt.Println(\"Downloaded\", file.Name(), numBytes, \"bytes\")&#125; bucket的文件删除删除某个bucket里面的某个文件 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/aws/credentials\" \"github.com/aws/aws-sdk-go/service/s3\" \"fmt\" \"os\")func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 if len(os.Args) != 3 &#123; exitErrorf(\"Bucket and object name required\\nUsage: %s bucket_name object_name\", os.Args[0]) &#125; bucket := os.Args[1] obj := os.Args[2] svc := s3.New(sess) _, err = svc.DeleteObject(&amp;s3.DeleteObjectInput&#123;Bucket: aws.String(bucket), Key: aws.String(obj)&#125;) if err != nil &#123; exitErrorf(\"Unable to delete object %q from bucket %q, %v\", obj, bucket, err) &#125; err = svc.WaitUntilObjectNotExists(&amp;s3.HeadObjectInput&#123; Bucket: aws.String(bucket), Key: aws.String(obj), &#125;) fmt.Printf(\"Object %q successfully deleted\\n\", obj)&#125; 代码所在地https://github.com/Alexanderklau/Go_poject/tree/master/Go-Storage","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"程序员如何锻炼自己的产品思维","slug":"程序员如何锻炼自己的产品思维","date":"2019-10-25T01:46:55.000Z","updated":"2019-10-25T02:33:21.668Z","comments":true,"path":"2019/10/25/程序员如何锻炼自己的产品思维/","link":"","permalink":"https://yemilice.com/2019/10/25/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E9%94%BB%E7%82%BC%E8%87%AA%E5%B7%B1%E7%9A%84%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4/","excerpt":"","text":"程序员如何锻炼自己的产品思维写作目的源于一次需求会议被怼，大老板总是说我以技术思维决定一切。后来我一思考，卧槽，果然是这样，每次我都是非常纠结于技术实现和技术细节，总是纠缠在业务实现里面，所以渐渐就养成了那个习惯。思考了一下，有些地方也的确是应该做出一点点改变了，老话说，种一棵树，最早是十年前，其次就是现在，那么我们就开始种树吧。趁着放假读几本产品思维的书，有一点点感悟，所以将此文写下，方便自己，也方便急于转型的各位程序员老哥。 个人技术背景1.菜逼一个，看博客就知道了。 2.掌握技术：后端： Python，Golang，Java移动端：OC（大学时候兼职IOS开发）前端：基础的React和Vue框架 3.算法技术：渣渣 4.没有任职过任何产品岗位 个人分析优点技术涉及面广，做项目多，一直在项目第一线，熟悉项目业务，思维活跃，善于解决和发现问题。 缺点算法能力差，前端能力差，抽象思维较弱，容易钻牛角尖，对项目整体了解不够透彻，只了解某些模块和部分。 什么是产品思维？理论上的产品思维1.把握关键点的能力 2.出方案，协调资源，说服团队把资源倾斜到关键点上的能力 3.评估关键点进展程度的能力 大白话解释1.首先用户就是一切，一切为了用户爽 2.反向思维，逆推解决问题 3.换位思考啊大哥，你不仅仅是产品人员，你还得是老板，用户，程序员balabala 4.脑子里对业务and产品都算是有了解（当然不能说像程序员一样） 其他来源对产品思维的解释1.从人性本质挖掘需求 说白了就是你要从人去思考问题，也就是说，你要人的表面挖掘到人的内心，类似挠痒痒，不能挠痒痒之后把皮整破了，这就是你满足了表面需求，但是破坏了底层需求2.从赚钱的角度思考 说白了就是追逐利益，想法儿怎么搞钱，例如扫码送东西，例如扫码给红旗，例如十一的时候给微信加国旗，这都是从逐利的思想去发觉需求3.沟通能力 我缺乏哪些技能？粗略看一下，其实缺乏的东西看起来很简单 对整体架构了解不多 逆向思维较差，不能从用户需求去理解问题，只单纯纠结能不能实现功能 评估项目和关键点能力不足 不能够和其他程序员有很好的沟通 平常和业务纠缠太多了，我这种Code monkey每天都去思考这个功能怎么实现，用什么技术更牛逼，怎么优化之类的，纠结技术，功能，细节等等。举个例子，我作为一个代码工程师工程师思维关注技术至上，技术水平代表实力，向于在产品中使用先进、流行的技术，因为掌握先进主流的技术可以提高他的身价。产品思维关注的是，这技术能给用户带来什么价值？有什么商业价值？所以我需要跳出这个怪圈，学会用产品的思维去思考问题，这样也能够开拓自己的眼界，无论是技术还是其他的路，都可以走的更远。 我该如何去补强这些技能？我理解的产品思维每一个项目都是产品。我们可以把工作当中的任何一个输出成果当做产品，用产品思维来完成这个成果。比如，我现在正在开发一个分布式的同步备份工程，将之称为产品。按照产品思维来策划这个工程，你要思考：我为什么要做这个产品？希望得到什么？用户是谁？谁在用这个？他们希望怎么去用？干系人有哪些？他们的期待是？使用场景：现有的web？还是独立开发APP？或者是普通的云计算服务？或者是普通存储服务？或者是类似同步服务？用户的关注点：怎么用？好操控么？用着舒服么？界面看着开心么？思考一下，产品思维的确和工程师思维不太一样，我也不能总是在工程师思维这个怪圈中徘徊 理论上的补强手段保持自己对于不同产品、不同领域的好奇心和敏感度很多时候我都忙于自己当下的工作，很难有机会接触到不同领域不同产品。很可能渐渐地就失去了对于产品的好奇心和敏感度，所以必须要让自己走出去，多去接触，或者看一看别人的产品or项目如何设计，思考他们是怎么做产品的？他们为什么这么做 ？如果我来做能怎样做？通过这样的思考和练习，来保持自己对产品的好奇心和敏感度 向上拓展自己的能力，不能停留于技术人员or产品经理一直纠缠与技术实现细节，总归是只有一层，如果满足这一层，也就是写代码的工具，或者是模块添加人员，也就没有办法建立起来自己的核心竞争力，笑傲江湖里面，剑宗气宗之争也是这一点，剑气双休才是最重要的。所以不仅仅是技术要抓，思想也要抓。 强化自己逻辑思维分析能力在逻辑思维方面，我想没有谁比得过程序员，程序员本来就是逻辑性很强的工作，这一点其实我认为更重要的是换位分析，易地而处的一种状态。我们往往分析自己的工作比较容易，但是涉及大局分析，就有些力不从心，这个我认为还是要针对性训练。 分解问题的能力其实这个在写代码的时候也经常预见到，不是么，一个大问题细化为好几个小问题，换算成产品思维也即是：1.产品有哪些功能？ 2.这些功能下面又分哪些模块？ 3.具体的应用场景在哪里？ 4.产品模块之间相互的联系是什么？ 5.谁在用这些产品？ 6.业务部门之间的需求是否互相耦合？是否已经存在重复需求？ 这里只是举个例子，具体问题具体分析，将自己想象成产品经理，先不要思考问题怎么解决，看看产品是怎么做的，再去对比思路思考解决问题。 用户行为分析能力什么是用户行为？关键就是用户用着你这个产品产生的行为，再去产生其他行为，这是用户增长和用产品化的重要组成部分。首先我们需要找出，关键用户行为，也就是，用户在使用产品时，是奔着你产品的什么方面来的，拿我正在做的项目举个例子，同步备份模块，干嘛的，同步备份文件的，特点呢？分布式，速度快，那不就完了！关键行为就是同步备份，这才是用户的关键行为。首先我们要考虑为什么会产生关键行为，也就输确定产品的价值，产品的价值就是用户愿不愿意给这个产品花钱，愿不愿意花钱去买我们的东西，解决痛点是第一位，但是在这之前，有没有类似的产品做了？人家做的好不好？谁的效率高？谁更牛逼？牛逼在哪？这才是要去分析的地方。 场景分析能力说白了，角色扮演，你把自己想象成一个用户，现在我想要一个产品，思考一下1.产品包含哪些场景 2.产品涉及哪些角色 3.场景会被第三方影响么？如果会，该如何去降低它？ 举个例子，同步备份的产品用在普通用户手中，普通用户的网很慢，同步时断时续，这就是第三方的缘故，但是我们的产品是单节点，也就是说只能一点点下，不能分布式，这就坑了，用户会觉得，你这怎么那么卡，你看看人迅雷，都能断点，都能分布式，你这个，get out，这就是第三方影响使用场景。再举个例子哈：朱啸虎先生在杭州的一次演讲中提到了维诺城。维诺城是在地铁口放置终端，用户出了地铁口之后可以在上面打印周围商家的优惠券。维诺城最初的生意非常好，因为地铁人流大，又是优惠券提供，在大众点评美团还没崛起的时候，它确实是很方便的产品。然而现在一方面因为美团这些APP的强势崛起，另一方面因为地铁提高了租金，更多的商家进场，甚至地铁公司本身都要来抢这个生意，维诺城的生意就下坡路了。 维诺城的例子说明什么？说明如果产品的主要场景容易受限于特殊的场地和时间特性，而这个场景进入的门槛比较低或是由第三方来控制，那么这个产品从场景上来说是有很高风险的；作为产品经理就要尝试思考有没有办法去降低这些影响，或是去发现自己产品不过度依赖这个场景的核心竞争力？ 数据分析能力数据这玩意，永远是支撑一个产品，或者是一个理论的重要依据。如何在通过数据去引导自己的产品思维 1、明确数据指标的定义、口径和使用场景。 要能清楚地和开发人员描述数据指标到底是什么，有哪些维度，在哪个页面或哪个场景之下发生； 2、层层剥离，穷举指标 产品经理为了保证数据的准确性，要尽可能地将指标拆解，拆解到不能拆解为止。同时也要分清哪些是核心指标，哪些是主要指标，哪些是次要指标； 3、数据指标和用户结合 新用户做了什么？老用户做了什么？付费用户做了什么？非付费用户又做了什么？流失用户在流失之前做了什么？要回答这些问题就要将数据指标和不同的用户结合起来分析","categories":[],"tags":[{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"keywords":[]},{"title":"新旧博客迁移的一点感悟","slug":"新旧博客迁移的一点感悟","date":"2019-10-24T09:50:37.000Z","updated":"2020-04-14T12:03:13.727Z","comments":true,"path":"2019/10/24/新旧博客迁移的一点感悟/","link":"","permalink":"https://yemilice.com/2019/10/24/%E6%96%B0%E6%97%A7%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E7%9A%84%E4%B8%80%E7%82%B9%E6%84%9F%E6%82%9F/","excerpt":"","text":"算是日记吧其实自己一直在cnblog上更新自己的博客，从16年3月入行到现在，已经过去了三个春秋，发觉自己的技术还是个渣渣，最近生活真的忙成一团，工作也很忙，生活也很忙，有时候饭都不容易吃上，感觉自己学习真的学不动了，不知道自己是不是懈怠了，运动，音乐什么的，也停下来了，感觉真的缺少了一点点乐趣。不过说真的，自己也真的该动起来了，因为时间不等人啊，已经入行这么久，跌跌撞撞像个摇摆人，所以未来我还是要多学习，多更新我的博客，将自己的技术或者是一些感悟，哪怕是一些灵光一闪的理想，都记录下来，哈哈，这样会不会好一些呢？会不会明天就是更好的那一天呢？ 算是自己我介绍吧渣渣一个，技术又全又杂，精通的少，各种都会一点，但是真正就是个渣渣，哈哈，现在孑然一生，18年年底被踹，重新出发，想想自己当时为了感情选择留在这个陌生的城市，现在已经爱上了这座城市，这座美丽的西南大都会。我想我会留下来的吧，我会留下来的？我也不确定吧，现在要慢慢出发，重新出发，我想我会越来越好的。 算是结尾吧可能你因为一些别的原因走到我博客来，其实欢迎你，欢迎你听一个24岁的家伙碎碎念那么久，未来大部分应该会更新技术，或者是我的一些奇特爱好，哈哈，希望你们会喜欢，我爱你们。","categories":[],"tags":[{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"keywords":[]}]}