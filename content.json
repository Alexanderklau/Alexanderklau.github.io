{"meta":{"title":"Yemilice","subtitle":null,"description":null,"author":"Yemilice lau","url":"https://yemilice.com"},"pages":[{"title":"","date":"2019-11-06T02:28:37.885Z","updated":"2019-11-06T02:28:37.461Z","comments":true,"path":"baidu_verify_kjucdQVPYU.html","permalink":"https://yemilice.com/baidu_verify_kjucdQVPYU.html","excerpt":"","text":"kjucdQVPYU"},{"title":"","date":"2019-10-28T05:11:59.061Z","updated":"2019-10-28T05:11:59.061Z","comments":true,"path":"google9c12e62c3231610a.html","permalink":"https://yemilice.com/google9c12e62c3231610a.html","excerpt":"","text":"google-site-verification: google9c12e62c3231610a.html"},{"title":"分类","date":"2020-04-14T11:16:58.000Z","updated":"2020-04-14T11:17:49.391Z","comments":true,"path":"categories/index.html","permalink":"https://yemilice.com/categories/index.html","excerpt":"","text":""},{"title":"关于我","date":"2020-04-14T11:23:29.000Z","updated":"2021-08-26T06:34:22.002Z","comments":true,"path":"about/index.html","permalink":"https://yemilice.com/about/index.html","excerpt":"","text":"简单说下我干嘛的 没什么优点，一个写代码的说唱歌手。 原本是要去做音乐的，害，家里不同意 说那都是二流子玩的，我？？？？ 厂牌？ 没有，aka 造梦的艺术家 有名？ 没有，主要是混音和beat制作，很少整活 参加过比赛？ 参加过，2020新说唱，海选过了，没时间去现场 我现在也在参加一些说唱类节目，不过我现在基本都是趋于编曲和混音制作方面了 唱的其实不多，不过我会在我的blog里面发一些我以前唱的歌 什么时候开始搞说唱的？ 其实和写代码开始时间差不多，2014年，我当时录了第一首歌 然后我2015年就参加了八英里，一轮游，当时参加的人有red flower，xixia空军那帮人，其中有PG，贝贝，MC ming西之类 我第一轮对上一个西安老哥，直接被干爆，这是我第一次开始我的rap生涯。 2015我参加过干一票，还是淘汰，我有时候都怀疑我适不适合唱歌。哈哈 第一份工作是什么时候开始的？ 2014年，实习，我那时候还是大二学生 我买了一台二手苹果笔记本，直接海投简历，不要钱干活都行的那种 后来进了一家小公司，做美图软件的，一开始做IOS开发，兼职后端开发。 然后emmm，程序员之路就走上了正轨 为什么还没有放弃音乐？ 其实是一种爱好，一种寄托。 玩音乐的时间算起来挺久了 我记得是4岁 我父亲开始教我手风琴，然后我学了钢琴 后来父母分开，父亲远走，丢失原本优渥的家庭条件 我不再进行音乐学习，但是加入了学校乐团，任职小号手 进入大学，我开始慢慢接触别的音乐风格，从county music到摇滚，到哥特，最后到hiphop，电子，慢慢再到爵士 其实是一个循序渐进的过程。 写博客的目的？ 写博客，其实很简单 因为我是一个想法比较多的人 因为我是一个爱学习的人 因为我是一个爱看书的人 因为我是一个不能在朋友圈发这些东西的人 博客其实是我学习的重要基地 我的博客记录的往往都是我踩的坑，做的事 每天和你擦肩而过的有100多人，每天你要听几百句话 当你回头想寻找他们，却早就消失不见 若干年后你我将化为尘土 但是你留下的知识，和文字 会记录你在某个时刻 有多么的幸福 一些感悟 如果你看到了博客，说明你我很幸运能认识，感恩你来过，也感恩你的离开。 如果遇到什么问题，或者有什么建议和意见，可以给我发邮件 Yemiliceklichko@outlook.com PS！！！ 我最近在找工作！ 如果有谁在看！希望你们，考虑考虑我！ 将我的简历附着如下，爱你噢！ 我可以做什么 Golang后端开发 Python后端开发 全栈开发 游戏后端开发（我想做的 简历在这里！！一点就送！！！ 2021-08-18"},{"title":"","date":"2020-05-19T07:34:45.854Z","updated":"2019-10-28T05:11:59.061Z","comments":true,"path":"images/google9c12e62c3231610a.html","permalink":"https://yemilice.com/images/google9c12e62c3231610a.html","excerpt":"","text":"google-site-verification: google9c12e62c3231610a.html"},{"title":"tags","date":"2020-04-14T11:21:09.000Z","updated":"2020-04-14T11:21:09.945Z","comments":true,"path":"tags/index.html","permalink":"https://yemilice.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Golang协程基础探究","slug":"Golang协程基础探究","date":"2021-10-27T03:39:17.000Z","updated":"2021-10-27T03:58:50.243Z","comments":true,"path":"2021/10/27/Golang协程基础探究/","link":"","permalink":"https://yemilice.com/2021/10/27/Golang%E5%8D%8F%E7%A8%8B%E5%9F%BA%E7%A1%80%E6%8E%A2%E7%A9%B6/","excerpt":"","text":"前言最近我把Go重新过了一遍，特别是Go的协程这一块，我感觉任何事都是从简单到复杂 包括现在，所以我重新开始学习基础，后序我会出一个系列 分别为 Golang协程基础 （已经完成！） Golang协程调度 Golang协程控制 Golang协程通信 Golang垃圾回收机制 所以我会持续更新，大家请期待吧，爱你们！ Go里的协程是什么写Go这么长时间了，在开发项目当中，感觉Golang的好处还是很多的 Golang为什么被推崇，核心就是在并发和协程方面有很大的优势 协程这个概念其实不陌生，我在大学看Python的时候就看过这方面的资料 就是轻量级的线程 但是Go的协程其实和Python又不太一样了，这里我还是认真讲一下协程是个什么玩意儿吧 进程和线程协程是轻量级的线程，但是线程又和进程有不能说的PY交易 所以我首先来过一遍进程和线程的基础概念 首先直接说概念，这个是核心，记住就完事 线程是进程的组成部分 一个线程只能有一个进程 但是一个进程可以有多个线程 进程死了，线程一起死 进程之间相互独立 进程开销比线程大 可以这么理解，线程是进程的崽，进程是独立个体，可以随意下崽（创建线程） 操作系统里面，调度到CPU中执行的最小单位就是线程 有多核处理器的计算机，线程可以分布在多个CPU上，实现真正的并行逻辑。 看图，这就是多核处理器和单核处理器的差别（Python就是上面那个。。。GIL让他永远用不了多核 线程的切换和调度这里还是分析线程，是为后序分析协程逻辑打好基础，要是大家伙不想看，直接跳过即可 线程好用，但是不能一下开无数个，也不能全开，也不能不返回就持续等待 所以，为了最大化利用CPU资源，操作系统需要通过定时器，IO设备，上下文切换等动作去控制线程 一般的切换逻辑是 当A线程发生切换的时候，会从用户态转移到内核中，记录寄存器值，进程状态之类的信息到操作系统线程的控制块当中 然后进行切换，切换到下一个执行线程B，加载刚刚保存那得那些寄存器值，然后从内核转移到用户态中 如果线程A和线程B不属于同一个线程，切换的时候将会更新额外的状态信息和内存地址，然后导入页表到内存里面。 可以看见一点，就是线程切换需要记录一大堆东西 这就是线程切换的一点点知识。 线程和协程的关系协程，轻量级线程，相当于线程PLUS 但是它和线程不同的一点，人家切换或者是做别的操作 不依赖操作系统内核，而依赖自身（Go）的调度器 其实就是内部执行的一串代码 协程其实是线程的从属 下面分析下他们的具体区别还有联系 GMP模型-线程和协程的核心关系首先看个图 这个图就是GMP模型的核心图，这个图其实说的挺明白了 首先 G就是协程 P就是Go的调度器 M就是线程 可以看见，Go的协程依托线程 一个P可能包含了多个协程，一个P在任何时候只能有一个M 这就说明了线程和协程的关系应该是 m:n 相关的知识我也在其他的文章里说过 golang的并发机制探究 但是我后续还是会细化一下GMP模型 协程的调度方式首先看个图 协程和线程的关系为M：N，为多对多关系 调度器P可以将多个协程调度到一个线程中，也可以切换一个协程到多个线程中运行 协程的切换协程为什么叫轻量级线程，因为它的切换速度比线程快，根据上面我讲的线程切换 线程切换需要操作系统用户态和内核态，并且需要存储寄存器的变量值，保留额外的一些变量值（上面有说 协程切换只需要保留极少的状态值和寄存器变量值，并且一切都有Go调度器去操作，免去用户态和操作系统态交互的麻烦逻辑 线程切换的速度大概是 1-2微秒 协程切换的速度为 0.2 微秒 协程的调度策略这里后面我的Blog也会讲，在这我就简单描述一下吧 线程的调度大部分都是抢占式的，为了平衡资源，操作系统的调度器会定时发出中断信号，来进行线程切换 协程的调度是协作式的，当一个协程处理完任务的时候，可以将执行权限交还给其他协程，不会被轻易抢占，并且协程切换也是有一定的方法，比如抢占队列，偷窃任务等等，这个我后面会另开一篇好好讲述 协程栈的大小线程栈大小，一般是创建时指定的，为了避免溢出，默认一个栈会比较大（2MB） 这样就大大限制了线程栈的数量，如果1000个线程就需要占用2GB虚拟内存 但是协程栈大小默认为2KB，这样就可以创建一大堆协程，并且协程可以动态扩容栈大小 而线程只能固定一个栈大小 协程栈扩容的算法我后面会说（自己老开坑。。。 并发和并行并发，并行是老生常态的话题了 我这简单说下 并发：谁先执行任务我不管，但是，某个时间段内，所有的任务都能执行完毕 并行：一起执行任务，大家一起出发 在我开发的生涯里面，这种情况不只是单纯的并发并行，一般都是一起用的 除开Python（有GIL锁） 基本都是多核并行处理多个线程任务，但是单核里面也在负责多个线程任务 所以这样的关系类似 转回Go部分，Go的调度器，会把协程分给多个线程，这些线程又很可能被分发给了不同的进程，这样的关系就类似 这样也说明，在多核的环境下，Go的并发，并行是同时存在且不冲突的。 写一个协程实例这个我相信大家玩Go的人都会写，其实Go的协程非常简单 1go test() 那么现在咱们要实现一个并发协程，首先实现一个线性流程 1234567891011121314package mainimport \"fmt\"func FmtSmg(name string) &#123; fmt.Println(name)&#125;func main() &#123; z := []string&#123;\"yemilice\", \"fuck\", \"day\"&#125; for _, i := range z &#123; FmtSmg(i) &#125;&#125; 这边输出 123yemilicefuckday 现在我们改写成协程模式 123456789101112131415161718package mainimport ( \"fmt\" \"time\")func FmtSmg(name string) &#123; fmt.Println(name)&#125;func main() &#123; z := []string&#123;\"yemilice\", \"fuck\", \"day\"&#125; for _, i := range z &#123; go FmtSmg(i) &#125; time.Sleep(time.Second * 2)&#125; 得到输出 123dayyemilicefuck 这就是一个简单的协程，这部分我用了time.sleep做通信等待，这个比较low，我后续会在协程通信的blog里面更详细的描述介绍 例如channel，waitgroup等 Go的并发模型上一节我们实现了一个Go的协程实例，但是似乎我们并不了解为什么Go要这么设计 这一节我将告诉你什么是Go的并发模型，也就是Go执行的流程，这一节也是为下次的文章做好基础，比较重要 其实Go遵循的是fork-join的一种并发模型 fork可以指程序中任何地方，这里将子协程和主协程分开执行 join指的是某个时候，子协程和主协程执行分支合并在一起 看个图 这就是fork-join的并发模型 举个简单的例子 12345678func work() &#123; fmt.Println(\"work\")&#125;func main() &#123; go work()&#125; 这里我们去执行，但是什么都没有返回 这里如果用fork-join表示，画图如下 可见我们需要连接点 将代码改写 1234567891011121314func work() &#123; fmt.Println(\"work\")&#125;func main() &#123; var wg sync.WaitGroup wg.Add(1) go func() &#123; defer wg.Done() work() &#125;() // 这是连接点 wg.Wait()&#125; 这里有了连接点，用fork-join表示一下就是 这里的代码不用深究，这里属于协程控制，这里后面我会单开博客讲 这里只是为了让大家直观看到fork-join这种并发模型，这是Go预言需要遵循的并发哲学 总结这次主要是把协程的基础概念讲了一下 讲了协程和线程的关系 讲了协程是怎么来的，怎么实现一个协程 讲了Go的并发模型 下集预告下一节我将深入到Go协程之间的调度当中 整明白Go协程的调度原理 整明白Go协程的调度策略 整明白Go协程的几种状态","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"设计高可用的ElasicSearch索引","slug":"设计高可用的ElasicSaerch索引","date":"2021-09-09T07:36:23.000Z","updated":"2021-10-21T07:43:26.167Z","comments":true,"path":"2021/09/09/设计高可用的ElasicSaerch索引/","link":"","permalink":"https://yemilice.com/2021/09/09/%E8%AE%BE%E8%AE%A1%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84ElasicSaerch%E7%B4%A2%E5%BC%95/","excerpt":"","text":"前言最近又是学习的爆发期，我戒除了上班划水和看知乎故事会，也戒除了游戏和小说 也戒除了频繁参加外面的无用活动，也逐渐修复了寂寞侵蚀内心的恐惧 将心思逐渐稳定下来，所以，我本月开始到年底，将会爆发式更新blog和歌曲 请大家和我一起学习吧！对了，如果有机会，请不要忘记帮我看看是否有合适的工作 我最近在换工作，走过路过，也别忘记我找份工作。 开始！ 123456789101112131415从不去关心他人的定位对我喜欢讨厌或者是敬畏始终在不停的韬光养晦为我喜欢的事鞠躬尽瘁妈妈问我每天是否疲惫生活似好似坏前路隐晦希望的濒危物种不令人敬佩只想和路过的你说声幸会 当我们在说Es索引设计时，我们在说什么？在我的开发生涯中，我使用过Mysql，Etcd，Mongodb之类的数据库 当我拿到一个数据库要进行开发任务的时候，我的第一件事往往就是查看数据结构，或者是查看表结构 如果是Mysql一类的数据库，数据表中，表的字段类型是否合适，表设计是否合理，涉及到联合查询的机制是否完全？这往往就是数据库表设计的核心。 嵌套到es当中，es的索引，你也可以理解为表 当我们要设计索引的时候，我们就是设计表 当我们说要设计高可用的的索引时，往往就是指索引 可支撑大数据量 性能影响小 结合业务场景，全维度考虑增，删，改，查 ElasticSearch索引的基础知识索引，这个东西在数据库里面就是帮助加快检索速度的 它是一种数据结构，这个我原来提过一点点 具体的地址，请参看 ElasticSearch检索的核心-倒排索引解读 今天我们的主题并不是原理，而是如何设计索引 如何设计索引才能让我们的ES更加健壮，避免后期存入数据过多后还要更改结构 这个才是这篇文章的核心。 所以基础知识这里，我将不会表述太多，请大家见谅。 默认你已经会用Es，就这样，Over。 Mapping的设计Mapping是什么?Mapping在Es里面，相当于表结构，我举个例子 1234567891011121314151617181920\"mappings\": &#123; \"doc\": &#123; \"properties\": &#123; \"name\": &#123; \"ignore_above\": 256, \"type\": \"keyword\" &#125;, \"id\": &#123; \"type\": \"keyword\" &#125;, \"size\": &#123; \"type\": \"long\" &#125;, \"last_mod_time\": &#123; \"format\": \"yyyy-MM-dd HH:mm:ss\", \"type\": \"date\" &#125; &#125; &#125;&#125; 我们定义的mapping里面有若干个字段，name，id… 类型不同，有long，keyword，date Mapping在索引设计中是非常重要部分，就和表设计一样的，你需要定义字段 一个好的字段能让我们的检索速度飞快，一个差的字段会让我们浪费很多平白无故的存储空间 首先Mapping的基础知识可以参看这篇文章 一文搞懂 Elasticsearch 之 Mapping 这篇文章的大佬把Mapping说的很清楚了 Mapping 分为两种，静态Mapping和动态Mapping 下面我分别说下静态和动态的几个优缺点 静态Mapping事先定义好字段，也就是定义好基础的Mapping格式，就像章节最开始我举的例子。 静态Mapping，就相当于我们创建Mysql表，事先建表，规定好所有的字段和类型 静态Mapping的优点如下 可选可控 节约存储空间 静态Mapping的缺点如下 设计要求高，后期无法进行更改 将数据格式全部规定死，不够动态 动态Mapping我们不创表，直接传入数据，Es会根据你传入的数据自动匹配合适的类型，也就是自动识别数据 说白了，就是你，传个json过来，Es根据你的json自动匹配类型，然后创建Mapping 动态Mapping这东西，其实我是不推荐用的，因为相当于，你把数据类型的判断逻辑交给了Es，这是很不可取的，因为Es，很傻，说下原因 当你不想检索一些字段的时候，你可以通过设置mapping事先指定，但是动态的不行 动态Mapping可控性没那么高，你往里导数据，要保证数据的一致性 高可用Mapping设计的流程查了一些资料，其实大家可以看一下铭毅天下这个老哥的公众号 他的公众号给了我很大启发！ 铭毅天下-死磕Elasticsearch方法论 首先，设计Mapping，需要预先考虑如下几点 是否需要进行全文检索 是否需要排序 数据类型的多重选择 首先，先将Mapping里的几个参数及其基础设置梳理 参数 具体说明 传入参数 enabled 设置是否需要检索 True/False index 设置是否构建倒排索引 True/False index_option 设置存储倒排索引的哪些信息 True/False doc_values 是否开启聚合分析 True/False dynamic 动态更新mapping True/False data_detection 自动识别日期类型 True/False 进行Mapping设计时，首先要考虑我们到底有多少字段，这些字段的属性是什么 这里非常重要，因为，当你创建完Index的时候，Es是不许更新表结构，也就是Mapping的， 如果要选择更新，则需要重建Index，当数据量很大的时候，这种方案肯定是不可以的。 所以，我这里定义的流程如下 第一步：确定存储的数据类型先细分析一波，先根据我们的需求，确定建立好我们的数据类型 一般的数据类型如下 根据我们的需求去梳理数据类型 这里提几点选择策略 如果你有很多文字，不需要分词，选text，需要分词，选keyword 如果你未来不确定你到底有多少数据，将类型设置为long是比较合适的 keyword检索比较短的字符会更快，如果字符很大，那么会增加存储和检索成本 第二步：确定哪些字段需要检索如果我们存储的一个json十分巨大，例如content是一篇文章，或者我们的Mapping字段非常的多，那么如果全部默认检索，那我们会搜出一大堆无用的东西 这样既增加了存储成本，又减弱了检索效率，所以下一步，我们就要根据需求，确定哪些字段需要检索 一些固定参数，或者不想给用户展示的参数也就没有检索价值 例如ID一类的参数 这里如果我们不想ID被检索，那么需要设置 1234\"id\":&#123; \"type\": \"text\", \"index\": false &#125; 第三步：检索的方式这里一般指的是分词的设置，这里需要指定分词器 分词器我以前的blog里面也讲过 定义自己的分词器 这里相当于是，给指定的字段，添加分词 假如我们现在有一个字段，名字叫name，我们需要指定中文分词器IK 1234\"name\":&#123; \"type\": \"text\", \"analyzer\": \"ik_smart &#125; 第四步：指定mapping的特殊设置这里的设置，不针对某个字段，而是针对整个mapping的setting设置 这里有如下几个常用设置 12345678910111213&#123; \"settings\": &#123; // 分片数量 \"number_of_shards\": 5, // 副本 \"number_of_replicas\": 1, // 最好压缩 \"codec\": \"best_compression\", // 最大展示条数 \"max_result_window\": \"100000000\", // 刷新时间 \"refresh_interval\":\"30s\"&#125; 一般都是这么几个设置 甭管那么多，直接上，不要怂 这张图是铭毅天下那里找来的！爱你！ 这个流程，非常清楚了 Mapping的模版这里给出我自己开发时候的一个模版，这个模版扛住了千万数据量，直接上，不要怕 大家拿过来改改字段就行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&#123; \"settings\": &#123; \"number_of_shards\": 5, \"number_of_replicas\": 1, \"codec\": \"best_compression\", \"max_result_window\": \"100000000\", \"refresh_interval\":\"30s\" &#125;, \"mappings\": &#123; \"doc\": &#123; \"properties\": &#123; \"name\": &#123; \"type\": \"keyword\" &#125;, \"id\": &#123; \"type\": \"keyword\" &#125;, \"data\": &#123; \"type\": \"nested\", \"properties\": &#123; \"value\": &#123; \"type\": \"text\", \"fields\": &#123; \"keyword\": &#123; \"ignore_above\": 256, \"type\": \"keyword\" &#125; &#125; &#125;, \"key\": &#123; \"type\": \"text\", \"fields\": &#123; \"keyword\": &#123; \"ignore_above\": 256, \"type\": \"keyword\" &#125; &#125; &#125; &#125; &#125;, \"size\": &#123; \"type\": \"long\" &#125;, \"last_mod_time\": &#123; \"format\": \"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd || epoch_millis\", \"type\": \"date\" &#125;, \"user\": &#123; \"type\": \"keyword\" &#125;, \"content\": &#123; \"analyzer\": \"ik_smart\", \"term_vector\": \"with_positions_offsets\", \"type\": \"text\" &#125; &#125; &#125; &#125;&#125; 大数据下索引的切分当我通过filebeat或者logstash倒入数据到Es中的时候 传输到Es中，创建的index是可以自己控制的 一般的划分方法是： 年 月 日 自定义 举例来说 假如我们的log索引，名字叫”log-2021-09” 那么每天的数据量都有千万，那么这个索引就会越来越大，越来越大 你做检索的时候，就会在一个非常大的索引中进行 这样检索的时候，卡，慢就出现了 万一这索引坏了，那。。。丢数据吧 所以，如何进行切分，或者优化索引，势在必行 下面我这里将给出一些我自己实战的手法，给大家一些建议。 动态创建索引首先，上一节我们讲了Mapping模版，这里我就不再多说 我们需要结合模版去动态创建索引 方法如下 rollver滚动创建索引现在开始设定 log-2021-09 这个索引 这步的意思是创一个索引，名字叫做log-2021-09-00001，别名为logs_write 123456curl -XPUT 'localhost:9200/log-2021-09-00001 ?pretty' -d'&#123; \"aliases\": &#123; \"logs_write\": &#123;&#125; &#125;&#125;' 现在开始设置动态索引创建 这步的意思是，设定logs_write，当天数大于7天，或者文档数量大于100000，或者大小大于5gb，创建一个新的log-2021-09-00002 索引 12345678POST /logs_write/_rollover &#123; \"conditions\": &#123; \"max_age\": \"7d\", \"max_docs\": 100000, \"max_size\": \"5gb\" &#125;&#125; 定时清理过期数据Curator索引管理工具这个工具，可以进行索引管理 安装的方法，网上找RPM包直接安就得了 https://www.elastic.co/guide/en/elasticsearch/client/curator/current/yum-repository.html 它的功能有 关闭索引 创建快照 创建索引 打开索引….. 这里，我们可以通过Curator来进行索引创建，定时配置删除等等 例如我们要动态删除7天前的索引 12345678910111213141516171819202122232425# Remember, leave a key empty if there is no value. None will be a string,# not a Python \"NoneType\"## Also remember that all examples have 'disable_action' set to True. If you# want to use this action as a template, be sure to set this to False after# copying it.actions: 1: action: delete_indices # 这里执行操作类型为删除索引 description: &gt;- Delete metric indices older than 3 days (based on index name), for zou_data-2018-05-01 prefixed indices. Ignore the error if the filter does not result in an actionable list of indices (ignore_empty_list) and exit cleanly. options: ignore_empty_list: True filters: - filtertype: pattern kind: prefix value: logs- # 这里是指匹配前缀为 “order_” 的索引，还可以支持正则匹配等，详见官方文档 - filtertype: age # 这里匹配时间 source: name # 这里根据索引name来匹配，还可以根据字段等，详见官方文档 direction: older timestring: '%Y-%m-%d' # 用于匹配和提取索引或快照名称中的时间戳 unit: days # 这里定义的是days，还有weeks,months等，总时间为unit * unit_count unit_count: 7 以上命令删除了7天前，以log-*开头的索引 可以看下这篇文章 ElasticSearch——Curator索引管理 结尾这些大概就是我实战遇到的一些问题，结合网上的一些资料 我输出了这篇blog 最近我开始疯狂学习，希望未来会有突破吧 狗公司不发年终，淦，还是赶紧找机会跑路，才是最重要的。 大家加油吧！写算法Ing！ 加油！","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"写一个高可用Rpc服务（基础知识篇）","slug":"写一个高可用Rpc服务（基础知识篇）","date":"2021-08-30T10:30:31.000Z","updated":"2021-08-30T10:42:31.856Z","comments":true,"path":"2021/08/30/写一个高可用Rpc服务（基础知识篇）/","link":"","permalink":"https://yemilice.com/2021/08/30/%E5%86%99%E4%B8%80%E4%B8%AA%E9%AB%98%E5%8F%AF%E7%94%A8Rpc%E6%9C%8D%E5%8A%A1%EF%BC%88%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%AF%87%EF%BC%89/","excerpt":"","text":"前言最近实在是太忙啦，每天都加班，这是开博这么久首次，一个月都没UPDATE，my bad，这个月保证日更三篇，补上补上。 久违的freestyle时间，（虽然我现在玩爵士了） 123456789101112131415每天reload存档似乎总会是一样加班就像是吃饭一样平常内心是否总想这样看不见未来的远方迷雾它层层阻挡思绪飞扬总在寂寞的晚上让我来静静的品尝 为什么要写这篇文章首先是因为我自己，最近非常的忙，但是我又在想，我他喵的忙了个什么 汇报一下最近（这一个月）的战果 从无到有编写完成了一个RPC服务，并且开源给全公司的项目使用 完成了一个CEPH多站点数据同步的开发（我在想这玩意到底有什么用） 完成了一个ElasticSearch项目的开发，大概就是优化优化再优化 其实收获最大的还是开发一个RPC Server，当然对于大佬们可能啥也不算 我其实不建议自己造轮子，因为现有已经有很多的Rpc框架可用，而且都非常稳定 但是此次开发，涉及到一些特殊的功能，所以不得不自己造轮子 但是对我很重要，我将这次开发的过程记录下来 并且，将此次RPC代码抹去项目核心，开源至GITHUB当中，希望大家好好利用 爱你们！ RPC服务的基础首先，需要知道什么是RPC，或者RPC到底是干嘛的 这里我将会简单的说明一下，RPC服务的核心 什么是RPC首先，RPC的全名，叫做Remote Procedure Call 大白话来说，就是远程过程调用 更大白话来说，就是A，B两个服务器，我希望在A上控制B进行某些操作，比如 rm -rf（狗头），我们需要一个服务进行交互，这个服务就叫做RPC 所以RPC其实是一种网络通信的框架，基于HTTP，或者TCP，或者什么有的没的，这不重要 RPC不是一种协议，它没那么高深，它是一种工具。 常见的RPC有什么？这个说起来就多了 Golang 有 GRPC，这个我写过文章，可能有个两三篇了吧 使用Golang的gRPC框架的一点随想 学习etcd的消息协议gRPC一点随想 自己个儿去翻一下，哈哈 Java系的，有福报厂的Dubbo 这位更是重量级 还有我曾经用过的Thrift（难用的1B） 一个完整的RPC框架应该包含什么？RPC的核心功能 client端 （调用方） server端 （服务提供方） Network Service （底层协议，HTTP/TCP） 这大概就是一个RPC服务的核心功能，其实简单的理解为 12发送方（client） ---&gt; 中间协议 ---&gt; 接收方（server） 这样就可以表示它们的关系了。一个RPC框架，也需要包含这些功能，无论是简单的，还是复杂的，都要有这些功能。 RPC的功能详解研究了Grpc，还有其他的一些RPC服务，除了上述三个必须功能以外，还有几个加强功能，方便RPC服务续航前进的。 下面将这些功能解说一下，帮助大家打好基础，深入学习 服务端服务端，也就是Server端，这个东西，一般是以一个服务的形式，常驻在后台，等待客户端的调用 这个东西相当于大门，他规定了一些很重要的东西 指定开放的端口 维护一个call id，这个东西映射了一个call id map，call id map是对应的函数指针,这个我后面会说 等待客户端请求 调用本地函数 返回执行结果 server端是常驻在后台的服务，也就是广义上俗称的RPC服务，没了server端，就相当于老虎没牙。 客户端客户端，也就是client端，一般就是发起调用的那一方，和server端是好基友，缺了谁都不行的那种 这个玩意相当于钥匙，告诉你我要调用，我要开门，我要进去那种 将调用的函数/命令 映射为call id 将调用/发送的数据流 传输给 server 端 指定server的端口，密码，鉴权之类的东西 等待执行结果 获取执行结果 client端通常在我们的业务代码中调用，一般就是你写在业务代码里面的部分，client端相当于是钥匙，打开server端大门，执行我们要的操作。 序列化首先，rpc服务是去其他节点执行函数/操作，所以肯定会带有参数 我们有时候要传输参数，所以就要有个固定格式，然后也要有解析格式的步骤 但是A -&gt; B 传输的过程中，传输的参数不在一个内存里，这样就没法进行通讯调用了 从 A 传输参数到 B，需要 A 把参数转换成字节流，传给B 然后B将字节流转换成自身能读取的格式 转换成字节流的步骤就叫序列化 字节流转换成自身能读取的格式被称为反序列化 例如Grpc服务里面有protobuf，这是很典型的序列化操作，这里兄弟们可以自己去看下 我也写过。 学习etcd的消息协议gRPC一点随想 网络传输顾名思义，网络传输，就是通过网络进行消息传递，那么这里肯定有一个网络传输逻辑，术语称为网络传输层 网络传输层的主要工作就是 1把经过序列化/反序列化的字节流传递给服务端/客户端 这里就涉及到网络协议了，一般有什么TCP，UDP，HTTP之类的，基本都是网络的玩意儿 Grpc用了HTTP2协议 一般的RPC都是TCP连接，本次开发的RPC服务我也会用TCP协议，请注意 一个完整的RPC服务的主要流程上一节给铁子们讲了一下RPC主要的功能，这一节就来说说，RPC的主要功能如何联系起来 顺便画几个流程图，更加方便大家学习浏览 这章挺重要的，因为这样类似于我们设计的RPC服务的基础架构 请大家，务必，认真细致的阅读此章 因为免得后面我写代码你啥也看不懂！ 认真阅读！ 认真阅读！ 认真阅读！ 重要的事儿说三遍。 你要不好好读，到时候对不上了，指定没有你好果汁 RPC服务的流程上一节我们详细讲述了RPC服务的四个重要功能 服务端 客户端 序列化/反序列化 网络传输 那么他们之间的联系是什么样的呢？ 首先，我们还是假定我们有两个节点，一个client节点，一个server节点 假设我们现在要在远端执行一个 “Print” 函数 主要目的就是：Client节点请求访问Server节点上的Print函数，并且获取返回的结果 基本的流程如下 client节点，发起调用Print的请求 client节点，找到Print 函数的 call id client节点，序列化调用的参数/call id client节点，根据指定的ip，协议，端口发送字节流到server节点 server节点，接收到client的字节流 server节点，反序列化字节流，拿到id 或者参数 server节点，根据id 去 call map里面寻找函数 server节点，调用print函数 server节点，获取到print函数返回 server节点，序列化返回结果 serve节点，传输返回结果的字节流 client节点，接收返回结果字节流 client节点，反序列化字节流 client节点，输出返回结果 这个大概就是RPC调用函数的具体流程，细化一下，画个图 流程如下 这就是基础的RPC流程 写一个基础的RPC服务上面，我们已经过了一遍RPC服务的流程 下面我们就来写代码，实现一个简单的RPC流程吧 首先给出我的开发环境 Python环境：3.7 使用包：无第三方包 实现功能 121. client传递一个Message给server端2. server端返回传递的Message Server端代码 12345678910111213141516171819202122232425262728293031# coding: utf-8__author__ = 'Yemilice_lau'from xmlrpc.server import SimpleXMLRPCServerclass SimpleRpcServer: # 创建一个指定的rpc 函数 list _rpc_methods_ = ['PrintWork'] def __init__(self, address): # 倒入自有的rpc服务包 self._serv = SimpleXMLRPCServer(address, allow_none=True) for name in self._rpc_methods_: self._serv.register_function(getattr(self, name)) # 主函数 def PrintWork(self, name): print(name) # 持续运行的server def serve_forever(self): self._serv.serve_forever()# Exampleif __name__ == '__main__': print(\"服务开始.....\") # 指定一个端口 7900 kvserv = SimpleRpcServer(('127.0.0.1', 7900)) kvserv.serve_forever() client端代码 12345678910# coding: utf-8__author__ = 'Yemilice_lau'from xmlrpc.client import ServerProxys = ServerProxy('http://localhost:7900', allow_none=True)# 发送一个消息给server端s.PrintWork(\"Good job\") 这下可以调用一下server玩玩 1python rpcserver.py 输出 1服务开始..... 现在执行client 1python rpcclient.py 这时server端返回了 12127.0.0.1 - - [30/Aug/2021 17:13:49] \"POST /RPC2 HTTP/1.1\" 200 -Good job 这样就完成了一个简单的RPC服务流程 一个优秀的RPC服务应该有哪些特点？上面我们简单的实现了一个RPC服务，但是那只是非常非常简单的RPC服务 相当于你想整个高达，但是最后整出来个卡布达，还是人工智障形态的 这部分关系到我们后面章节的开发，还是认真看一下 既然要做，就要做到最好，所以我自己思考了一下 那么到底什么样的RPC服务才能被称为优秀的RPC服务呢？ 根据我这一阵的开发来看，一个优秀的RPC服务，肯定是有如下优点的 速度速度肯定是很重要的 以前我的博客聊过，影响RPC速度有这么几个重要原因 序列化/反序列化部分影响 网络环境影响 server代码影响 首先，序列化，反序列化受传输字节流大小影响，转换比较大的字节流是比较花费时间的 所以Grpc改用了protobuf作为序列化/反序列化的核心，抛弃掉传统的json传输转换，Grpc为什么很快，很大一部分原因来源于protobuf的高效率，所以序列化/反序列化对速度的影响非常重要 网络环境，这个属实是基础逻辑了，你网慢，自然而然返回，发送的就慢，现在基础的有Tcp传输，http传输，需要针对综合性的问题，进行协议选择 server代码，这部分可谈的也很多，例如队列机制，多进程机制，令牌桶一类，都可进行调优。 可用性拿我此次开发来说，我面临的是一个集群（机器数量10+），并且需要支持 Rpc直接支持Python库调用 Rpc直接支持Shell命令调用 Rpc直接支持集群级别的消息发送和返回 这里就直接面对自己造轮子的境地，而且未来还不确定是不是会有跨语言的需求，例如某天突然要支持Golang，Java 这里需要考虑是否跨平台, restful json? http XML? 也需要考虑是否有异步操作，异步通信？同步通信？ 所以Rpc的可用性，需要在此处就进行详细的考虑，免得后续开发造成很大的麻烦。 负载均衡避免单个服务器接收过多的Rpc请求 隐私性涉及到鉴权部分了，这里相对来说比较麻烦 常用的鉴权逻辑有 Public Key鉴权 证书鉴权 网关鉴权 需要根据自己的实际情况进行分析，这边扯这个淡时间就太长了 我这次开发鉴权用的是证书，哥几个心里有数就行。 容错性容错性，这个说起来还是很简单，但是你细分析下就觉得这破玩意是真的挺多 出现错误之后的处理 是否有异常的处理机制 远端和本地数据不一致的问题（一致性问题） 异常事务的回滚机制 首先，一致性问题就够TM头大了，这个原来我写过Raft协议，专门写过这个，这里不再细说 还有异常情况，这里也需要进行细分 网络？ 执行返回结果？ 其他错误？ 发生了异常处理之后，还有 是否重试？ 是否回滚？ 是否抛出？ 这个真的麻烦，这也是我们要考虑的点 暂时结尾ok！兄弟们，全体目光像我看齐，看我看我，我宣布个事儿 咳咳，错了 基础知识篇这就结束了，咱们马上要进入高阶开发篇了！ 这次开发花费时间太长了，我也太累了，最近都没好好学习！ 这样可不行！ 努把力，继续刷算法，努力！哥们！努力! 预告一下下一篇： 高阶开发篇！ 下一篇的主要内容有 实现Rpc队列 实现Rpc直接调用Python库 实现Rpc直接调用shell命令 实现Rpc传输json 实现协程Rpc 爱你们！","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"望江亭(remix)","slug":"望江亭remix","date":"2021-08-20T06:33:17.000Z","updated":"2021-08-24T08:13:40.673Z","comments":true,"path":"2021/08/20/望江亭remix/","link":"","permalink":"https://yemilice.com/2021/08/20/%E6%9C%9B%E6%B1%9F%E4%BA%ADremix/","excerpt":"","text":"望江亭（remix）很喜欢王诗安，一直非常喜欢 listen remix听听就好 歌词后面补 最近忙 结尾我 间歇性写歌 间歇性录歌 不忙的时候会参加比赛 平常在soundcloud发歌多一些 最近加班太多 不想干了 累 此处应有自拍，但是我不想拍，我烦 over","categories":[],"tags":[{"name":"说唱之路","slug":"说唱之路","permalink":"https://yemilice.com/tags/%E8%AF%B4%E5%94%B1%E4%B9%8B%E8%B7%AF/"}],"keywords":[]},{"title":"刷KPI的HR就不要给我发面试邀请了吧","slug":"刷KPI的HR就不要给我发面试邀请了吧","date":"2021-06-23T06:42:49.000Z","updated":"2021-06-24T02:27:04.611Z","comments":true,"path":"2021/06/23/刷KPI的HR就不要给我发面试邀请了吧/","link":"","permalink":"https://yemilice.com/2021/06/23/%E5%88%B7KPI%E7%9A%84HR%E5%B0%B1%E4%B8%8D%E8%A6%81%E7%BB%99%E6%88%91%E5%8F%91%E9%9D%A2%E8%AF%95%E9%82%80%E8%AF%B7%E4%BA%86%E5%90%A7/","excerpt":"","text":"前言去年这个时候面试了一家小公司叫无糖信息，大概是叫这个名字 面试的体验极差，HR从头到尾都是隐形人，我感觉就是不停的刷KPI的，忽悠你去面试 我过去先等了半个小时，那面试官都没来 然后过了一会面试官气冲冲的过来了，搞得好像是我很想来面试似的，是你们找我来的，大哥，不是我没工作一定要来你们公司 面试官全程鼻孔看天，对我做的东西嗤之以鼻，工作四年还用校招的题考我，全程态度极差，我们说话交流不到 10 句，简历一个问题都没问，然后垮着一张脸，问我 go 的问题 第一句，你协程用的多吗 第二句，我看你简历很一般啊 第三句，你的情况我了解了，你可以走了 但我当时也没怼，一个是觉得自己怂，再一个是我和你不一样，我有家庭教养，不像这个面试官一样。 我后面找这个HR说这个事儿，人家也敞亮，诶，就是玩 就是已读，就是不回 行吧，就当被狗咬了呗 当时写了两篇博客 似乎要沉下心来处理一些事 Golang语言的一些基础(针对面向基础的笔/面试) 也间接促进了我沉下心学习和去年的博文爆发 至于我今天为什么又提起这件事呢。。。 是因为那个SB的HR又找我面试同一个岗位，哈哈哈哈哈！ 你他妈不知道去年你干了啥么？ 而且你们一个岗位，一年都没招到人？同一个岗位同一个工资同一个水平呗这不是刷KPI这是什么，还想忽悠我过去挨怼啊？就100人小公司，你招聘有那么需求旺盛吗？ 行啊，你自己送上门，那别怪我喷你 我直接问： 您又想KPI我啊？ 它回了一个： ？ 我直接回答： 当时我去面试，面试官吊炸天气冲冲，我等半小时面试 5 分钟，后面找你们你们也不理，我忘了拉黑你实在是对不起，你们从去年招人到今年还没招到，不是 kpi 是个锤子。 然后直接拉黑删除一条龙，估摸着您组织好语言的时候，看到那个感叹号，心理也会挺那啥吧，我只是把当时的一些感觉还给你罢了。 写这篇文章的目的我本来都要把去年那事儿忘了，但是你把我这思想勾起来，我不聊两句也说不过去对吧。 陆陆续续面试以来，碰到挺多HR都挺那啥的，如果有HR在看这个博客 我就想问你们一个问题，为什么你们要别人（面试者）无论如何给你们回复，但是你们如果不过也从来不给面试者回复呢？ 你们可以辩解，说你们太忙，但是谁的时间不是时间？我遇到了好几个这种HR，还有同一家公司，三四个HR过来找你的，面试不过了也不通知，然后后面又来找你面试的，咋的，你拿我当傻子涮着玩儿是吧？无限循环？这种我一律直接拉黑 我不知道你们怎么看这个问题，无论如何，HR找我我都会礼貌的回复，但是礼貌的回复之后，总是得不到礼貌的回应，难道现在不讲道理才是生活的必要手段？fuck，那你们鼓吹什么绅士风度？要面试的人礼貌，但是你们有礼貌的对待面试的人吗？ 我感觉肯定也有人说，这么屁大点事儿你发什么blog，是，这是我的blog，您要不乐意看您就走人，没求着你啊，再一个，以后自己遇到事儿还是要怼回去，你越讲礼貌，越忍让，别人才会觉得你软弱可欺。 这事儿是不大，但是这是我的态度，我不是求着你找一份工作的，我们是平等的状态，抛开掉HR和面试者的角度，我们还可能成为朋友，或者是好朋友 未来我还可能邀请你来听我们的乐团演出，真的不必要像无糖信息这种公司把我得罪的这么死（忘了告诉大家我现在玩爵士了 结尾首先先锤一下无糖信息，垃圾公司，垃圾面试官，垃圾HR，看到了没，我就骂你，我就在沈阳大街骂你（狗头 先送你一个祝福 顺便我祝你幸福 别杠我，杠我就你对 最后想给看到博客的人说 遇到垃圾公司，直接曝光 遇到垃圾面试官，直接曝光 遇到垃圾HR，骂他就完了 遇到垃圾面试官，直接骂 写算法了，我的理想是最高的那个台阶，大家一起加油！","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"}],"keywords":[]},{"title":"爵士乐和声进行的中心与精华-导音","slug":"爵士乐和声进行的中心与精华-导音","date":"2021-06-23T02:42:01.000Z","updated":"2021-06-23T03:02:37.582Z","comments":true,"path":"2021/06/23/爵士乐和声进行的中心与精华-导音/","link":"","permalink":"https://yemilice.com/2021/06/23/%E7%88%B5%E5%A3%AB%E4%B9%90%E5%92%8C%E5%A3%B0%E8%BF%9B%E8%A1%8C%E7%9A%84%E4%B8%AD%E5%BF%83%E4%B8%8E%E7%B2%BE%E5%8D%8E-%E5%AF%BC%E9%9F%B3/","excerpt":"","text":"什么是导音？What isguide tones? 在爵士乐中，和弦大部分为七和弦，导音主要是指的七和弦的三音或七音。 在一个七和弦中，最能体现和弦色彩的音就是三七音。 三音为稳定音级，七音为不稳定音级，两者决定一个和弦的大，小，属等重要属性。 其次，导音也可以是和弦除三七音之外音，根据旋律及和声进行的需要而定。 也可以把导音理解成在一段和声进行中起承前启后作用的重要旋律音。 比如这首大家熟悉的曲目ALL THE THINGS YOU ARE。 整个A段旋律的主体就是从上一个和弦的三音移动到下一个和弦的三音，这种三音或七音的随着和声进行所产生的旋律线条称之为导音线条。 一般情况下，在standard里有三种导音线条。此曲中，每个画了圈的导音与下一个导音的音程关系为上移4度，再下移五度。这种上下跳进的导音移动模式我们可以把它看作是一种跳进的导音线条。 还有一种流线型的导音线条，比如AUTUMN LEAVES的A段。 从A-7的3音C（稳定），延伸到第二小节D7七音C（紧张） 然后从下方以音阶模式上行解决至Gmaj7三音-B（稳定） 保持B音至Cmaj7第一拍，B音变为Cmaj7七音 再由音阶上行到F#-7b5的三音A 保持到B7变为B7不稳定导音A 最后音阶上行解决到E小的三音G 整个导音线条呈流线型下行趋势—C,C,B,B,A,A,G. 除以上两种导音线条之外，还有一种导音线条随着和声进行保持一个音不变， 所以可以把它看作为一种直线导音线条。 比如这首ONE NOTE SAMBA。 A段的旋律就建立在一个F上。 D-7中F为3音，Db7中F为3音，皆为稳定音级。 在C-7中F为11音，在B7b5中F为b5音，为不稳定音级。 在第五小节解决回D-7稳定音级，三音F，然后循环。 推荐曲目： All The Things You Are Squaresville Something Cool the Way You Look Tonight 结尾最近很久没吹小号了，其实生活真的需要慢下来，但是我真的慢不下来 爵士对于我来说，很像得不到，但是又想得到的东西 其实做说唱的最大原因是简单。。。。（暴露了 好了，爱你们呀！","categories":[],"tags":[{"name":"编曲相关","slug":"编曲相关","permalink":"https://yemilice.com/tags/%E7%BC%96%E6%9B%B2%E7%9B%B8%E5%85%B3/"}],"keywords":[]},{"title":"ElasticSearch-新老选主算法对比","slug":"ElasticSearch-新老选主算法对比","date":"2021-06-16T07:17:06.000Z","updated":"2021-06-16T07:23:38.662Z","comments":true,"path":"2021/06/16/ElasticSearch-新老选主算法对比/","link":"","permalink":"https://yemilice.com/2021/06/16/ElasticSearch-%E6%96%B0%E8%80%81%E9%80%89%E4%B8%BB%E7%AE%97%E6%B3%95%E5%AF%B9%E6%AF%94/","excerpt":"","text":"前言首先，ElasticSearch 7，也就是Es 7， 变动还是有点儿大，改了很多东西，例如取消了type，修改了选主算法之类的操作 正好几天在钻研一些选主算法一类的东西，看了ETCD，rabbitmq，kafka之类的一些选主算法，想起来似乎对于Es，我还没有细致研究 于是产生了写这篇文章的动力，这篇文章，也是一篇新老选主算法的对比文章 大概会描述一下Es的两种选主算法，然后分析一下新老算法的差异 好了，我们开始把。 老样子，一段freestyle 12345678910111213141516黑暗笼罩着我的眼看不清到底是黎明还是黑夜时间依旧不会停歇滴答滴答本质是仅仅如此还是始终如一？我问自己到底想要何物夸父逐日终于大泽之尾停下来的风景似乎更美 老选主算法 Bully算法（在Es7之前的所有版本使用）Bully算法，在ElasticSearch 7.0之前，都是Es的选主算法，在7.0之后被替换。bully，顾名思义，霸道选举，也叫霸道选举算法（自己编的） Bully算法的原理首先，一句话概括： Bully算法的基本原理就是，根据节点的ID大小来判定谁是leader 这个直接点明本质 Bully算法的消息类型Bully算法在选举的时候会发送三种消息类型 选举消息 （Election Message: Sent to announce election.） 应答消息（Answer (Alive) Message: Responds to the Election message.） 选举成功消息 （Coordinator (Victory) Message: Sent by winner of the election to announce victory.） 这三种消息类型组成了Bully的基础消息类型，这也是Bully算法选举必须要了解的东西。请注意。 Bully算法的选举流程还是用最熟悉的《黑社会》电影举例 假设我们现在有node1（大D）, node2（阿乐）, node3（吉米）三个进程，现在开始选主。 node1的进程号比node2，node3都大，他会直接通知node2，node3,发送选举成功（Coordinator Message）消息，如果它的进程ID小于node2，node3，那么他将发送选举消息 （Election Message） 如果发送选举消息没有回应，这时候有两个原因，一个是其他节点的进程ID大于它，另一个是其他节点还在向集群内节点广播选举消息，也就是互相发送选举消息，就类似，大D和阿乐都自认自己是话事人。 如果node2的进程ID大于node1，那么node1就会收到应答消息（Answer (Alive) Message），表明，选举失败，你不是话事人，等待其他节点的选举成功（Coordinator Message）消息 如果node2进程ID小于node1，node1会返回一个应答消息（Answer (Alive) Message），启动选举进程，向更高的进程发送选举消息 （Election Message） 如果node1接受到了node2节点选举成功（Coordinator Message）消息，则说明，node1看node2是master节点。 为了方便阅读，这里有个图将bully算法选举流程列出如下 分步解释 节点1向节点，节点3发送选举，并且带上自己的序号1 节点2，3接收到消息之后，进行序号比较，发觉自己的序号更大，向节点1返回应答消息Answer (Alive) Message，告知节点1被踢出选主序列（大概是这个意思） 节点2向节点3发送选举请求，节点3找不到更高序号的节点发送选举请求了 节点3向节点2返回应答消息，节点3收不到其他节点的应答消息了 节点3被认为是leader，向其他节点发送Coordinator Message，选举成功的请求，将自己是master节点广播到节点1，节点2 Bully算法在ElasticSearch中如何运用（如何选出es的Master）上面我已经把bully算法如何选举详细的说了，聪明的你应该明白了吧？ 要不明白可以给我发邮件或者留言 下面说一下Es里面，bully如何选举出master的 首先看一下基础步骤，这里很可能会贴出java源码，看不懂的我也米办法了，凑合看 找到活动的active node可以选举的节点，这个是在配置文件 elasticsearch.yml 里面的 discovery.zen.ping.unicast.hosts 定义的 首先Es的Java实例会去直接调用ping逻辑检查可用的节点 12345678List&lt;DiscoveryNode&gt; activeMasters = new ArrayList&lt;&gt;(); for (ZenPing.PingResponse pingResponse : pingResponses) &#123; // We can't include the local node in pingMasters list, otherwise we may up electing ourselves without // any check / verifications from other nodes in ZenDiscover#innerJoinCluster() if (pingResponse.master() != null &amp;&amp; !localNode.equals(pingResponse.master())) &#123; activeMasters.add(pingResponse.master()); &#125; &#125; 这里会直接去ping 那些节点，然后把除本节点以外的，能ping通的，可用的，正在活动的节点加入到activeMasters这一个链表里面 找到可以成为master的node1234567// nodes discovered during pinging List&lt;ElectMasterService.MasterCandidate&gt; masterCandidates = new ArrayList&lt;&gt;(); for (ZenPing.PingResponse pingResponse : pingResponses) &#123; if (pingResponse.node().isMasterNode()) &#123; masterCandidates.add(new ElectMasterService.MasterCandidate(pingResponse.node(), pingResponse.getClusterStateVersion())); &#125; &#125; 这里是将所有的可以选举的节点（包括本节点），加入到了一个新的masterCandidates链表里面 Bully算法选举看下代码 如果刚才的那个活动选举的链表activeMasters为空，也就是说不存在活着的master节点，然后再去再去配置文件里面elasticsearch.yml，有个重要属性，discovery.zen.minimum_master_nodes，这代表着最小选举节点，当activeMasters为空，并且minimum_master_nodes &gt; masterCandidates，满足匹配数量，直接走bully的选举，选举出最小ID的节点成为master节点。 12345678910111213141516if (activeMasters.isEmpty()) &#123; if (electMaster.hasEnoughCandidates(masterCandidates)) &#123; final ElectMasterService.MasterCandidate winner = electMaster.electMaster(masterCandidates); logger.trace(\"candidate &#123;&#125; won election\", winner); return winner.getNode(); &#125; else &#123; // if we don't have enough master nodes, we bail, because there are not enough master to elect from logger.warn(\"not enough master nodes discovered during pinging (found [&#123;&#125;], but needed [&#123;&#125;]), pinging again\", masterCandidates, electMaster.minimumMasterNodes()); return null; &#125; &#125; else &#123; assert !activeMasters.contains(localNode) : \"local node should never be elected as master when other nodes indicate an active master\"; // lets tie break between discovered nodes return electMaster.tieBreakActiveMasters(activeMasters); &#125; Bully算法的优点其实Bully算法，简单粗暴，好处就是简单 并且算法的难度低啊，怪不得Es最初几个版本要用它，简单就完事儿了 而且bully的选举速度很快，相互通知，比对大小，就得了，所以我想这就是es最初几版用它的原因吧。 Bully算法的缺点缺点的话。。。我感觉bully算法相比于其他主流算法，相对来说简单一些 但是简单很可能就是一种原罪 当有节点频繁加入或者退出的时候，主节点会频繁的进行切换，保存的节点信息的元数据也就会越来越大，越来越大 所以Bully算法的缺点，从我的角度上来看的话，也就是无法满足复杂场景下的选主需求，因为复杂场景下的选主，需要强力的选主算法支撑 因为主节点，能力越大，责任越大！必须保持稳定！包租婆，你说是吧！ 为什么要替换Bully算法Es7 版本算是大改，不仅改了选主算法，连type都删了，这算是一个大变动，我记得很多人的Es都是5，或者6 我查询了一些资料，发觉在Es官方的文章上说明了为什么替换的原因 123456789101112131415161718192021Elasticsearch 6.x 及之前的版本使用了一个叫作 Zen Discovery 的集群协调子系统。这个子系统经过多年的发展，成功地为大大小小的集群提供支持。然而，我们想做出一些改进，这需要对它的工作方式作出一些根本性的修改。Zen Discovery 允许用户通过设置 discovery.zen.minimum_master_nodes 来决定多少个符合主节点条件的节点可以形成仲裁。在每个节点上一定要正确地配置这个参数，如果集群进行动态扩展，也需要正确地更新它，这一点非常重要。系统不可能检测到用户是否错误配置了这个参数，而且在实践当中，在添加或删除节点之后很容易忘记调整这个参数。Zen Discovery 试图通过在每次主节点选举过程中等待几秒来防止出现这种错误配置。这意味着，如果所选的主节点失败，在选择替代节点之前，集群至少在几秒钟内是不可用的。如果集群无法选举出一个主节点，有时候很难知道是为什么。 这个翻译太蹩脚了，我来直接简单扼要的说明一下为什么要替换吧 老版本里面有个discovery.zen.minimum_master_nodes，这个很重要，但是动态扩展的时候有些时候可能会忘记设置这个东西 如果不设置这个东西，Zen Discovery会在每次选举过程中等待一阵，大概是几秒时间来防止这种错误配置，这就造成集群暂时不可用 也有可能造成无法选主的问题，这个非常致命，所以我们要换这套算法。 新选主算法 类Raft算法（Es7之后更新）接上节，那么，Es不用Bully之后，到底要用什么呢？ 官方给的文章也说明了这个问题 12345678910我们重新设计并重建了 Elasticsearch 7.0 的集群协调子系统：1. 移除 minimum_master_nodes 参数，让 Elasticsearch 自己选择可以形成仲裁的节点。2. 典型的主节点选举现在只需要很短的时间就可以完成。3. 集群的伸缩变得更安全、更容易，并且可能造成丢失数据的系统配置选项更少了。4. 节点更清楚地记录它们的状态，有助于诊断为什么它们不能加入集群或为什么无法选举出主节点 这边说的很清楚，原有的Zen Discovery被替换了，不再使用 那么新版采用的算法是什么呢？ 这个在官方文档里也有 12345678我们经常被问到的一个问题是，为什么不简单地“插入”像 Raft 一样的标准分布式共识算法。有很多公认的算法，每种算法都有不同的利弊权衡。我们仔细评估了所有可以找到的文献，并从中汲取灵感。在我们早期的概念验证中，有一个概念便使用了非常接近 Raft 的协议。 所以，我将Es7的选主算法命名为类Raft算法，也就是类似Raft的算法。但是不是完全是Raft算法，这个我会在后面详细说明。 Raft算法的原理首先Es的选主算法基础是来源于Raft，还是有必要分析下Raft算法的机制和原理 才有助于后期对Es 7 的核心源码进行解读分析 什么是Raft算法？这个又涉及到了一致性问题，这是分布式系统的一个老调常谈的部分 首先，Raft算法是用来解决分布式一致性问题，而编写出来的一种算法。 Raft算法是如何工作的？在Raft算法中，一个节点分别可能有三种角色 Follower 跟随者 Candidate 候选人 Leader 领导者 当初始化的时候，所有的节点都是Follower跟随者 此时此刻，如果没有收到leader的消息，那么节点将会自动转换为Candidate候选人的身份 这时，成为候选人的节点，将向其他节点发送选举投票请求 这时，接收到信号的节点，将会回复这次投票请求 如果大多数节点都赞成选举这个节点为leader，那么这个节点将会成为集群leader节点 这就是领导者选举的步骤，通俗来讲，也就是选主步骤，这也是我今天要讲的核心。 这里我画了个图，将步骤完全简化，大家，凑合看下吧，聪明的你，一定一看就懂！ 开始选举的条件是： 当follower节点接收不到leader节点的心跳 leader节点超时 但是要注意，当follower节点收不到leader节点心跳的时候，需要等待一点时间切换为Candidate候选人，才可以开始选举。 看下图吧，大概，也许差不离，就是这么选举。 类Raft算法在ElasticSearch中如何运用大概知道了Raft算法的选举原理，那么在Es里面，如何使用新的算法去选举leader呢？ 这里就需要追一下源码了，下面又到了追源码的路子了，大家要看不了的话，真没办法了！ 首先，ElasticSearch的选举算法套了Raft的壳子，但是不是真的Raft逻辑 相比于Raft算法，Es的选主算法有如下不同 初始为 Candidate状态 允许多次投票，也就是每个有投票资格的节点可以投多票 候选人可以有投票的机会 可能会产生多个主节点 举例来说，如果node1，node2，node3进行选主 如果node1当选leader，但是node2发来了投票要求，那么node1无条件退出leader状态，node2选为主节点，但是node3也发来了投票要求，那么node2退出leader状态，node3当选主节点。 说明白了，就是保证最后当选的leader为主leader 那么，综上所述，选举的流程为 节点的初始状态，为Candidate，当加入集群的时候，如果我们的discovery发现集群已经存在 leader，那么新加入的节点自动转换为follower。 类似下图： 假设Candidate开始，那么节点收到足够的投票数量，转换为leader，假设其他节点发送了拉票请求，此节点辞去leader，转换为Candidate，直到选出leader，转换为follower。 角色转变类似这张图： 类Raft算法的优点这个资料上面有，我就直接说了 免去了 Zen Discovery 的 discovery.zen.minimum_master_nodes 配置，es 会自己选择可以形成仲裁的节点，用户只需配置一个初始 master 节点列表即可。也即集群扩容或缩容的过程中，不要再担心遗漏或配错 discovery.zen.minimum_master_nodes 配置 新版 Leader 选举速度极大快于旧版。在旧版 Zen Discovery 中，每个节点都需要先通过 3 轮的 ZenPing 才能完成节点发现和 Leader 选举，而新版的算法通常只需要在 100ms 以内 修复了 Zen Discovery 下的疑难问题，如重复的网络分区可能导致群集状态更新丢失问题 类Raft算法的缺点 节点多的情况下，会造成重复选主多次，选主缓慢 暂时缺少资料支撑，只有些英文的。并且还TM不全。。回头补上。 其他Raft算法的实现（哪些知名项目也使用了Raft）这个就有话说了 除开我研究过一阵的ETCD，ETCD是把Raft协议用到核心层的分布式数据库 这个我原来写过文章 学习etcd核心机制Raft协议的一点随想 可以自己去翻一下。 还有kafka kafka原有的一致性算法是Zookeeper提供的ZAB协议，但是2.8被替换成了Raft，说明Zookeeper已经被抛弃了，Raft的一些机制的确是好于ZAB 当然也有RocketMQ，内部核心来源于dledger源码，也是基于Raft的。 总结草草写完，过于浅显，入个门也够了，也作为我自己的笔记 希望有大佬看见，能给予指点，这次借鉴了张超老师的很多博客，包括他写的Es源码解析这本书，对我的帮助非常非常大！感谢您！张超老师！ 6月第一篇blog，我还在不断努力，你们呢？ 希望自己，努力的这段时间，会有好的结果，希望自己可以换个好点的工作。希望大家也是！看到博客的人，爱你们！ 123456789101112131415161718踌躇不前，总是妄想能一步登天登上山峰发觉我依旧在山脚前沿抬目望眼所见皆是虚无贪念停或走？或是将生活翻面直面内心懦弱的另一边。 参考文章 深入理解 Elasticsearch 7.x 新的集群协调层Elasticsearch 新版选主流程","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"ElasticSearch检索的核心-倒排索引解读","slug":"ElasticSearch检索的核心-倒排索引解读","date":"2021-05-14T07:09:41.000Z","updated":"2021-05-14T07:44:00.223Z","comments":true,"path":"2021/05/14/ElasticSearch检索的核心-倒排索引解读/","link":"","permalink":"https://yemilice.com/2021/05/14/ElasticSearch%E6%A3%80%E7%B4%A2%E7%9A%84%E6%A0%B8%E5%BF%83-%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E8%A7%A3%E8%AF%BB/","excerpt":"","text":"前言ElasticSearch为什么适合做检索服务器？ 因为快啊，大佬！ 为什么快啊？ 因为倒排索引啊！ 什么是倒排索引？ 这个，就要细细分析一下了，这篇文章可能写的不是那么全，但是我也会尽量总结所有重点！希望能帮到大家，爱你们！ 索引是什么？首先，从基础玩起来，倒排索引，分为倒排+索引 索引这个词汇，在数据库的出镜率非常高，我基础比较差，所以，我在这里会从头进行学习解读，希望大家理解，如果对索引非常了解的兄弟，请直接跳过这一段 首先，什么是索引。 索引是一种特殊的数据库数据结构 首先，一般我们认为的查找，就是从头检索到尾，也就是从开头遍历到结尾，这样的时间复杂度是O(n) 索引，就是将数据库表中的某一列或几列以特定的数据结构存起来，比如B-Tree，Hash等，这样我们去查找的时候，复杂度就会下降到O(log)或者O(1) 把索引想成目录，把数据库想成书的内容。所以索引的核心作用就是加快数据的检索和查询速度。 上面那句话我感觉就是说了和没说一样。。你用目录来找内容肯定比一页页遍历翻书快多了，下面咱们就该走一下索引的原理了，睁大眼睛，我们走起。 索引的原理首先，上面说了，索引是一种数据结构，这种结构很可能是B-Tree，Hash等等 一般的数据库索引数据结构基本都是Tree，Tree这个东西，涉及一种叫做平衡多叉树的数据结构 也有一些数据库索引使用hash桶做数据结构，但大部分都是Tree 平衡多叉树就是b-tree，b+ tree的核心，这玩意儿就是搞查询用的 平衡多叉树的基本原理 这不是二叉结构，有一种树叫做平衡二叉树，多叉和二叉是不同的玩意。 B树和B+树的核心都是平衡多叉树 所有节点关键字是按递增次序排列，并遵循左小右大原则 树中每个节点最多含有m个节点（m&gt;=2） 这样似乎有点抽象。。。不过这个只是理论 后面我单独开贴来说一下B树,B+树系列吧 常规的索引数据结构如下 这篇文章不是讲B树，hash的，所以我就直接进入正题了，直接讲ElasticSearch。 ElasticSearch的倒排索引是什么？上面说了，索引相当于是目录，是查询内容的指向标一类的东西 那么，倒排索引又是什么？和一般的索引有什么不一样的嘛？ 现在我来和大家一起复习一下。 首先索引的机制我已经简单的介绍了，是一种数据库中使用的数据结构。 一般是B树，hash之类的。 但是ElasticSearch用的既不是B树也不是hash，用的是倒排索引 ElasticSearch的核心就是搜索，所做的一切都是为了提高搜索的效率 ElasticSearch是一个非关系型的数据库，和Mysql之类的关系型数据库有本质区别。 所以用的索引技术也不相同 倒排索引，就是为了方便检索的一种数据结构 倒排索引检索 VS 传统检索如果我们在关系型数据库中，例如Mysql中进行查找，我们只能用like来实现模糊检索 例如，我们现在要检索一篇含有 “Ak47” 的文章，需要编写如下sql语句 1select * from article where content like '%Ak47%'; 这样的查找，我们是没法使用索引的，因为我们需要进行全扫描，你不可能将整个文章内容都作为索引 这样检索效率很差，也没法完成复杂性检索。 更别提复杂的全文检索了，所以，mysql不适合用来做检索引擎。 更多情况下，很多数据库是以一个主键，作为每个文档的唯一标识 例如传统索引下 文档ID content 1 Ak47突击步枪 2 Ak74u突击步枪 3 Ak74s突击步枪 4 Akm突击步枪 倒排索引就不一样了，他是以单词作为索引，然后将对应的文档id和索引进行关联，类似链表，然后生成倒排索引结构 word 文档ID Ak 1,2,3,4 Ak47 1 Ak74 2,3 Akm 4 突击 1,2,3,4 步枪 1,2,3,4 突击步枪 1,2,3,4 所以，检索的时候只要去通过词汇，直接就能找到匹配的文档 相当于，假设你要搜索 “Ak47”，直接根据word去找匹配的词汇，然后取到文档ID就行了。 这个不就很快？所以倒排索引的好处就体现出来了。 所以倒排 Vs 传统，倒排完胜。 词汇的形成是通过分词进行切分的，分词的核心在这里就不做讨论了，如果想看，可以看下我以前的一篇blog 中文分词的算法分析 倒排索引的数据结构ElasticSearch的核心首先是 Apache Lucene，而倒排索引也是出自Lucene的特殊的数据结构 首先我们看上一节，倒排索引其实可以用一个字典逻辑来表达 12345&#123; \"Ak\":[1,2,3,4], \"AK47\":[1], \"Ak74\":[2,3]&#125; 这个字典里面的key值是分词后的单词，对应的value是文档的ID 根据Lucene的概念，这个key值被称为 Term 如果要进行检索，我们通过term去找对应的值 一般如果文档数量很大，那么对应的term表也一样很大，全都放到内存会出事的，所以，Lucene定义了一个索引，叫做 Term Index，汉语词典索引 一般我们不能把所有的Term表都放到内存里，所以这个是指向第二层索引表指路牌 第二层，全称 Term Dictionary，汉语叫做索引表 根据lucene的概念，这个value值被称为 Postings List，汉语被称为倒排表。 记录表不仅仅只是一个文档ID的list，不要被我的简写搞混淆了，记录表里面包含了大概如下信息 字段 字段功能 文档ID 包含单词的所有文档唯一id 词频（TF） 记录 Term 在每篇文档中出现的次数，用于评分 位置（Position） 记录 Term 在每篇文档中的分词位置（多个），用于做词语搜索 偏移（Offset) 记录 Term 在每篇文档的开始和结束位置，用于高亮显示 看个图 这是他们三者之间的关系 这就是倒排索引的大概数据结构。 Term Index解析Trem Index, 走检索的时候，这个相当于是入口，也就是目录。 通过Terms Index能够快速地在Terms Dictionary中找到你的想要的Term。 存储模式Terms Dictionary 存储 Term 的索引文件叫做 Terms Index，存储的格式是 .tip 数据结构Term Index是由多个FST组成的，FST这个东西展开说太多了，咱们这篇文章不太够，所以我这里就简单描述下，后面再开团讲这个。 Trem Index里面主要包含 字段 字段功能 header header头 IndexStartFP 当前的FSTIndex信息的起始位置 FSIndex 起始位置索引，FST算法存储 它的数据结构如下： Trem Index的结构是Burst-Trie实现的，这里面主要包含了Term的一些前缀 它的结构类似 这里简单的画了个图，您就凑合看吧 当然也有复杂的，类似这样 当然这里不可能是包含所有的term，这里和mysql之类的索引是不一样的，这里存的只是term的前缀。 所以，当我们搜索”Ak47”的时候，这里面大概率会存储着”A”的前缀，找到A之后再去匹配Term Dictionary Term Dictionary解析Term Dictionary 存储了所有的Term值 如果用精准一点的描述，Term Dictionary存储了Term和对应的Postings List指针。 存储模式Terms Dictionary 的文件存储格式为 .tim，存储了Term和对应的Postings List指针。 数据结构先看个图 tim主要包含了如下字段 这里面，Nodeblock是核心，先看这张图，Nodeblock其实类似一个树 Terms Dictionary 通过 .tim 后缀文件存储， 其内部采用 NodeBlock 对 Term 进行压缩前缀存储， 处理过程会将相同前缀的的 Term 压缩为一个 NodeBlock， NodeBlock 会存储公共前缀，然后将每个 Term 的后缀以及对应 Term 的 Posting 关联信息处理为一个 Entry 保存到 Block Entry是一个关联的信息，一般记作元数据 Block可以互相包含，因为前缀很可能相同 具体流程类似： Postings List解析Postings List就是前面我们说的，包含文档ID，文档位置，词频等信息，这些数据相互独立，并且在Postings List中也有这样的表现 存储模式Postings List 被拆成三个文件存储： .doc后缀文件：记录 Postings 的 docId 信息和 Term 的词频 .pay后缀文件：记录 Payload 信息和偏移量信息 .pos后缀文件：记录位置信息 数据结构这三个文件是做查询使用的，所以用的最多的应该.doc文件 我这里举一个.doc的数据结构的例子，进行分析 .doc文件里存储了Term的文档对应的ID，.doc的数据结构如下 TermFreqs 存储文档号和对应的词频 SkipData是搜索的时候判断对应的文档ID在不在一个交集当中，进行跳表的 倒排索引的查询逻辑首先接着上面那个数据结构，我们把数据结构连接起来，看一下下面的图。 通过Term index，这里面记录着前缀 通过前缀快速定位到Term dictionary的offset 通过offset定位到Postings List 这就是大概的倒排索引查询逻辑，这里面较为抽象，但是将基本的查询步骤都刻画出来了。 结尾这篇文章，我感觉写的不好，我预计，我后序还是会修修补补，大家看到了，如果我有错误，马上指出来！ 最近学习进入了一个新的阶段，希望我自己能打通任督二脉，希望我可以做到吧。 1234567891011太多的感谢说不出口我知道是你们在我的背后不断鞭策信念不会随时间陈旧停不下执笔的手踌躇茫然也只是短暂停留 最后感谢一些文章的作者，你们帮了我很多 tim&amp;&amp;tip文件Lucene 倒排索引原理Elasticsearch索引原理","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"为什么要使用消息队列服务","slug":"为什么要使用消息队列服务","date":"2021-05-08T01:48:28.000Z","updated":"2021-05-08T02:03:51.925Z","comments":true,"path":"2021/05/08/为什么要使用消息队列服务/","link":"","permalink":"https://yemilice.com/2021/05/08/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BD%BF%E7%94%A8%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"消息队列是什么？化繁为简一下，分拆一下这个词汇，首先，先来看队列（queue） 队列是一种常用的数据结构，特点是先进先出 消息队列，顾名思义一下，就是把消息放在队列当中进行处理 这个消息，肯定是等待处理的消息，我们应该要获取消息做什么事 比如获取一个返回结果，接受一个参数等等。 所以这里引出了新的概念，消费者和生产者 生产者就是往队列里面塞数据 消费者就是往队列里面取数据 这就是消息队列的基础概念。 消息队列解决了什么问题按理说，消息队列只是一个队列类数据结构，这个我们完全可以自己实现 例如Python的队列queue，或者java的Deque都可以实现队列的功能 再去实现一个消费者／生产者逻辑就好了，那为什么要用消息队列呢？ 这边举几个我开发中遇见的例子 异步拿初始化服务来说，初始化服务的步骤如下 1初始化开始 --&gt; 服务A初始化 --&gt; 服务B初始化 --&gt; 服务C初始化 --&gt; 返回成功 来看个图，大概类似这样。 初始化的流程类似是一个链表，一走到底，这样你让人家客户等很久，客户心理也不开心啊，不能这么搞，所以得想个好办法处理一下。 如果有了消息队列，我们就可以把这个处理方法优化一下 如图所示 现在我们利用了消息队列作为中间件，当传入ip给消息队列之后，可以直接返回一个初始化进行中的状态，立马返回，减少等待。 各个服务会自己去消息队列中获取ip进行操作，这样就避免了一步步调用造成的时间浪费，这里就将整个流程异步化。 这是消息队列的第一个好处。 解耦/复用解耦，这个翻译一下，说人话就是，解除相互的依赖，让大家能独立运行。 还是老样子，举个例子。 现在我们有一个处理订单的程序 主要的功能有获取订单，订单入库，订单校验，费用计算，记录日志等 这个画个图，流程如下 现在可以看出，订单入库，订单校验，费用计算，日志记录这几个功能都依赖订单处理这个模块 写一个伪代码来看的话 1234567891011121314//Order_process 订单处理 func Order_process() &#123; //获取订单的函数 Order, _ := GetOrder() // 获取到订单去做几个功能 // 订单入库 _ := OrderStorage(Order) // 订单校验 _ := OrderVer(Order) // 订单金额 _ := OrderAmount(Order) // 日志 - := OrderLog(Order)&#125; 现在只有四个功能，如果后序功能越来越多，那么Order_process这个函数也会越来越长，并且每次都要重新编译主函数，这个是非常不可取的。 假设我们现在用了消息队列，它的流程就变成了这样 首先，订单处理模块，解除了其他四个功能对它的依赖，只将订单传输进消息队列当中 其他几个功能模块要做的就是去消息队列中获取订单，分别处理就好了 这样我们的伪代码就变成了 1234567//Order_process 订单处理 func Order_process() &#123; //获取订单的函数 Order, _ := GetOrder() // 订单入消息队列 mq.put(Order)&#125; 完全破处了其他几个功能模块的依赖，如果未来需要进行功能添加，只需要单独开发，并且订阅mq队列就可以。 也降低了维护成本，处理问题也针对到模块本身，减少了排错占用的人力成本。 这是消息队列的第二个好处。 削峰/限流说人话就是，当访问量激增，咱们的数据库或者是服务顶不住的时候，先往消息队列里面写，等着后面数据库/服务根据自身设置，从消息队列里面取数据消费。 这个其实说起来比较简单，画个图吧（突然发觉我已经不讨厌画图了 现在有个大批量的访问来了，直接去访问服务A，服务A假设上限是1000，结果你访问量是10000，好了，直接凉凉 现在加上消息队列，访问先存放到消息队列里面，然后服务A直接去消息队列取1000条出来先消费了，然后继续从队列里面取就行了，避免服务直接挂掉。 不过这不是缓存嘛？？？？ 我寻思redis好像也是干这个的。。。。不过的确还是有不一样的地方，我在下面的会详细说下。 为什么要选择消息队列中间件？这个其实是我曾经一直思考过的一个问题 首先 在Python里，我们有collections 的 queue 在Java里，我们有JDK 的 Deque 在Golang里，我们有slice作为简单队列 我们还可以多线程，多进行处理一些问题。 如果只是为了实现一些功能，我们甚至可以用redis这个更简单的玩意儿。 那么，为什么我们还是要选择例如rabbitmq，rocketmq，kafka这类做消息队列服务呢？ 下面我将从我自己收集到的一些信息，总结一些自己的感悟，希望可以帮助大家。 持久化首先，持久化就可以把前面说的那几种干死一大片 对，你可以用queue实现一个队列，但是万一断电了，你队列里面的消息不就没了吗？ 对，你也可以往硬盘里写，你甚至可以另写一个定时同步的脚本去做这件事 但是。。。这不麻烦吗。。 万一你是分布式的，你存一份同步一份，妈耶，那工作量。 类似redis这种，可以把数据存在磁盘上。同理，消息队列的数据也是要存起来的。这样才可以减少意外情况带来的损失。 所以，你要自己写的话，简单的队列还是可以滴，但是消息队列嘛，免了。 高可用用消息队列的都是他娘的分布式服务，如果你是个自己写的单机的消息队列，你这台机器挂了，岂不是消息队列服务就没了？ 像rabbitmq这种，带着主从模式的，可以保证多少个节点down掉之后，消息服务依旧可用 一般的内存消息队列可没有这个功能哈，you know？ Redis Vs 消息队列上面两个还是比较好理解，完全排除了那些内存数据库，也就是断了你自己写消息队列的这条心 因为你的多线程，多进程，queue，deque，永远都是单节点内存队列 但是有个特殊的玩意儿，Redis 上面我说过了，其实削峰的功能，还挺像Redis的，因为Redis也有这个功能，而且用的人还不少。 在互联网，大家都把这个叫做Redis缓存。 Redis其实可以覆盖很多消息队列的功能，但是！它终究有些功能是做不到的，下面我还是来详细讲一下redis和消息队列的对比不同吧。 首先，Redis也可以做消息队列 这个毋庸置疑，并且Redis的消息队列实现起来还挺简单的。 老版本的Redis，功能需求不多的，直接可以上 Redis Pub/Sub 如果Redis的版本大于5.0, 可以直接上Redis Stream，这个就是Redis专门用来做消息队列的实现方案。 Redis Stream的概念如下 12345Redis Stream 提供了消息的持久化和主备复制功能可以让任何客户端访问任何时刻的数据并且能记住每一个客户端的访问位置，还能保证消息不丢失 既然，Redis已经这么厉害了，那为什么还要用消息队列的中间件呢，例如rabbitmq，rocketmq 其实Redis和消息队列中间件还是有区别的，下面我把我总结的几个点拿出来，给大家讲讲 Redis的机制，本来就是做缓存的 Redis严格上来讲是一个内存数据库 Redis如果pop任务从队列出去，失败了不会回到队列重试，需要手动重新push Redis自己本身有一个基于Redis源码的消息队列disque 一般的消息队列中间件都有持久化设置，Redis需要手动设置 一般的消息队列中间件处理之后可以手动ack，也可以自动ack 以rabbitmq为例，如果rabbitmq没有收到ack，会将消息放回消息队列进行处理，保证消息不丢失 一般的消息队列中间件具有更完善的MQ机制。 消息队列在项目上的使用一般什么情况下才会用消息队列呢，这个问题我也反复问过我自己，下面我就从我自己做过的几个项目来分析一下一般什么情况才会上消息队列吧，可能并不完善，不过胜在都是自己的经验，也算有一点点可取之处吧。 需要异步的情况下这种情况我在上面的章节举过例子，但是我举一个我开发的项目的例子吧，这样更加直观。 我开发了一个文件同步系统，类似百度网盘，需要从远端下载文件到本地，并且要对每个文件的同步结果进行日志记录。 分析一下，我的大概步骤就是 1获取文件 -&gt; 文件传输 -&gt; 下发文件 -&gt; 同步文件 -&gt; 记录状态 -&gt; 结束同步 -&gt; 日志记录 可以看到，这是一个很长的步骤，并且可以通过异步逻辑去改装这个步骤 所以这里调用了消息队列做异步服务 修改过的服务步骤如下 123 Rabbitmq服务 —————————————————————————————— 获取文件 -&gt; |文件传输 -&gt; 下发文件 -&gt; 同步文件| -&gt; 记录状态 -&gt; 结束同步 -&gt; 日志记录 首先，从获取文件开始，后面的任务状态直接修改为“待同步”，等rabbitmq服务跑外内部的步骤，再去修改服务状态，然后结束同步，记录日志。 这样做就可以减少业务在前端的等待时间。 这样就是我的大概想法。 微服务的架构下公司的微服务架构我参与了设计，其实主要的核心就是解耦，这个我上面也说过了 主要的核心就是降低每个业务之间的互相依赖，比如A依赖B，B依赖C，这样如果A丢失或者挂掉，那么B，C都会一起完蛋，这是高可用的系统中非常不可取的。 所以，消息队列中间件，起到一个链接各方，传递消息的作用，以前是互相依赖传递消息，现在是用电话（消息队列）去传递消息，并且只用记住电话号码（订阅的消息队列）就可以了。 实时性要求不高的情况下以rabbitmq为例，rabbitmq在上传消息到队列的时候是有一些延迟的，并不是实时操作的 而且rabbitmq还有ack机制消费者获取消息之后才会ack通知消息队列，如果没有ack通知，消息会重新放入消息队列，再次等待消费 所以消息队列，例如rabbitmq，kafka等，都不是实时的，如果需要追求实时性操作，你需要redis。 几种常见的消息队列盘点这里直接上个图，这个图的原地址是 https://zhuanlan.zhihu.com/p/60288391 感谢您！您的图让我醍醐灌顶！ 并且将消息队列优缺点总结如下 ActiveMQ优点 单机吞吐量：万级 topic数量都吞吐量的影响： 时效性：ms级 可用性：高，基于主从架构实现高可用性 消息可靠性：有较低的概率丢失数据 功能支持：MQ领域的功能极其完备缺点 ActiveMQ 5.x维护越来越少，较少在大规模吞吐的场景中使用。 Kafka号称大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开Kafka，这款为大数据而生的消息中间件，以其百万级TPS的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。 Apache Kafka它最初由LinkedIn公司基于独特的设计实现为一个分布式的提交日志系统( a distributed commit log)，之后成为Apache项目的一部分。 目前已经被LinkedIn，Uber, Twitter, Netflix等大公司所采纳。 优点 性能卓越，单机写入TPS约在百万条/秒，最大的优点，就是吞吐量高。 时效性：ms级 可用性：非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消费者采用Pull方式获取消息, 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次 有优秀的第三方Kafka Web管理界面Kafka-Manager 在日志领域比较成熟，被多家公司和多个开源项目使用 功能支持：功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用 缺点 Kafka单机超过64个队列/分区，Load会发生明显的飙高现象，队列越多，load越高，发送消息响应时间变长 使用短轮询方式，实时性取决于轮询间隔时间 消费失败不支持重试 支持消息顺序，但是一台代理宕机后，就会产生消息乱序 社区更新较慢 RabbitMQRabbitMQ 2007年发布，是一个在AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。 优点 由于erlang语言的特性，mq 性能较好，高并发； 吞吐量到万级，MQ功能比较完备 健壮、稳定、易用、跨平台、支持多种语言、文档齐全 开源提供的管理界面非常棒，用起来很好用 社区活跃度高 缺点： erlang开发，很难去看懂源码，基本职能依赖于开源社区的快速维护和修复bug，不利于做二次开发和维护。 RabbitMQ吞吐量相比其他消息队列低 需要学习比较复杂的接口和协议，学习和维护成本较高。 性能差，每秒只能处理几万到十几万 消息堆积的时候，性能会马上下降 RocketMQRocketMQ阿里的开源，用Java语言实现，在设计时参考了Kafka，并做出了自己的一些改进。 RocketMQ在阿里集团被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog分发等场景。 优点 单机吞吐量：十万级 可用性：非常高，分布式架构 消息可靠性：经过参数优化配置，消息可以做到0丢失 功能支持：MQ功能较为完善，还是分布式的，扩展性好 支持10亿级别的消息堆积，不会因为堆积导致性能下降 源码是java，可以自己阅读源码，定制MQ 缺点 支持的客户端语言不多，目前是java及c++，其中c++不成熟 社区活跃度一般 没有在 mq 核心中去实现JMS等接口，迁移需要修改大量代码 选择消息队列的建议如果你的只是轻量级使用mq消息队列 数据量可能每秒10W以下，对于持久化要求不高 上Redis 如果你只是轻量级使用mq消息队列 数据量10w以下，需要一定的持久化操作 上Rabbitmq 如果你是互联网业务，并且数据量时高时低，高的时候特别高，低的时候几乎没有（好像都是这样。。） 你要求数据不能丢失 你要求分布式 你要求高吞吐 上kafka 结尾差不多就这样些，作为5月第一篇blog，我要加油！大家也要加油！ 我们一起刷题，一起离开！","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"弄懂难缠的DFS算法和相关变种(Python实现)","slug":"弄懂难缠的DFS算法和相关变种-Python实现","date":"2021-04-28T09:21:07.000Z","updated":"2021-04-28T09:36:57.711Z","comments":true,"path":"2021/04/28/弄懂难缠的DFS算法和相关变种-Python实现/","link":"","permalink":"https://yemilice.com/2021/04/28/%E5%BC%84%E6%87%82%E9%9A%BE%E7%BC%A0%E7%9A%84DFS%E7%AE%97%E6%B3%95%E5%92%8C%E7%9B%B8%E5%85%B3%E5%8F%98%E7%A7%8D-Python%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"前言这次不废话，直接接上次的BFS，直接来看DFS。 什么是DFS算法DFS，全名深度优先搜索 用大白话来说，其实就是 一条路走到黑，走不通再回来，直到无路可走 举个简单的例子，现在我们有一个树，就像下面这样 12345 A / \\ B C / \\ / \\D E F G 假设我们要用DFS算法来进行遍历／搜索 它的步骤如下 从初始节点A出发，并且将A标记为已访问 查找A的一个临接顶点B。 如果B存在，继续执行访问，否则回退到上一步，继续查找临接顶点 将B标记为可访问，继续执行查找临界点D的操作 重复操作，直到所有的值都访问完了，无值可以访问为止。 那么，遍历树的顺序应该是 A -&gt; B -&gt; D -&gt; E - &gt; C -&gt; F -&gt; G 是不是有点像树的前序遍历，其实差不了多少 它的遍历步骤用图来表示，就像下面这样 其实换一种走迷宫的说法，就是把所有能走的路都给走了。 来个图，一看你就明白了 很感谢这个图的作者！我找不到您的出处了，如果您看到，请联系我，我会加上引用！感恩！感恩！ 这就是俗称的一条路走到黑，撞墙了要么回去，要么继续找路。 DFS的实现现在弄明白原理了，问题就在实践上了 其实看下上面的步骤，基于DFS 首先，我们需要标记一个已经访问的对象，并且持续性访问子节点，直到无法访问为止。 这种一般呼之欲出的方法就是递归，我们可以通过递归实现这些操作。 或者我们也可以利用栈实现，先将根入栈，再将根出栈，并将根的右子树，左子树存入栈，按照栈的先进后出规则来实现DFS 栈的方法 12345678910111213def DFS(root): if root: res = [] stack = [root] # 当 stack 有值 while stack: currentNode = stack.pop() res.append(currentNode.val) if currentNode.right: stack.append(currentNode.right) if currentNode.left: stack.append(currentNode.left) return res 递归的方法 1234567def DFS(root): if root is not None: print(root.key) if root.left is not None: return DFS(root.left) if root.right is not None: return DFS(root.right) DFS的几道变种算法题94. 二叉树的中序遍历给定一个二叉树的根节点 root ，返回它的 中序 遍历。 12输入：root = [1,null,2,3]输出：[1,3,2] 这是一道基础的DFS算法题，中序遍历，直接递归走你 12345678910111213141516171819202122class Solution(object): def inorderTraversal(self, root): \"\"\" :type root: TreeNode :rtype: List[int] \"\"\" # 搞个全局的列表 z = [] if root == None: return [] # 这边写个递归 def dfs(root): if root: dfs(root.left) z.append(root.val) dfs(root.right) dfs(root) return z 112. 路径总和给你二叉树的根节点 root 和一个表示目标和的整数 targetSum ，判断该树中是否存在 根节点到叶子节点 的路径，这条路径上所有节点值相加等于目标和 targetSum 。 叶子节点 是指没有子节点的节点。 12输入：root = [5,4,8,11,null,13,4,7,2,null,null,null,1], targetSum = 22输出：true 这是一道典型的DFS题，需要一条路走到黑那种 并且你需要记录下来到底走了那些路，能不能综合成一个总数 这边我用的方法是，所有路线走遍，分别记录，一条条再去匹配targetSum，没有匹配到，直接返回false 把上面那个模版拿过来，加两个参数 第一个，加一个stact_val，这个是用来记录和的 第二个，在每一步遍历的的时候，都去做一步加法，最后统计总量对比 123456789101112131415161718192021222324252627class Solution(object): def hasPathSum(self, root, targetSum): \"\"\" :type root: TreeNode :type targetSum: int :rtype: bool \"\"\" if not root: return False if root: stack = [root] stack_val = [root.val] # 当 stack 有值 while stack: currentNode = stack.pop() temp = stack_val.pop() if not currentNode.left and not currentNode.right: if temp == targetSum: return True continue if currentNode.right: stack.append(currentNode.right) stack_val.append(currentNode.right.val + temp) if currentNode.left: stack.append(currentNode.left) stack_val.append(currentNode.left.val + temp) return False 129. 求根节点到叶节点数字之和1234567891011121314151617181920212223给你一个二叉树的根节点 root ，树中每个节点都存放有一个 0 到 9 之间的数字。每条从根节点到叶节点的路径都代表一个数字：例如，从根节点到叶节点的路径 1 -&gt; 2 -&gt; 3 表示数字 123 。计算从根节点到叶节点生成的 所有数字之和 。叶节点 是指没有子节点的节点。输入：root = [1,2,3]输出：25解释：从根到叶子节点路径 1-&gt;2 代表数字 12从根到叶子节点路径 1-&gt;3 代表数字 13因此，数字总和 = 12 + 13 = 25输入：root = [4,9,0,5,1]输出：1026解释：从根到叶子节点路径 4-&gt;9-&gt;5 代表数字 495从根到叶子节点路径 4-&gt;9-&gt;1 代表数字 491从根到叶子节点路径 4-&gt;0 代表数字 40因此，数字总和 = 495 + 491 + 40 = 1026 这道题的解法，其实就是遍历所有子树，到底，然后把每个子树的数字组成新数字，最后返回一个和。 分析一下，按照1，2，3这个来看，上层子树永远是下层的10倍数 也就得出 (1 * 10 + 2) + (1 * 10 + 3) = 25 根据这个逻辑，开始写代码 首先把那个DFS的遍历模版拿出来 1234567def DFS(root): if root is not None: print(root.key) if root.left is not None: return DFS(root.left) if root.right is not None: return DFS(root.right) 改一下，先写个伪代码 12345678def dfs(root): if not root: return 0 num = 上一个子树的节点 * 10 + root.val if not root.left and not root.right: return num else: return 左节点num + 右节点num 现在我们要获取到的数据就是，上一个子树的节点，这个我们决定，以参数的形式传输进去，因为第一个节点树，都是0 改一下代码 12345678def dfs(root, nodeval): if not root: return 0 num = nodeval + root.val if not root.left and not root.right: return num else: return dfs(root.left, num) + dfs(root.right, num) 把我们的代码嵌入到主代码当中 123456789101112131415class Solution(object): def sumNumbers(self, root): \"\"\" :type root: TreeNode :rtype: int \"\"\" def dfs(root, nodeval): if not root: return 0 total = nodeval * 10 + root.val if not root.left and not root.right: return total else: return dfs(root.left, total) + dfs(root.right, total) return dfs(root, 0) 这样就完成了这道题。 总结这段时间觉得自己越来越不努力了，我不喜欢自己这样，我一点也不喜欢。 我觉得每天我都要努力前进，后续我会持续性输出算法和其他的东西，请期待吧。 今天的freestyle说点什么呢？说点开心的事儿吧。 突然想到的小样，不代表任何事物。哈哈。 12345678910111213check it~初见的记忆浮现是不是爱神射错了离弦的箭？曾几何时你我只是互相平行的线是谁在中间接了莫名其妙的姻缘？似乎曾经相见是石头记下宝玉渊源？ 最近好累，感觉真的挺累，学习不会停止，你，我，我们，都要在春暖花开的地方相见。","categories":[],"tags":[{"name":"算法","slug":"算法","permalink":"https://yemilice.com/tags/%E7%AE%97%E6%B3%95/"}],"keywords":[]},{"title":"学习etcd的消息协议gRPC一点随想","slug":"etcd的消息协议-gRPC学习随想","date":"2021-04-06T02:39:55.000Z","updated":"2021-04-08T08:09:33.194Z","comments":true,"path":"2021/04/06/etcd的消息协议-gRPC学习随想/","link":"","permalink":"https://yemilice.com/2021/04/06/etcd%E7%9A%84%E6%B6%88%E6%81%AF%E5%8D%8F%E8%AE%AE-gRPC%E5%AD%A6%E4%B9%A0%E9%9A%8F%E6%83%B3/","excerpt":"","text":"前言首先，要在这里说明一个情况，我的etcd的学习进入了第二个阶段 再一个，未来我将不会更新一些基础代码用法，未来的博客文章将会持续性输出阅读源码和算法之类的文章，因为我的学习也进入了另一个阶段。 大家共勉吧，希望大家都能找到合适的，适合自己的工作，也希望大家都可以快快乐乐的工作和生活。 爱你们！ 我以前也写过一篇gRPC鸡翅使用的的相关文章 如果大家不了解gRPC，请先看看怎么用 使用golang的grpc框架的一点随想 etcd和grpc的关系首先，为什么我要把etcd和grpc放到一起，或者说，他们到底有什么PY交易，导致etcd一定要用grpc呢。 这里就要将一些基础理论了 首先简单说明他们的关系 etcd v3 使用了gRPC作为了它的消息协议。 etcd 项目包括基于 gRPC 的 Go client 和 命令行工具 etcdctl，通过 gRPC 和 etcd 集群通讯。 对于不支持 gRPC 支持的语言，etcd 提供 JSON 的 grpc-gateway。这个网关提供 RESTful 代理，翻译 HTTP/JSON 请求为 gRPC 消息。 这里的资料来源于etcd官方文档中文版 这里用大白话来说，就是 etcd v3 是通过grpc通信的，并且etcd惯用的管理命令 etcdctl，也是通过grpc进行etcd集群的管理和消息分发的。 为什么etcd v3要使用gRPC这里就要了解一下etcd 协议的变迁了 首先，etcd v2 使用的是传统的 http+JSON 和server端进行交互，http+JSON的组合必须为每个请求建立一个连接，相当于一对一。 etcd v3 就开始完全采用了gRPC进行通信底层的协议消息。 gRPC是通过了protocol buffer进行定义管理，gRPC在处理网络连接的优势非常明显，因为它使用单一连接的HTTP2， 实现多路复用的RPC，相当于一对多 为什么原有的http+JSON被替换了呢？ 分开剖析一下。 JSON 和 protobuf的对比首先，RPC这个东西，主要就是把消息（内存对象）转换成信息流，发给server端，然后server端再给它转换成需要的数据类型。 etcd v2 是通过JSON作为消息传递的数据格式 etcd v3 是通过protobuf作为消息传递的数据格式 不同的地方出现了，首先，protobuf 替代了 JSON，那，为什么JSON这种老牌数据格式被替换了呢？ 这里我查阅了一些资料，这篇文章写的真的很好，一看就大概明白了，我在这里感谢这个作者！ 这个作者的文章地址在：https://zhuanlan.zhihu.com/p/331593548 很感谢您！您是我的指路明灯！ 首先先说一下结论：protobuf的效率高于JSON 现在分析一下为什么会这样。 看下这段JSON 123456789101112131415&#123; \"work\":123, \"work2\":\"456\", \"work3\":&#123; \"work31\":789 &#125;&#125;&#123; \"work\":789, \"work2\":\"456\", \"work3\":&#123; \"work31\":123 &#125;&#125; 可以看到，JSON中包含很多类型的值，但是有些值是非字符串的，丽日，work的值是123，这个值的类型是int，内存表示只占两个字节，转成 JSON 却要五个字节。bool 字段则占了四或五个字节，所以，JSON其实有很多不必要的内存占用的。 还有一个问题重复传输字段，可以看见，同样的key，work，只是因为值不同，就要传输两次work这个key值，所以造成了不必要的冗余，所以这就是JSON不足的地方。 那么protobuf是从哪里解决这个问题的呢？ 首先，protobuf首先需要定义好要传输的字段类型和字段名，例如 1234message TestWork &#123; string message = 1; int32 code = 2;&#125; 定义好之后，直接编译成二进制文件 .proto 这部分不明白的可以看一下我以前的blog: 使用golang的grpc框架的一点随想 编译之后，protobuf对数字之类的编码，使用了VarInts Varints是将一个整数序列化为一个或多个Bytes的方法,越小的整数，使用的Bytes越小。所以解决了JSON的第一个问题，非字符串的资源占用效率问题。 并且看上面，protobuf直接定义好了要传输的字段名，给每个字段指定了一个整数编号。就像上面。这里传输的时候，可以直接传递编号，不用带上字段传输，这样增加了效率，避免了第二个问题：冗余问题 所以，这就是protobuf替代JSON的必要条件。 HTTP API 和 gRPC的对比从上面可以知道，etcd v2 是直接用了http api，etcd v3兼容了两种模式，一种是 http api，一种是gRPC，那么，这两种服务，有什么不同的地方吗？ 这边简单列一个表格，对他们进行比较 功能 gRPC HTTP API 协定 .proto(必须用) OpenAPI（可以不用） 协议 HTTP/2 HTTP Payload Protobuf(二进制，不可外部读取) JSON（可外部读取） 规定性 非常严格 宽松 流式处理 客户端，服务器，双向 客户端，服务器 浏览器支持 不支持 支持 安全性 TLS TLS 客户端代码生成 可生成 OpanAPI gRPC 替代 HTTP API的一些原因，相信大家在上面那个表里也能看出来。 我在这里总结一下gRPC的优点 性能： protobuf序列化字段，负载小 协议：转为HTTP/2 设计，比普通的HTTP紧凑高效，单个TCP可复用多个HTTP/2 调用 代码生成：.proto文件自动生成，并且端到端生成消息和客户端代码 严格规范：避免多平台的情况下出现分歧，各个平台实现一致。 流式处理：支持一元，服务到客户端，客户到服务端，双向流式传输 超时处理支持：支持rpc内部的timeout，并且可以取消timeout的服务 现在，为什么要用gRPC替代HTTP API，我相信，你心里，也应该有数了。 etcd的gRPC源码简单解读读源码真是个很头大的工作，反正我是觉得自己很菜，读起来很累，不过查询了一些资料，自己也读了一点，也算是明白了那么点点门道，哈哈。 server端首先，阅读gRPC源码，还是要先找到proto etcd的gRPC的proto，放置的位置在：/etcdserver/etcdserverpb/rpc.proto 首先先看一下这个文件定义了哪些服务 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768service KVservice Watchservice Leaseservice Clusterservice Maintenanceservice Auth``` 定义了6个服务，服务里面有多个RPC方法，我们选一个最常用的KV来进行简单的分析吧。首先看KV这个服务，代码如下```protobufservice KV &#123; // Range gets the keys in the range from the key-value store. rpc Range(RangeRequest) returns (RangeResponse) &#123; option (google.api.http) = &#123; post: \"/v3beta/kv/range\" body: \"*\" &#125;; &#125; // Put puts the given key into the key-value store. // A put request increments the revision of the key-value store // and generates one event in the event history. rpc Put(PutRequest) returns (PutResponse) &#123; option (google.api.http) = &#123; post: \"/v3beta/kv/put\" body: \"*\" &#125;; &#125; // DeleteRange deletes the given range from the key-value store. // A delete request increments the revision of the key-value store // and generates a delete event in the event history for every deleted key. rpc DeleteRange(DeleteRangeRequest) returns (DeleteRangeResponse) &#123; option (google.api.http) = &#123; post: \"/v3beta/kv/deleterange\" body: \"*\" &#125;; &#125; // Txn processes multiple requests in a single transaction. // A txn request increments the revision of the key-value store // and generates events with the same revision for every completed request. // It is not allowed to modify the same key several times within one txn. rpc Txn(TxnRequest) returns (TxnResponse) &#123; option (google.api.http) = &#123; post: \"/v3beta/kv/txn\" body: \"*\" &#125;; &#125; // Compact compacts the event history in the etcd key-value store. The key-value // store should be periodically compacted or the event history will continue to grow // indefinitely. rpc Compact(CompactionRequest) returns (CompactionResponse) &#123; option (google.api.http) = &#123; post: \"/v3beta/kv/compaction\" body: \"*\" &#125;; &#125;&#125; 然后我们需要找到对应的服务端的go文件，文件名叫 v3_server.go 先看下Put方法 1234567func (s *EtcdServer) Put(ctx context.Context, r *pb.PutRequest) (*pb.PutResponse, error) &#123; resp, err := s.raftRequest(ctx, pb.InternalRaftRequest&#123;Put: r&#125;) if err != nil &#123; return nil, err &#125; return resp.(*pb.PutResponse), nil&#125; 看到了吗，有个raftRequest函数，追踪一下 12345678func (s *EtcdServer) raftRequest(ctx context.Context, r pb.InternalRaftRequest) (proto.Message, error) &#123; for &#123; resp, err := s.raftRequestOnce(ctx, r) if err != auth.ErrAuthOldRevision &#123; return resp, err &#125; &#125;&#125; 这部分代码调用raftRequestOnce，大概的意思就是如果出现错误，就进行重试。 12345678910func (s *EtcdServer) raftRequestOnce(ctx context.Context, r pb.InternalRaftRequest) (proto.Message, error) &#123; result, err := s.processInternalRaftRequestOnce(ctx, r) if err != nil &#123; return nil, err &#125; if result.err != nil &#123; return nil, result.err &#125; return result.resp, nil&#125; 回到PUT部分的代码，大致意思就是，上传信息，如果错误，重试。 再看下Range方法 123456789101112131415161718192021func (s *EtcdServer) Range(ctx context.Context, r *pb.RangeRequest) (*pb.RangeResponse, error) &#123; // 判断请求是否是可以 read if !r.Serializable &#123; err := s.linearizableReadNotify(ctx) if err != nil &#123; return nil, err &#125; &#125; var resp *pb.RangeResponse var err error // 检查权限，看看权限是否可用 chk := func(ai *auth.AuthInfo) error &#123; return s.authStore.IsRangePermitted(ai, r.Key, r.RangeEnd) &#125; // 查询kv时候的回调函数 get := func() &#123; resp, err = s.applyV3Base.Range(nil, r) &#125; if serr := s.doSerialize(ctx, chk, get); serr != nil &#123; return nil, serr &#125; return resp, err&#125; 调用了一个doSerialize函数 看下它 1234567891011121314151617181920212223242526272829func (s *EtcdServer) doSerialize(ctx context.Context, chk func(*auth.AuthInfo) error, get func()) error &#123; for &#123; // 获取权限相关信息 ai, err := s.AuthInfoFromCtx(ctx) if err != nil &#123; return err &#125; if ai == nil &#123; // chk expects non-nil AuthInfo; use empty credentials ai = &amp;auth.AuthInfo&#123;&#125; &#125; // 回调执行chk函数，校验权限 if err = chk(ai); err != nil &#123; if err == auth.ErrAuthOldRevision &#123; continue &#125; return err &#125; // fetch response for serialized request // 回调get函数，通过authStore读取kv get() // empty credentials or current auth info means no need to retry // 读完，权限没有更改，结束，否则，重试 if ai.Revision == 0 || ai.Revision == s.authStore.Revision() &#123; return nil &#125; // avoid TOCTOU error, retry of the request is required. &#125;&#125; cilent端server看完了，该看下cilent端的部分代码了 client端的代码 放置在：/clientv3/client.go 下面，将针对几个重要函数进行源码解析 如果我们要启动一个etcd 的 client连接，我们应该 12345client, err := clientv3.New(cfg)if err != nil &#123; fmt.Println(\"连接ETCD失败\") return nil, err&#125; 追踪到核心代码 newClient 这里为了避免文章太长，将一些不必要的操作打了省略号，请注意！！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162func newClient(cfg *Config) (*Client, error) &#123; ...... // use a temporary skeleton client to bootstrap first connection ...... ctx, cancel := context.WithCancel(baseCtx) // 这里检测配置信息，并且创建一个client实例 client := &amp;Client&#123; conn: nil, dialerrc: make(chan error, 1), cfg: *cfg, creds: creds, ctx: ctx, cancel: cancel, mu: new(sync.Mutex), callOpts: defaultCallOpts, &#125; // 记录账户和密码 if cfg.Username != \"\" &amp;&amp; cfg.Password != \"\" &#123; client.Username = cfg.Username client.Password = cfg.Password &#125; ...... // 初始化balancer实例 client.balancer = newHealthBalancer(cfg.Endpoints, cfg.DialTimeout, func(ep string) (bool, error) &#123; return grpcHealthCheck(client, ep) &#125;) // use Endpoints[0] so that for https:// without any tls config given, then // grpc will assume the certificate server name is the endpoint host. // 建立一个网络连接 conn, err := client.dial(cfg.Endpoints[0], grpc.WithBalancer(client.balancer)) if err != nil &#123; client.cancel() client.balancer.Close() return nil, err &#125; client.conn = conn ...... // 初始化多个客户端，前面的介绍过，有6个 client.Cluster = NewCluster(client) client.KV = NewKV(client) client.Lease = NewLease(client) client.Watcher = NewWatcher(client) client.Auth = NewAuth(client) client.Maintenance = NewMaintenance(client) if cfg.RejectOldCluster &#123; if err := client.checkVersion(); err != nil &#123; client.Close() return nil, err &#125; &#125; // 启动一个goroutine，同步集群中的URL go client.autoSync() return client, nil&#125; 最后一步执行了一个goroutine，执行了一个autoSync 方法 这个方法的代码如下 1234567891011121314151617func (c *Client) autoSync() &#123; ...... for &#123; select &#123; case &lt;-c.ctx.Done(): return case &lt;-time.After(c.cfg.AutoSyncInterval): ctx, cancel := context.WithTimeout(c.ctx, 5*time.Second) err := c.Sync(ctx) cancel() if err != nil &amp;&amp; err != c.ctx.Err() &#123; logger.Println(\"Auto sync endpoints failed:\", err) &#125; &#125; &#125;&#125; 这里循环执行了一个Sync方法，方法代码如下 123456789101112func (c *Client) Sync(ctx context.Context) error &#123; mresp, err := c.MemberList(ctx) if err != nil &#123; return err &#125; var eps []string for _, m := range mresp.Members &#123; eps = append(eps, m.ClientURLs...) &#125; c.SetEndpoints(eps...) return nil&#125; 这里的的操作步骤，是请求当前的节点列表，然后更新本地的缓存。 下面我们举一个简单的put例子，看一下put的代码怎么写的 首先，写一个put代码 1etcd.client.Put(context.Background(), name, value) 追踪代码 clientv3/kv.go 12345678type KV interface &#123; // Put puts a key-value pair into etcd. // Note that key,value can be plain bytes array and string is // an immutable representation of that bytes array. // To get a string of bytes, do string([]byte&#123;0x10, 0x20&#125;). Put(ctx context.Context, key, val string, opts ...OpOption) (*PutResponse, error) ....&#125; 持续追踪 1234func (kv *kv) Put(ctx context.Context, key, val string, opts ...OpOption) (*PutResponse, error) &#123; r, err := kv.Do(ctx, OpPut(key, val, opts...)) return r.put, toErr(ctx, err)&#125; 调用了kv.Do部分 看下kv.Do的代码 123456789101112131415161718192021222324func (kv *kv) Do(ctx context.Context, op Op) (OpResponse, error) &#123; var err error switch op.t &#123; // 查询操作 case tRange: ....... // 上传操作 case tPut: var resp *pb.PutResponse r := &amp;pb.PutRequest&#123;Key: op.key, Value: op.val, Lease: int64(op.leaseID), PrevKv: op.prevKV, IgnoreValue: op.ignoreValue, IgnoreLease: op.ignoreLease&#125; resp, err = kv.remote.Put(ctx, r, kv.callOpts...) if err == nil &#123; return OpResponse&#123;put: (*PutResponse)(resp)&#125;, nil &#125; // 删除操作 case tDeleteRange: ....... case tTxn: ....... default: panic(\"Unknown op\") &#125; return OpResponse&#123;&#125;, toErr(ctx, err)&#125; 看到了吗，put调用了 KVclient.Put的方法，这个方法在刚刚上面那个位置 /etcdserver/etcdserverpb/rpc.pb.go里面 123type KVClient interface &#123; Put(ctx context.Context, in *PutRequest, opts ...grpc.CallOption) (*PutResponse, error)&#125; client v3的服务流程，就这样走完了。 后记etcd grpc这部分就讲完了 其实grpc还有很多可以讲的东西，不过这篇blog不是这么玩的。 下一篇博客将会详细分析gRPC，或者是ElasticSearch的一些原理或者源码解读，或者是算法，请大家期待吧。 12345678910111213141516171819突然想写一首diss 歌曲内心依旧激昂翻滚从未平息想到那些不尊重人的faker coder 面试官竖起中指对你们亲切表达从来不care他人的看法评判我的资格你还没有拿下回去继续敲你那没用的代码甩你开源5个身位冒牌faker程序员还有资格坐在高位？fuck off 垃圾傀儡。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"学习etcd核心机制Raft协议的一点随想","slug":"学习etcd核心机制raft协议的一点随想","date":"2021-04-04T06:50:25.000Z","updated":"2021-04-04T06:56:43.913Z","comments":true,"path":"2021/04/04/学习etcd核心机制raft协议的一点随想/","link":"","permalink":"https://yemilice.com/2021/04/04/%E5%AD%A6%E4%B9%A0etcd%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6raft%E5%8D%8F%E8%AE%AE%E7%9A%84%E4%B8%80%E7%82%B9%E9%9A%8F%E6%83%B3/","excerpt":"","text":"前言最近开始学习k8s相关的东西，不可避免的和etcd搭上了交道，说来使用etcd的日子也不短了 中途开源过Python和Golang的etcd的api，代码在github上，公布一下 Golang的代码： 1https://github.com/Alexanderklau/Go_poject/tree/master/Go-Etcd 我只能说我会用，但是，会用是远远不够的，所以，这几天看了一些书和博客，将etcd相关的一些重要的知识点进行梳理总结，并且整理输出 作为自己的笔记，希望可以帮到大家。 感谢 《etcd技术内幕》的作者！您的书给了我很大的启发，也推荐大家去看看！ etcd到底是什么是一个分布式的KV存储数据库，通过raft算法保持数据的一致性。 通常，我们会把etcd作为分布式系统的数据共享，或者是服务发现，服务注册等。 什么是服务发现？当我们开发到后期，一个系统中包含的模块和服务越来越多，所以对需要对系统进行拆分，现在流行的微服务架构就差不多这样。 有时候多个服务互相依赖，假设，一个检索系统，tika和elasticsearch相互依赖，当tika挂掉之后，elasticsearch并不知道它挂了，所以，这就出现了负载均衡的问题。 当我们使用了服务发现后，tika和elasticsearch通过定期发送心跳，告知服务是否存活，当elasticsearch调用tika的时候，会调用服务发现组件，保证返回的服务地址可用，或者是良好的负载均衡。 什么是服务注册？服务注册，其实和服务发现相辅相成，如果没有服务注册，那我们一般都是通过读取配置文件获取服务地址，如果有了服务注册，当启动服务，或者安装服务的时候，将信息注册到etcd当中，这时，服务发现就派上了用场了，请继续浏览上面的流程。 什么是数据共享？这个很简单，在分布式系统中，我们经常需要同步配置文件，也有可能，分布式系统中的几个机器需要共用一个文件，例如rabbitmq的cookie。我们可以将这种数据存储在etcd当中，就避免了配置同步需要另写代码，或者是rpc，其他服务出现问题时同步失败的情况。 etcd的基础数据模型etcd有几个特殊功能，假设我们对一个键值进行修改 123&#123; \"work\":\"ak47\"&#125; 如果现在我们把ak47换成m16，那么原有的ak47这个值不会消失/删除，而是会记录一个不同的版本号，把ak47和m16进行区分。这就是wathcer机制。 一个key会对应多个generation（翻译成代，世代的意思，可以记作周期），意思就是，一个key很可能有多个实例，也就是说，可以被修改多次，也可以对应多个值 当key被创建的时候，会同时创建一个generation实例，和这个key相互关联 当key被修改的时候，会记录当前版本到generation中 当key被删除时，会添加一个墓碑（tombstone）到 generation中，标识这个generation已经完蛋，并且创建一个新的generation。 所以，查询的步骤应该是 寻找指定的key值 获取全部generation版本号 根据查询的generation从存储中找到具体的Value值 输出Value 所以，etcd不会进行覆盖的操作，而总是生成一个新的数据结构。 更详细的解释etcd的数据模型首先，etcd将数据存放在一个持久化的B+树当中 etcd会维护一个字段序的B树索引，是为了加速针对key的范围扫描 在每个B树索引项中，都存储了一个key值，这也是为了快速定位指定的key或者进行范围扫描 所以回到上面讲的，etcd的每个key有多个版本，在每个revision的tree里，有多个对应的keys。 etcd保证数据一致性的方法-Raft协议etcd是一种分布式的数据库，分布式数据库里面，存在的一个很重要的问题就是，保证每个节点的数据一致，也就是数据一致性 一般的分布式数据库，etcd，elasticsearch之类的都会维护多个副本，这样我们上面的问题就变成了 维护多节点副本的一致性 那么什么又是一致性呢？ 顾名思义，多个节点的数据一致，并且保持更新的状态，少数集群凉了也不影响整个集群的工作。 这就是一致性的妙处，Raft协议，就是实现一致性的重要算法。 Raft协议的大白话解释首先我看了一下Raft的一致性算法论文，论文的中文地址在 https://www.infoq.cn/article/raft-paper 我在这里大白话总结一下Raft协议的核心内容 首先，Raft会进行一个状态（角色）划分 假设现在我们有四个个节点node1, node2, node3，node4, 副本的协议是单副本 那么所有的节点就会处于三种角色状态 leader 主节点，通过follower选举出来的，接收所有的client请求 follower 跟随者，从主节点获取请求，进行相关操作 candidate 当leader出现故障时，选主过程打开，其他follower转为这个角色，直到选出新的leader 在这里可以看到了，leader是带头大哥，follower是小弟，任何时候都要听大哥指挥 大哥让你更新你就更新，让你删除你就删除。如果大哥被杀（leader挂掉），那么其他小弟（follower）就会竞争大哥的位置 你们看过《新世界》没，选帮派大哥，是不是有那味了？ 竞选大哥（leader选举）的流程如下： 其他小弟follower发现，大哥node1的心跳没了（leader节点不通，无返回，心跳机制接收不到leader的存活信息，leader timeout） 开始触发选举 （election timeout） 所有 follower 转变角色为 candidate candidate（node2）开始投票，优先投票给自己（加勒比海盗选海盗王） candidate (node2)给其他节点(node3, node4)发送选举请求（request vote）拉票 其他的candidate(node3, node4)节点接收到请求后，如果他们还没有开始进行投票（上一步的投票给自己），就会投票给拉票节点(node2) node2 获取了半数以上的票数，当选为新的大哥（leader） 但是，竞选大哥（leader）也可能出现一种情况，就是我支持大D，你支持阿乐，那谁当大哥啊？ 这种问题也是有的，就是 当node2(大D) 得到了 node3 (根叔)的支持，拿到一票，但是node1（邓伯）投了 node4(阿乐)一票，这样就是2对2 当node2的选举请求（request vote）到达node3，但是node4 的选举请求到了node1的时候，会有一个election timeout的事件，这一步预示选举失败，要搞新和连胜了，重新选举一个大佬，所以上一轮选举失败。 node4(阿乐)的选举计时器（election timer）到期，直接timeout，阿乐会触发选举，继续发送选举请求（request vote）给根叔（node3）,邓伯（node4）,大D（node2），这时，邓伯和根叔的选举计时器（election timer也到期，接受到阿乐（node4）的信息，直接投票给阿乐（node4），大D（node4）这时候也到期了，这时node4（阿乐）已经获得了半数投票，加冕话事人，大D那票，也就无所谓了。 这就是Raft的大白话解读，我反正懂了，你们呢？ 日志复制首先书接上回，我们选出了大哥（leader） 大哥（leader）能干嘛 leader除了给小弟（follower）发号施令（心跳信息），还会接受到client的请求，比如更新，删除，等消息，发送到所有follower节点，进行相应的操作，当leader接受到半数以上的follower操作成功信息的时候，将成功的相应返回，对client进行应答。 回到本节，什么是日志复制？只是复制日志吗？ native了兄弟！在数据库里面，日志里面有数据也有操作，是很重要的东西，万一你把数据整丢了，通过日志也能恢复！ 日志应该是挺重要的东西，etcd是怎么保护日志的那？ 假设三个节点，node1（leader）, node2（follower）, node3（follower） 假设我们现在往etcd里面写了一条数据 123&#123; \"a\":10&#125; 首先，这个写入的请求(set a=10)会被传入到node1（leader），然后被传输给node2，node3 node2，node3收到Append Entries的消息(set a=10)之后，会记录操作到本地的log当中，并且返回成功的信息 node1在收到半数以上的响应消息之后，才会认为集群已经成功记录了本次操作，node1会更新日志，提交对应日志的纪录状态，最后返回消息给client。 一个etcd集群当中，每个节点都需要维护一个log，除此之外，log维护还需要两个重要的数值 一个是commitIndex（当前日志索引值） 另一个是lastApplied （最后日志索引值） 说起来似乎有点抽象，其实就是，一个是现在日志的位置，另一个是最后一条日志的位置，做记录用的。 leader节点不仅要维护自己commitIndex，lastApplied，他还需要知道所有节点的commitIndex，lastApplied信息。 为啥呢，因为leader是老大啊，他需要知道每个follower节点的日志记录到哪了，从而保持大家的一致，也决定下次发送的消息里面包含什么信息。 所以leader还维护了两个数组，一个叫nextIndex，另一个叫matchIndex。 这个同样是为了更新用的 nextIndex记录的是发送给follower的下一条日志的索引值 matchIndex是记录了已经发送给follower的最大索引值 这都是由follower节点上报给leader的 太绕了，我举个例子吧。 还是用上面那个node1,node2,node3的环境。 假设，node3宕机过，现在数据不一致，那么leader节点的记录的三个节点的nextIndex和matchIndex的表示形式如下图，看图 黑色箭头代表的是nextIndex，红色箭头代表的是matchIndex，这边表示出来就是 123456&#123; \"node1\": &#123; \"nextIndex\": 3, \"matchIndex\": 4 &#125;&#125; 所以leader里面应该是按照这个形式存储的nextIndex和matchIndex 我们发现node3和node1,node2有误差，是因为node3宕机过，现在在leader中，记录了node3的nextIndex和matchIndex 123456&#123; \"node3\": &#123; \"nextIndex\": 0, \"matchIndex\": 1 &#125;&#125; 这时leader还能知道node3的日志具体位置，也知道该向node3发送哪些日志信息。 但是有一种特殊情况，leader挂掉之后，新leader接替上位，新leader会把所有的nextIndex和matchIndex都置为空。新leader会以自己本节点的日志为核心，将其他节点的nextIndex置换为本节点提交日志的最后一条，将matchIndex置为0值。 新的leader会持续向其他节点发送append Entriesx消息，node3并没有2，3这两条日志，node3将会返回给leader追加失败的相应，leader会修改node3的nextIndex,matchIndex，将他们前移一位，继续进行追加，直到返回成功为止。 可以看下这个图 日志的新旧对比上一节提到了日志复制，但是我们如何去保持日志永远都是最新的呢？ 如果需要比较节点之间的日志新旧，就需要找到最后一条日志的索引值和任期号，用来决定谁才是最新的。 如果任期号比较大，那么认为此日志比较新。 如果任期号相同，日志索引值比较大的比较新。 在选举过程中，candidate节点成为leader的过程中，向半数以上的节点都发送了日志信息，所以，leader节点必然和其他节点都有一个相同的日志信息，也就是交集。 日志压缩与快照随着etcd服务集群部署的时间越长，数据量也就越来越大，占用的资源也就越多，我们前一阵子，etcd的内存占用率非常高，一看，原来是有人把操作日志全记录在etcd当中了。 日志不能无限量增长下去，所以需要压缩机制和清除机制来释放空间。 一般在etcd中，大家都用压缩这种机制，因为压缩非常简单，而且效率也非常高。 快照包含了节点当前的数据状态，也包含了最后一条日志记录的任期和索引号 也就是说，假设，我们的日志记录了1-100条日志的任期和索引号，现在我们生成快照文件，只需要记录最后第100条的任期和索引号就得了，1-99条日志记录全部丢弃。 一般恢复快照的时候，都是leader节点发送快照给follower，follower使用快照恢复数据，这里是通过GRPC发送的网络消息，这里比较复杂，未来我写一篇日志详细讲下。 后记etcd的基础过了一遍了，其实我弄明白的差不多了。 学习嘛，见贤思齐焉，见不贤而内自省也。 希望能帮助大家。 12345678910111213描绘人生不用名贵的画笔我吐字成金勾勒速写生活的点滴妈妈总是说你还是个孩子没有办法处理好自己的事可我已经开始长胡子扛起不屈的意志","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang进阶-必须知道的一些事","slug":"Golang进阶-必须知道的一些事","date":"2021-03-19T08:46:16.000Z","updated":"2021-03-19T09:07:34.825Z","comments":true,"path":"2021/03/19/Golang进阶-必须知道的一些事/","link":"","permalink":"https://yemilice.com/2021/03/19/Golang%E8%BF%9B%E9%98%B6-%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BA%8B/","excerpt":"","text":"前言最近感觉自己又陷入了无尽的自我循环和自我否定，不知道自己到底是怎么了 我，出生于忧患之中，但是告诫自己，不能死于安乐。 这篇文章是收集的一些Golang进阶的知识，作为我自己更上一层楼的笔记，也希望可以帮助大家 未来将会持续性输出面试之类的八股文和算法之类的笔记，因为我感觉自己需要时间去沉淀 1234567怀才不遇只是欺骗自己的安慰剂胸无点墨想学太白一字千金？泛舟池上不如随风远去人生不止生命不息 Golang进阶需要知道的知识理解Golang垃圾回收垃圾回收，一般简称GC，你理解为，释放不需要的资源就行 GC的核心机制，就是后台维护一个守护线程，监控对象状态，识别不需要的对象，释放资源 Golang的垃圾回收机制进行了多次演变 12345678910111213141516171819202122231. v1.0 — 完全串行的标记和清除过程，需要暂停整个程序2. v1.1 — 在多核主机并行执行垃圾收集的标记和清除阶段3. v1.3 — 运行时基于只有指针类型的值包含指针的假设增加了对栈内存的精确扫描支持，实现了真正精确的垃圾收集4. v1.5 — 实现了基于三色标记清扫的并发垃圾收集器,大幅度降低垃圾收集的延迟从几百 ms 降低至 10ms 以下5. v1.6 — 实现了去中心化的垃圾收集协调器；基于显式的状态机使得任意 Goroutine 都能触发垃圾收集的状态迁移6. v1.7 — 通过并行栈收缩将垃圾收集的时间缩短至 2ms 以内7. v1.8 — 使用混合写屏障将垃圾收集的时间缩短至 0.5ms 以内8. v1.9 — 彻底移除暂停程序的重新扫描栈的过程9. v1.10 — 更新了垃圾收集调频器（Pacer）的实现，分离软硬堆大小的目标10. v1.12 — 使用新的标记终止算法简化垃圾收集器的几个阶段11. v1.13 — 通过新的 Scavenger 解决瞬时内存占用过高的应用程序向操作系统归还内存的问题12. v1.14 — 使用全新的页分配器优化内存分配的速度 2021年，Golang的垃圾回收机制是三色标记法搭配辅助GC还有写屏障 三色标记法是标记-清除法的一个增强版本 那么，什么是标记清除法呢 简单的说下 标记-清除法的基础原理 123就是，先停止服务运行，被引用的对象打上标记没打上标记的对象就直接清除，也就是回收资源，然后恢复程序运行。 说白了，就是先给你停止任务，正在引用的对象被打个标签，告诉GC，这个是我的人，我罩着的，你不能动，其他的我都用过了，随便你干掉吧，GC才会去清除未引用的标记。 那么三色标记法的原理呢？ 首先，三色，是哪三色，是白色，灰色，黑色 这三个分别代表三种不同的标识状态 白色代表可回收，灰色代表被黑色引用，黑色代表被程序引用 感觉有点绕，这边简单的出个示意图吧 1234567main(主程)| |---------------------A B C D E F G--------------------- |-----| 包含引用 现在我们有个栈，主main引用了A，B两个元素，但是B同时引用了E这个元素，根据三色标记法，三色标记的情况如下 123456789---A B 标记的黑色对象----E 标记的灰色对象--------C D F G 标记的白色对象------- 所以三色标记法GC的步骤是 12341. 扫描全局数据和当前的栈区域，标记引用的对象（A，B）黑色对象2. 扫描引用的对象，(E) 标记灰色对象3. 其他的全打入白色对象（C D F G）4. 重复步骤2，直到灰色对象为空，清空所有白色对象 写屏障，简单点说，就是GC开始的时候，有一个记录器，名字叫屏障，第一次运行的时候，它会扫描各个对象的状态，第二次扫描时，会拿出来和第一次扫描的结果进行比对，也就是三色法那个记录灰色的步骤，标记被引用对象为灰色，防止丢失。 辅助GC，如果GC回收的速度过慢，赶不上程序分配对象的速度，那么这边就会暂时停止分配对象，然后将用户线程抢过来执行GC，其实整个程序现在就是停止的状态，这就是辅助GC 讲了原理，那么我们什么时候去触发GC呢？ 达到内存阈值，阈值是由一个gcpercent的变量控制的,当新分配的内存占已在使用中的内存的比例超过gcprecent时就会触发 达到定时时间，如果上面的内存阈值一直达不到，那就默认2min触发一次GC。 手动触发GC，runtime.GC()等 理解Golang的内存分配首先，什么是内存分配 内存分配的地位？ 1内存分配和垃圾回收是Golang内存管理的核心双子 内存分配主要解决什么问题？ 1主要解决协程,对象的内存分配问题 Golang内存分配的算法是？主要的思想是什么？ 12345TCMalloc算法，全程：Thread-Caching Malloc，中文翻译：线程缓存分配核心的思想就是内存分为多级管理，也就是根据多级缓存，将对象大小分类，根据类别实行不同的分配策略。每个线程维护独立的内存池，进行内存分配时，首先从独立的内存池申请内存，不足时，才向全局申请内存，避免恶意竞争 对象大小有哪几种分类方法？ 微对象 （0， 168b） 小对象 (16b， 32KB) 大对象 (32KB，无限大) 多级缓存是什么 看下这张图 123456789101112131415161718192021222324首先看下这个图，这个图里面有三个组件：1. 线程缓存（Thread Cache）2. 中心缓存（Central Cache）3. 页堆（Page Heap），这三个组件的作用分别是线程缓存: 线程缓存和线程上的处理器一一绑定，主要用来缓存用户程序申请的微小对象。中心缓存：Golang内存分配的中心缓存，访问需要互斥锁，主要是用来管理跨度内存管理单元。页堆：内存分配的核心结构体，Golang会将其作为全局变量存储，是一个全局的缓存列表。下面来理解多级：多级，理解为多层级，每个线程都有一个独立的池，所以不需要进行竞争也就不需要互斥锁进行保护，能够较少抢锁带来的损耗当自带的缓存不足时，会直接调用中心缓存解决对象的内存分配如果是大对象，将会被直接进行分配（页堆分配） 分配小对象的步骤 12341. 确定分配对象的大小2. 从线程缓存获取空闲的内存空间3. 假设线程缓存空闲不足，从中心缓存获取4. 清除空闲内存（调用runtime.memclrNoHeapPointers） 分配大对象的步骤 121. 获取对象大小，检测对象大小2. 大于32KB，直接调用（runtime.mcache.allocLarge）分配大内存 理解Golang的runtimeruntime是什么东西？ 123456789理解为Golang的基础设施是一个Golang的内置库主要就是调度协程，内存分配，GC等一系列基础操作也是管理goroutine的调度程序可以理解Golang运行时候系统交互的操作。 详细一点，runtime主要有什么功能 1234561. GC() 垃圾回收2. GOMAXPROCS(n) 控制最大CPU3. Goexit() 终止调用并且退出4. Gosched() 让出CPU，让其他协程运行，接力协程5. NumGoroutine：返回正在执行和排队的任务总数6. NumCPU：返回当前系统的 CPU 核数量 理解goroutine泄漏goroutine泄漏是什么？ 12345678910111213结束goroutine有如下几种方法1. goroutine完成任务退出2. 遇到错误3. 通过信号的方式停止如果不是通过这三种方式结束的goroutine那就导致goroutine不会正常退出然后不断的增长，不会释放，占用过多资源这就叫goroutine的内存泄漏 举几个goroutine内存泄漏的例子 12345678一般goroutine调度不当，才会出现内存泄漏一般有如下几个原因可能造成goroutine泄漏1. 死循环2. channel机制-持续发送，但不接收3. channel机制-持续接收，但不发送(空channel)4. channel机制-缓冲区已满，持续发送 防治goroutine内存泄漏的几个方法 123451. 信号控制goroutine，当创建goroutine的时候就要想着结束goroutine2. 使用channel的时候，最好不要用无限缓存，规定一个缓存数量3. 避免死循环操作 如何检查goroutine内存泄漏 1go pprof， 这个可以看一下我原来的blog 链接在这里 一次Golang服务占用CPU过大的排查经过 Golang的一些常用标准库os 123操作系统功能的相关接口例如Open, Create, Mkdir, Remove time 123时间相关处理例如 time.Sleep(time.Second * 1) fmt 123格式化操作例如 fmt.Println(&quot;12&quot;) strconv 1提供字符串与基本数据类型互转的能力 string 1处理字符串的一些函数集合，包括合并、查找、分割、比较、后缀检查、索引、大小写处理等等。 http 1提供web服务 context 1上下文操作，我blog里有 sync 1提供了基本的同步原语。在多个goroutine访问共享资源的时候，需要使用sync中提供的锁机制。 Golang的package包管理Go modules管理 1231. go.mod 文件，它与 package.json 或 Pipfile 文件的功能类似。2. 机器生成的传递依赖项描述文件 ： go.sum。3. 不再有 GOPATH 限制。模块可以位于任何路径中。 结尾大概重要的地方都在这里了，我的基础还是稍稍偏差，不过我倒是觉得，学习嘛，不要停下来，每天进步一点点应该也就好了。 这周六我也要搬到新家去了 音乐工作室也搭建好了，买了电钢 编曲那套东西也都准备完毕了，希望我能做的更好吧 我希望我能越做越好。 1234567将脚步停滞，生命静止从不明白自己处于什么位置人生偶尔痛苦还是始终如此？活着才是唯一值得骄傲的事","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"读诗的感悟","slug":"读诗的感悟","date":"2021-03-03T05:42:41.000Z","updated":"2021-03-11T03:41:36.354Z","comments":true,"path":"2021/03/03/读诗的感悟/","link":"","permalink":"https://yemilice.com/2021/03/03/%E8%AF%BB%E8%AF%97%E7%9A%84%E6%84%9F%E6%82%9F/","excerpt":"","text":"前言今年我陷入迷茫 我不知道我的路是否还在远方？ 到底停下还是持续hold on？ 难道这就是生活给予我的前路渺茫？ ONE算命先生说我天赋异禀，功成名就 20年后，格子间的工蚁是我难辞其咎 身边朋友来了又走，life move on 对影成三人的生活，is my feture 塞上耳机，beats never stop 闭上了眼，已经是晚间十点 身体靠后，看地铁奔赴下一个旅程的终点 回归生活本质，吃饭得闲饮茶 所以，将进酒且君杯莫听 且听一首诗云子曰 TWOlisten 曾经仰天大笑出门 可我辈旧是蓬蒿人 曾经在会当凌绝顶 但高楼遮住我的眼 曾经狂放诗百篇 现在空空如也 江郎才尽？ye，这是生活做的孽 回到过去，回到充满希望的年代 活着也不只是为了活着 活着很简单，生活很难。","categories":[],"tags":[{"name":"说唱之路","slug":"说唱之路","permalink":"https://yemilice.com/tags/%E8%AF%B4%E5%94%B1%E4%B9%8B%E8%B7%AF/"}],"keywords":[]},{"title":"弄懂难缠的BFS算法和相关变种(Python实现)","slug":"弄懂难缠的BFS算法和相关变种-Python实现","date":"2021-02-23T08:22:51.000Z","updated":"2021-02-28T14:50:13.217Z","comments":true,"path":"2021/02/23/弄懂难缠的BFS算法和相关变种-Python实现/","link":"","permalink":"https://yemilice.com/2021/02/23/%E5%BC%84%E6%87%82%E9%9A%BE%E7%BC%A0%E7%9A%84BFS%E7%AE%97%E6%B3%95%E5%92%8C%E7%9B%B8%E5%85%B3%E5%8F%98%E7%A7%8D-Python%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"前言这段时间频繁刷题，leetcode真的好难啊！！每次都他娘的做不出来，除了刷题，最近还在复习各种架构，或者是完成公司的开发。这些占据了我过多时间，所以blog其实一直想写，但是实在腾不出时间，今天在针对性刷leetcode的时候，对BFS/DFS有了一点别的感悟，所以就写一篇博客，作为自己的笔记，在记录的同时，也帮助其他兄弟少走弯路，希望，能够帮到大家。 什么是BFS算法？这些百度谷歌都搜的到，不过这里还是简单说一下吧 首先，BFS的全名，叫做广度优先搜索算法 搜索，顾名思义，是找寻某个东西，所以叫搜索，在写代码的时候，搜索，其实等同遍历，只是这个遍历是有条件的。 相对于BFS，它的条件是什么呢？ 举个例子，有个迷宫，有两个点，你要从A 移动到 B，中间带X的表示墙壁，无法通行 12345A 0 0 0 X 0 0 X0 X 0 B 现在走出第一步 12345A 1 0 0 X 0 0 X0 X 0 B 走现在走第二步，发现有两个可以走的地方（分岔路） 12345A 1 2 0 X 2 0 X0 X 0 B 走第三步，依旧有个分岔路 12345A 1 2 3 X 2 3 X0 X 0 B 走第四步，只有一条路 12345A 1 2 3 X 2 3 X0 X 4 B 第五步，走到B点 12345A 1 2 3 X 2 3 X0 X 4 B 我们画出可行的步骤 12345A-1-2 3 | |X 2-3 X |0 X 4-B BFS（广度优先）算法，就是记录所有可行的路径。 当面临选择和岔路的时候，BFS选择我全都要，全都记录下来，然后选择其中一个进入，如果有死路，它选择返回，选另外的岔路，继续重复这样的操作。 可以看出，BFS是逐步求解的，由近到远。这里找路程的步骤，用动态图来展示如下 这个图其实就直接说明了BFS算法的特点 这个图真的很棒！我一看就大概明白BFS算法了。感谢此图的作者，如果你看到，请联系我，我会加上你的名字作为引用！谢谢！ 是不是很像钢铁雄心4推进部队的样子？ 持续性突进！ 树的BFS算法前面你可以看到，BFS算法，其实就是将分支逐步列出。 其实对于树这个结构来说，BFS算法更像是特殊的遍历整个树结构的一种方法。 举个例子 假设我们弄一个树 12345 A / \\ B C / \\ / \\D E F G 一般的遍历逻辑就是(前序遍历) A - B - D - E - C - F - G 但是，BFS可不是这么玩的，BFS的遍历逻辑就是A - B - C - D - E - F - G 这里来个图，你一看就明白！ 这就是树的BFS遍历，其实说起来也没多难吧？ 树的BFS算法模版根据上面的逻辑，我们可以看出来，树的BFS算法是一层层的层次搜索算法，并且是先进先出的逻辑。 如图所示 那么，遍历树的BFS的模版，应该这么写 首先，定义一个树的结构体 12345class TreeNode: def __init__(self, x): self.val = x self.left = None self.right = None 由于先进先出的结构特点，这里使用队列来进行存储数据，这是因为BFS算法需要保证优先访问顶点的未访问领接点。 1234567891011121314151617181920212223242526def BFS(root): if root == None: return # 队列化root queue = deque([root]) result = [] # 遍历root while queue: # 移去并且返回一个元素，queue 最左侧的那一个 node = queue.popleft() # 获取node的详细情况 result.append(node.val) print(node.val) # 访问左树 left = node.left if left != None: queue.append(left) # 访问右树 right = node.right if right != None: queue.append(right) return result 写一个测试的方法，就按着我们刚刚那个A - G的树来一把 123456789if __name__ == \"__main__\": tree = TreeNode(\"A\") tree.left = TreeNode(\"B\") tree.right = TreeNode(\"C\") tree.left.left = TreeNode(\"D\") tree.right.right = TreeNode(\"E\") tree.right.right.right = TreeNode(\"F\") tree.right.right.right = TreeNode(\"F\") print(BFS(tree)) 打印出来 1234567ABCDEF[&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;, &apos;E&apos;, &apos;F&apos;] 树的BFS算法变种从上到下打印二叉树 IIIleetcode地址：https://leetcode-cn.com/problems/cong-shang-dao-xia-da-yin-er-cha-shu-iii-lcof/ 123456789101112131415161718192021222324252627请实现一个函数按照之字形顺序打印二叉树，即第一行按照从左到右的顺序打印，第二层按照从右到左的顺序打印，第三行再按照从左到右的顺序打印，其他行以此类推。 例如:给定二叉树: [3,9,20,null,null,15,7], 3 / \\ 9 20 / \\ 15 7返回其层次遍历结果：[ [3], [20,9], [15,7]] 分析题目 这道题，主要就是用BFS去做遍历，然后遍历的同时判断现在遍历到第几层，然后根据层数转换打印的次序，这道题不算太难 首先先写个BFS模版 12345678910111213141516queue = deque([root])result = []while queue: node = queue.popleft() result.append(node.val) print(node.val) left = node.left if left != None: queue.append(left) right = node.right if right != None: queue.append(right)return result 根据需求，首先先解决输出是 12345[ [3], [20,9], [15,7]] 的问题，其实说明内部嵌套多个队列，改写一下，当遍历每一层的时候，添加到新的队列当中 12345678910111213141516while queue: # 定义一个新的队列 tmp = deque() # 判断队列循环到哪里 for i in range(len(queue)): node = queue.popleft() # tmp 队列 添加 val数据 tmp.append(node.val) left = node.left if left != None: queue.append(left) right = node.right if right != None: queue.append(right) result.append(list(tmp))return result 接下来就要判断循环的行号是偶数还是计数 123456# 如果是偶数if len(result) % 2: # 添加到队列左端 tmp.appendleft(node.val)else: tmp.append(node.val) 最终的代码是 12345678910111213141516171819202122232425262728293031from collections import dequeclass TreeNode: def __init__(self, x): self.val = x self.left = None self.right = Nonedef BFS(root): if root == None: return [] queue = deque([root]) result = [] while queue: tmp = deque() for i in range(len(queue)): print(len(result)) node = queue.popleft() if len(result) % 2: tmp.appendleft(node.val) else: tmp.append(node.val) if node.left != None: queue.append(node.left) if node.right != None: queue.append(node.right) result.append(list(tmp)) return result 结尾我这里只总结了二叉树的几个题目，其实还不是很全，最近实在是太忙啦！后面会补全图算法的BFS和DFS算法，大家多多期待吧！","categories":[],"tags":[{"name":"算法","slug":"算法","permalink":"https://yemilice.com/tags/%E7%AE%97%E6%B3%95/"}],"keywords":[]},{"title":"2020的回顾和2021的展望","slug":"2020的回顾和2021的展望","date":"2021-01-04T01:13:05.000Z","updated":"2021-01-04T01:42:56.078Z","comments":true,"path":"2021/01/04/2020的回顾和2021的展望/","link":"","permalink":"https://yemilice.com/2021/01/04/2020%E7%9A%84%E5%9B%9E%E9%A1%BE%E5%92%8C2021%E7%9A%84%E5%B1%95%E6%9C%9B/","excerpt":"","text":"前言现在是2021年1月4日早上的九点十四分 这是我2021开年第一篇日志，就为2020做一个回顾和2021年做一个展望吧。 回顾20202020其实是一个特殊的年份，想一想似乎大家都在生活当中挣扎。 其实我也一样，因为疫情的缘故，1月到3月都是在家办公，在家办公，其实真的挺累，每天没日没夜的编写代码，独立开发项目，并且独立测试，同事们有时候沟通也不足，每天都在疲惫当中度过。 但是堪堪顶住压力，项目顺利开发完毕并且上线，前几天我居然还在我司官网上看见了我开发的项目，居然还被放在首页拿去招标，而且居然TM的招上了央视的项目。所以说，认真做的东西，必有回响。 2020年的个人资产，增加了一套房子，其实买房并不在我计划之中，一直是母亲希望我有个地方住，她舍不得看着我搬家，看着我四处跑。一开始我真的是拒绝的，因为我应该会出国，但是疫情打乱了一切部署。 幸好，家里颇有资产，买房子也不至于伤筋动骨，房贷比起很多大佬都可以忽略不计，所以对于我的未来，我要搬进新家了，不用再租房子了，突然觉得自己多了一份责任，或者说多了一份辛苦。 2020年，看书方面，依旧保持20+的读书量，今年其实相比去年，懈怠了一些，不知道是不是我年纪大了（大雾 缺乏一点点耐心和恒心，自己也变懒了，唉，这样可不行啊。 2021年的展望阅读/看书方面还是老样子，读书至少要20+本，并且一定要往深里钻研 我初步定为 k8s部分 ElasticSearch部分 Python，java，Golang部分 数据库部分 前端部分 心理学部分 历史学部分 文学部分 经济学/投资部分 这就是我2021要看的书了，希望大家互相监督，互相进步。 工作/技术方面我打算往游戏/安全方面转。 因为原本我做的都是一些偏业务类的东西 我打算在游戏服务器，或者安全工程师上面发力，并不打算继续做偏业务的东西 业务代码写久了，我感觉会丢失一些计算机思维，所以，2021跳槽势在必行。 我会首先选择稳定一些的游戏大厂，小厂是肯定不考虑的。 在2021年，首先要提升的肯定是外语和算法水平，其他的东西都可以后期弥补，外语和算法是一定要补强的。 生活/娱乐方面我打算在新房子里搭建一个音乐工作室 还是老样子，2020年中国新说唱一轮游之后，我发现我和现在的rapper还是有非常大的差距，补强，补强，非常重要，编曲水平，出歌水平，也是很重要的。所以，搭建音乐工作室，也是自己副业走向的第一步。 身体方面，每天还是依旧保持半小时的锻炼时间，不能停止！身体第一！ 每年体检一次，自费最贵的体检。 做饭之类的。。。凑合做吧。 结尾2021最重要的三件事 跳槽 学习 锻炼 希望我都可以做到，2021年12/31日我会回来，看看这篇文章，是否我都做到了上面所说。 over。","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"}],"keywords":[]},{"title":"ElasticSearch定义自己的分词器词典（检索生僻词）","slug":"ElasticSearch定义自己的分词器词典（检索生僻词）","date":"2020-12-08T07:20:23.000Z","updated":"2020-12-08T07:33:02.107Z","comments":true,"path":"2020/12/08/ElasticSearch定义自己的分词器词典（检索生僻词）/","link":"","permalink":"https://yemilice.com/2020/12/08/ElasticSearch%E5%AE%9A%E4%B9%89%E8%87%AA%E5%B7%B1%E7%9A%84%E5%88%86%E8%AF%8D%E5%99%A8%E8%AF%8D%E5%85%B8%EF%BC%88%E6%A3%80%E7%B4%A2%E7%94%9F%E5%83%BB%E8%AF%8D%EF%BC%89/","excerpt":"","text":"前言ElasticSearch当中，有许多的分词器供我们调用，中文用的最多的就是IK分词器，一些基本的词汇都包含了。 但是，一些基本的生僻词就很难检索了，比如一些特定专业词汇，或者一些流行词汇之类的，所以这篇文章，我会讲一下自定义分词器词典的设置和扩展，让我们能够检索的词汇变的更多。如果能帮到你，我也会很开心！ 分词器怎么分词的首先要明白分词器分词的原理，这个我的blog以前说过，中文分词遵循的是最大匹配算法，Maximum https://yemilice.com/2020/08/21/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%9A%84%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/ 可以参看一下这篇博客，说的很清楚了。 我们来举个简单的分词例子 看下这个分词怎么分的：首先 123456GET http://10.0.9.28:9200/_analyze&#123; \"analyzer\": \"ik_max_word\", \"text\": \"年轻人不讲武德\"&#125; 分词的结果是 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&#123; \"tokens\": [ &#123; \"token\": \"年轻人\", \"start_offset\": 0, \"end_offset\": 3, \"type\": \"CN_WORD\", \"position\": 0 &#125;, &#123; \"token\": \"年轻\", \"start_offset\": 0, \"end_offset\": 2, \"type\": \"CN_WORD\", \"position\": 1 &#125;, &#123; \"token\": \"人\", \"start_offset\": 2, \"end_offset\": 3, \"type\": \"CN_CHAR\", \"position\": 2 &#125;, &#123; \"token\": \"不讲\", \"start_offset\": 3, \"end_offset\": 5, \"type\": \"CN_WORD\", \"position\": 3 &#125;, &#123; \"token\": \"讲武\", \"start_offset\": 4, \"end_offset\": 6, \"type\": \"CN_WORD\", \"position\": 4 &#125;, &#123; \"token\": \"武德\", \"start_offset\": 5, \"end_offset\": 7, \"type\": \"CN_WORD\", \"position\": 5 &#125; ]&#125; 这就是最大粒度的分词结果 举个例子， 你搜 “武德”，这句话就能搜出来 你搜 “年轻人”， 这句话也能搜出来 但是你要搜 “人不”，你铁定毛都搜不出来 为啥，因为这个没被分词儿，你肯定是什么都搜不到的。 我估摸着，你没弄明白我说的啥意思？你那么聪明，智慧，美丽，大方，你肯定能懂吧。 咱们拿生僻词举个例子 假设，我现在搜 “意带利黑手哥” 让我们和他比划比划 让你比划比划，让你知道什么叫黑手！ 123456GET http://10.0.9.28:9200/_analyze&#123; \"analyzer\": \"ik_max_word\", \"text\": \"意带利黑手哥\"&#125; 分词出的结果就是 123456789101112131415161718192021222324252627282930313233343536373839&#123; \"tokens\": [ &#123; \"token\": \"意\", \"start_offset\": 0, \"end_offset\": 1, \"type\": \"CN_CHAR\", \"position\": 0 &#125;, &#123; \"token\": \"带\", \"start_offset\": 1, \"end_offset\": 2, \"type\": \"CN_CHAR\", \"position\": 1 &#125;, &#123; \"token\": \"利\", \"start_offset\": 2, \"end_offset\": 3, \"type\": \"CN_CHAR\", \"position\": 2 &#125;, &#123; \"token\": \"黑手\", \"start_offset\": 3, \"end_offset\": 5, \"type\": \"CN_WORD\", \"position\": 3 &#125;, &#123; \"token\": \"哥\", \"start_offset\": 5, \"end_offset\": 6, \"type\": \"CN_CHAR\", \"position\": 4 &#125; ]&#125; 所以你搜 “意带利”,或者 “意带利黑手哥” 是肯定没这几个词儿的。 那就不能和他比划了。 但是我们就是要这个词可以被检索 那么我们现在该怎么做呢？ 分词器词汇的扩展百度，谷歌每天都会更新热点词汇，像 “意带利黑手”，“三日杀神”这样的人物，早就存在词库里面了。 当然，我ElasticSearch作为数一数二的检索引擎，能没这功能吗，其实也是有的 一般我们如果要定义自己的词典，首先就要去修改ik的配置 ik的配置一般放置在 1/etc/elasticsearch/analysis-ik 这下面有个文件叫做 IKAnalyzer.cfg.xml 打开它 12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=\"ext_dict\"&gt;&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=\"ext_stopwords\"&gt;&lt;/entry&gt; &lt;!--用户可以在这里配置远程扩展字典 --&gt; &lt;!-- &lt;entry key=\"remote_ext_dict\"&gt;words_location&lt;/entry&gt; --&gt; &lt;!--用户可以在这里配置远程扩展停止词字典--&gt; &lt;!-- &lt;entry key=\"remote_ext_stopwords\"&gt;words_location&lt;/entry&gt; --&gt;&lt;/properties&gt; 这注释，很清楚啊，我想。。大家不需要我再解释参数了吧。 如何定义扩展字典？ 首先看一下目录下面的几个文件 IKAnalyzer.cfg.xml：用来配置自定义词库 main.dic：ik 原生内置的中文词库，总共有 27 万多条 quantifier.dic：放了一些单位相关的词 suffix.dic：放了一些后缀 surname.dic：中国的姓氏 stopword.dic：英文停用词 这里可以看到，我们有两个方法去增加扩展词 一个是直接修改main.dic，进行词汇追加，另外一个就是重新写入一个dic文件，直接在IKAnalyzer.cfg.xml里面进行修改。这两种方法都介绍一下吧。 追加词汇直接在main.dic里面追加词汇 “意带利黑手” 然后重启ElasticSearch 再进行一次检索 123456GET http://10.0.9.28:9200/_analyze&#123; \"analyzer\": \"ik_max_word\", \"text\": \"意带利黑手\"&#125; 返回如下 123456789101112131415161718&#123; \"tokens\": [ &#123; \"token\": \"意带利黑手\", \"start_offset\": 0, \"end_offset\": 5, \"type\": \"CN_WORD\", \"position\": 0 &#125;, &#123; \"token\": \"黑手\", \"start_offset\": 3, \"end_offset\": 5, \"type\": \"CN_WORD\", \"position\": 1 &#125; ]&#125; 这下就能搜到了。 新建字典首先，我们在/etc/elasticsearch/analysis-ik里面建个字典，名字叫 new.dic 在里面写入我们要检索的词 然后修改配置 12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\"&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=\"ext_dict\"&gt;./new.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=\"ext_stopwords\"&gt;&lt;/entry&gt; &lt;!--用户可以在这里配置远程扩展字典 --&gt; &lt;!-- &lt;entry key=\"remote_ext_dict\"&gt;words_location&lt;/entry&gt; --&gt; &lt;!--用户可以在这里配置远程扩展停止词字典--&gt; &lt;!-- &lt;entry key=\"remote_ext_stopwords\"&gt;words_location&lt;/entry&gt; --&gt;&lt;/properties&gt; 重启elasticsearch 然后继续检索 123456GET http://10.0.9.28:9200/_analyze&#123; \"analyzer\": \"ik_max_word\", \"text\": \"意带利黑手\"&#125; 返回如下 123456789101112131415161718&#123; \"tokens\": [ &#123; \"token\": \"意带利黑手\", \"start_offset\": 0, \"end_offset\": 5, \"type\": \"CN_WORD\", \"position\": 0 &#125;, &#123; \"token\": \"黑手\", \"start_offset\": 3, \"end_offset\": 5, \"type\": \"CN_WORD\", \"position\": 1 &#125; ]&#125; 这就能和黑手哥比划比划了。 扩展字典的逻辑，大概就是这样。 结尾这两天在做智能检索，自己的ElasticSearch还是要多补补啊，最近成都疫情又变严重了，sad，要老老实实在家待一阵好好学习了。 希望能够帮到大家，希望大家多提意见，多和我比划比划。 年底了，大家要快乐呀！","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"ElasticSearch高级用法(Golang实现)","slug":"ElasticSearch高级用法(Golang实现)","date":"2020-12-02T06:38:21.000Z","updated":"2020-12-02T07:03:58.388Z","comments":true,"path":"2020/12/02/ElasticSearch高级用法(Golang实现)/","link":"","permalink":"https://yemilice.com/2020/12/02/ElasticSearch%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95(Golang%E5%AE%9E%E7%8E%B0)/","excerpt":"","text":"前言前阵子开发了一个检索服务器，用了一些Es的高阶功能，网上随便看了一圈，基本没有人公开这些功能的中文版，我寻思咱们不能只满足了自己，不满足其他老哥吧，所以，我将开发中用到的Es高阶功能总结输出. 此次开发 我用的是 Golang 1.13.6 Es的版本是6.3.2， Package: “github.com/olivere/elastic” 请注意。 定义Mapping模板首先，先展示一下我定义的mapping模板，这个模板是我们创建index之前定义的，这个十分重要！十分重要！十分重要！切记切记！ 首先我直接展示一下我的mapping定义，接下来我会一点点的说明每个参数的含义 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758var Contentmapping = `&#123; \"settings\": &#123; \"number_of_shards\": 5, \"number_of_replicas\": 1, \"codec\": \"best_compression\", \"max_result_window\": \"100000000\" &#125;, \"mappings\": &#123; \"doc\": &#123; \"properties\": &#123; \"name\": &#123; \"type\": \"keyword\" &#125;, \"id\": &#123; \"type\": \"keyword\" &#125;, \"data\": &#123; \"type\": \"nested\", \"properties\": &#123; \"value\": &#123; \"type\": \"text\", \"fields\": &#123; \"keyword\": &#123; \"ignore_above\": 256, \"type\": \"keyword\" &#125; &#125; &#125;, \"key\": &#123; \"type\": \"text\", \"fields\": &#123; \"keyword\": &#123; \"ignore_above\": 256, \"type\": \"keyword\" &#125; &#125; &#125; &#125; &#125;, \"size\": &#123; \"type\": \"long\" &#125;, \"last_mod_time\": &#123; \"format\": \"yyyy-MM-dd HH:mm:ss\", \"type\": \"date\" &#125;, \"user\": &#123; \"type\": \"keyword\" &#125;, \"content\": &#123; \"analyzer\": \"ik_smart\", \"term_vector\": \"with_positions_offsets\", \"type\": \"text\" &#125; &#125; &#125; &#125; &#125;` mapping主字段，我定义了如下几个字段 字段 字段说明 字段mapping类型 字段举例 name 姓名 keyword YK_example id id keyword 12345678 user 用户 keyword YK content 全文检索字段 text 中国123…… size 大小 long 14500 data 嵌套数据 nested [{key:123,value:456}, {key:789,value:101112} last_mod_time 最后修改时间 date 2020-12-02 12:00:00 这样是不是就说的很清楚了，下面我细致说一下mapping里面这种的设计方法吧 首先是keyword类型，如果你的字段，有全检索的需求，也就是完全匹配的需求，你需要使用这个类型，但是keyword能完全检索的长度有限，也就是说，他只能完全匹配指定长度的数据，我查了一下，大概是2766个UTF-8字节数，所以超过这个数的将不会被检索到 我这里面出现了ignore_above这个东西，这个东西是：最大可被检索字段 意思就是，当超过我定义的ignore_above的字符数的时候，多出来的将不会被检索到，这里是根据业务场景自己划分。 long类型，一般用来存储数字，这种情况，大部分都是存储文件大小之类的，一开始一定要用long定义，因为int类型大小超过100000会直接存不进去的。 text类型，这里一般都是存储那种特别大的文字数据的，比如你存了一个PDF进来，或者存了一本字典进来，就需要用text存储，text理论上支持存储无限大的文字数据。这里不想keyword，它不会被支持全文检索和精准匹配。需要定义分词器/在检索语句上下功夫 nested类型，这里一般是复杂嵌套，类似列表中包含字典的操作，[{key:123,value:456}，类似这样 date类型，这里一般是时间格式，你要自己格式化，”format”: “yyyy-MM-dd HH:mm:ss”,这种比对的就是：2020-12-02 12:00:00，如果你是2020-12-02 12:00:00:22，是肯定会导入失败的 大概就是这些，包含的部分也就足够你一般使用了，还有一些mapping的高级用法，后面我会单独写博客分析，本篇内容不是这个，此处进行跳过了。 定义分词器上面说了，分词器是做全文检索的时候必须要用的，分词器的功能就是能够让你对text字段进行检索，text字段是不可被全文检索的，因为它的大小不定，但是，用了分词器能让你进行全文检索，就像这样 所以，定义分词的的参数是 12345\"content\": &#123; \"analyzer\": \"ik_smart\", \"term_vector\": \"with_positions_offsets\", \"type\": \"text\" &#125; 加一个analyzer参数，指定某个字段使用ik分词器，这里可以使用 1&quot;analyzer&quot;: &quot;ik_smart&quot;, 也可以使用 1&quot;analyzer&quot;: &quot;ik_max_word&quot;, 这里根据你的业务自己选择 定义最大展示条数一般ElasticSearch为了保证一次不拿取过多数据，会进行一个限制，限制最大不能读取10000条数据，但是我们有些时候因为一些特殊原因需要拿取超过10000条数据（翻页 这时候有两种方法 第一种直接通过Es的接口 12345PUT _all/_settings &#123; \"index.max_result_window\":200000 &#125; 这种好处就是随时随地可以改 第二种方法就是，定义mapping的时候，直接定义 123\"settings\": &#123; \"max_result_window\": \"100000000\" &#125;, 我个人还是比较喜欢第二种啦，因为事先定义好总比发现了问题再去调接口好一百倍。 根据模板创建indexmapping现在有了，咱们现在要做的就是，利用mapping创建一个index，涉及一些连接Es之类的，我在这就不说了，我以前写过一个Golang调用Es的接口，大家要不自己去瞅瞅？ 1https://yemilice.com/2020/05/14/golang%E5%B0%81%E8%A3%85elasticsearch%E5%B8%B8%E7%94%A8%E5%8A%9F%E8%83%BD/ 直接调用一把代码 12345678910111213141516171819202122232425262728293031323334func (Es *Elastic) CreateIndex(index, mapping string) bool &#123; // 判断索引是否存在 exists, err := Es.Client.IndexExists(index).Do(context.Background()) if err != nil &#123; fmt.Printf(\"&lt;CreateIndex&gt; some error occurred when check exists, index: %s, err:%s\", index, err.Error()) return false &#125; if exists &#123; fmt.Printf(\"&lt;CreateIndex&gt; index:&#123;%s&#125; is already exists\", index) return true &#125; // 创建index createIndex, err := Es.Client.CreateIndex(index).Body(mapping).Do(context.Background()) if err != nil &#123; fmt.Printf(\"&lt;CreateIndex&gt; some error occurred when create. index: %s, err:%s\", index, err.Error()) return false &#125; if !createIndex.Acknowledged &#123; // Not acknowledged fmt.Printf(\"&lt;CreateIndex&gt; Not acknowledged, index: %s\", index) return false &#125; return true&#125;func main() &#123; // 初始化连接Es es, err := InitES() if err != nil &#123; return &#125; // 创建ES es.CreateIndex(\"text\", Contentmapping)&#125; 然后我们去查看我们的Es 就可以看到详细的信息了。大概就完成了 根据模板上传数据Golang有个很奇葩的地方，就是，你必须要按照规则传递数据，也就是事先定义好的结构体，如果你不按照这个规矩传，那你肯定是传不进去的，我这边模拟一个简单的数据传递逻辑吧，大家都是聪明孩子，肯定一点就通 首先，观察一下咱们的mapping，定义一个结构体，用来传递数据/输出数据 12345678910111213141516171819202122232425262728293031323334type ContentEsInfo struct &#123; Name string `json:\"name\"` ID string `json:\"id\"` Size uint64 `json:\"size\"` LastModTime string `json:\"last_mod_time\"` User string `json:\"user\"` Data []DataType `json:\"data\"` Content string `json:\"content\"`&#125;type DataType struct &#123; Key string `json:\"key\"` Value string `json:\"value\" `&#125;//Put 传入index名， typ，还有组合成的结构体func (Es *Elastic) Put(index string, typ string, bodyJSON interface&#123;&#125;) (bool, error) &#123; _, err := Es.Client.Index(). Index(index). Type(typ). BodyJson(bodyJSON). Do(context.Background()) if err != nil &#123; // Handle error fmt.Printf(\"&lt;Put&gt; some error occurred when put. err:%s\", err.Error()) return false, err &#125; return true, nil&#125;func main() &#123; z := ContentEsInfo&#123;Name: \"yk\", ID: \"ak47\", Size: 10423, Data: []DataType&#123;&#123;Key: \"1\", Value: \"2\"&#125;&#125;, User: \"yk123\", LastModTime: \"2020-01-01 12:00:00\", Content: \"dssads\"&#125; es.Put(\"content_test\", \"doc\", z)&#125; 传完了咱们看一下Es，里面已经有数据了。 如图： 输出字段既然已经有字段了，我们现在要输出字段，看下检索结果，同理，你还是需要结构体，我告诉你，你就逃不开和结构体的孽缘，哈哈哈哈！ 12345678910111213141516171819202122232425262728type ContentEsInfo struct &#123; Name string `json:\"name\"` ID string `json:\"id\"` Size uint64 `json:\"size\"` LastModTime string `json:\"last_mod_time\"` User string `json:\"user\"` Data []DataType `json:\"data\"` Content string `json:\"content\"`&#125;//GetMsg 获取Msgfunc (Es *Elastic) GetMsg(indexname, typ string) &#123; var contentinfo ContentEsInfo res, _ := Es.Client.Search(indexname).Type(typ).Do(context.Background()) //从搜索结果中取数据的方法 for _, item := range res.Each(reflect.TypeOf(contentinfo)) &#123; if t, ok := item.(ContentEsInfo); ok &#123; fmt.Println(t) &#125; &#125;&#125;func main() &#123; es, err := InitES() if err != nil &#123; return &#125; es.GetMsg(\"content_test\", \"doc\")&#125; 这边输出了： 1&#123;yk ak47 10423 2020-01-01 12:00:00 yk123 [&#123;1 2&#125;] dssads&#125; 输出指定字段有些时候你不想显示太多字段？没问题，可以让Es返回的时候指定只显示某些字段。有些时候如果某个字段特别大，我们可以直接屏蔽它，让它不包装返回。 假设我们要让content这个字段不返回 123456789101112131415161718192021//ShieldAnotherfield 屏蔽指定字段func (Es *Elastic) ShieldAnotherfield(indexname, typ string) &#123; var contentinfo ContentEsInfo //指定返回的字段 fsc := elastic.NewFetchSourceContext(true).Include(\"name\", \"type\", \"user\", \"size\", \"last_mod_time\", \"data\") res, _ := Es.Client.Search(indexname).Type(typ).FetchSourceContext(fsc).Do(context.Background()) //从搜索结果中取数据的方法 for _, item := range res.Each(reflect.TypeOf(contentinfo)) &#123; if t, ok := item.(ContentEsInfo); ok &#123; fmt.Println(t) &#125; &#125;&#125;func main() &#123; es, err := InitES() if err != nil &#123; return &#125; es.ShieldAnotherfield(\"content_test\", \"doc\")&#125; 可以查看一下返回 1&#123;yk 10423 2020-01-01 12:00:00 yk123 [&#123;1 2&#125;] &#125; 和上面对比一下，是不是少了dsds那个字段，那个字段就是content，如果当content特别大的时候，它就相当有作用。 翻页的实现和优化翻页，这是老生常谈的问题了，我的blog里面写过Es的翻页优化方法，其实很多人无脑推scroll动态翻页，这是不可取的，有些时候，你要根据自己的需求来定义翻页的逻辑，不能说别人用scroll，你就scroll，from+size也能满足一些不一样的需求。 当你的翻页需要支持跳页，指定页数翻页，最前/最后翻页，随机跳页的时候，我建议你用from+size 当你的翻页是动态的，例如下拉加载，例如往下滑持续加载，动态加载的时候，你要用scroll深度翻页，因为这个才是对你机器负载最低的一种翻页模式。 好了，我们来实现翻页吧。 我这里因为要支持随机跳页，所以我用了from+size的逻辑 12345678910111213141516171819//FromSize 翻页方法func (Es *Elastic) FromSize(indexname, typ string, size, from int) &#123; var contentinfo ContentEsInfo res, _ := Es.Client.Search(indexname).Type(typ).Size(size).From(from).Do(context.Background()) //从搜索结果中取数据的方法 for _, item := range res.Each(reflect.TypeOf(contentinfo)) &#123; if t, ok := item.(ContentEsInfo); ok &#123; fmt.Println(t) &#125; &#125;&#125;func main() &#123; es, err := InitES() if err != nil &#123; return &#125; es.FromSize(\"content_test\", \"doc\", 10, 0)&#125; 这里输出 1&#123;yk ak47 10423 2020-01-01 12:00:00 yk123 [&#123;1 2&#125;] dssads&#125; 这里的size，你可以理解为每页展示条数， 而from，你可以理解为页数， 要注意，这是从0开始1计算的，类似列表，第一个下标为0，如果你将size改为1，那么将搜索不到数据，理由是：第11条数据不存在，因为我们的数据库只有1条数据（暂时 高亮检索关键字ElasticSearch支持高亮返回，回到刚刚咱们讨论的话题 类似百度文库那样的搜索逻辑，如果检索到之后返回，高亮我们检索的值，这种一般怎么处理呢。 这种其实Es也是支持的 我们现在来一发检索 123456789101112131415161718192021222324252627282930313233//HighlightMsg 高亮方法func (Es *Elastic) HighlightMsg(indexname, typ string, size, from int, keyword string) &#123; // var contentinfo ContentEsInfo boolQ := elastic.NewBoolQuery() boolZ := elastic.NewBoolQuery() // 定义highlight highlight := elastic.NewHighlight() // 指定需要高亮的字段 highlight = highlight.Fields(elastic.NewHighlighterField(\"content\")) // 指定高亮的返回逻辑 &lt;span style='color: red;'&gt;...msg...&lt;/span&gt; highlight = highlight.PreTags(\"&lt;span style='color: red;'&gt;\").PostTags(\"&lt;/span&gt;\") escontent := elastic.NewMatchQuery(\"content\", keyword) boolZ.Filter(boolQ.Should(escontent)) res, _ := Es.Client.Search(indexname).Type(typ).Highlight(highlight).Query(boolZ).Do(context.Background()) // 高亮的输出和doc的输出不一样，这里要注意，我只输出了匹配到高亮的第一个词 for _, highliter := range res.Hits.Hits &#123; fmt.Println(highliter.Highlight[\"content\"][0]) &#125;&#125;func main() &#123; es, err := InitES() if err != nil &#123; return &#125; // 我们检索一下带有名气的doc，然后高亮输出 es.HighlightMsg(\"content_test\", \"doc\", 10, 0, \"名气\")&#125; 看一下返回 1234那就当因为刘先&lt;span style='color: red;'&gt;名气&lt;/span&gt;太大，曹操不得不展现出极度的宽容吧，但是神奇的是后面的“周不疑之死”。 看到了没，“名气”这个词语被高亮输出了。 全文检索-精准度调整因为分词器的缘故，我们在检索词汇的时候，经常会搜索到一些不相干的词，例如 我们搜索”今天是美好的一天”，我们想要的自然是匹配到 “今天是美好的一天” 的所有doc，但是分词器不会这么想，分词器会将这句话进行分词 切分为：[今天，美好，一天，美好的，美好的一天] 这样Es在检索的时候，就会把上面分词了的数据也检索到，意思就是，包含有“今天”，“美好”，“一天”。。。。之类的数据都可以被检索出来，这绝对不是我们想要的 但是我们可以设定短句搜索，并且调整它的精准度 12345678910111213141516171819202122232425262728293031323334//Precisesearch 精准检索func (Es *Elastic) Precisesearch(indexname, typ string, size, from int, keyword string) &#123; // var contentinfo ContentEsInfo boolQ := elastic.NewBoolQuery() boolZ := elastic.NewBoolQuery() // 定义highlight highlight := elastic.NewHighlight() // 指定需要高亮的字段 highlight = highlight.Fields(elastic.NewHighlighterField(\"content\")) // 指定高亮的返回逻辑 &lt;span style='color: red;'&gt;...msg...&lt;/span&gt; highlight = highlight.PreTags(\"&lt;span style='color: red;'&gt;\").PostTags(\"&lt;/span&gt;\") // 短句匹配 escontent := elastic.NewMatchPhrasePrefixQuery(\"content\", keyword).MaxExpansions(10) boolZ.Filter(boolQ.Should(escontent)) res, _ := Es.Client.Search(indexname).Type(typ).Highlight(highlight).Query(boolZ).Do(context.Background()) for _, highliter := range res.Hits.Hits &#123; fmt.Println(highliter.Highlight[\"content\"][0]) &#125;&#125;func main() &#123; es, err := InitES() if err != nil &#123; return &#125; // 搜个冷门词，ik里绝壁没有的 es.HighlightMsg(\"content_test\", \"doc\", 10, 0, \"渔阳三檛\")&#125; 得到返回值 123456想想祢衡的类似表演（&lt;span style='color: red;'&gt;渔&lt;/span&gt;&lt;span style='color: red;'&gt;阳&lt;/span&gt;&lt;span style='color: red;'&gt;三&lt;/span&gt;&lt;span style='color: red;'&gt;檛&lt;/span&gt;），曹操都只能表示惹不起，恭送出许。那就当因为刘先名气太大，曹操不得不展现出极度的宽容吧，但是神奇的是后面的“周不疑之死”。 这就匹配到了，并且也不会出现乱匹配的问题了。 总结大概也就这么多了，其实很多Es的检索逻辑在我以前的blog里面都写过了 再放送一遍旧文章地址： 1https://yemilice.com/2020/05/14/golang%E5%B0%81%E8%A3%85elasticsearch%E5%B8%B8%E7%94%A8%E5%8A%9F%E8%83%BD/ 今天所有写过的代码都在： 1https://github.com/Alexanderklau/Go_poject/blob/master/Go-Elasticdb/ElasticSearch_adv_use/Es_adv.go 大家可以自己下下来自己改着玩玩 这次用Es开发了一个文件检索服务器，作词作曲又是我自己，自认为在Es这个部分，我应该算是接触不少了吧，最近我在看Es源码，准备弄明白Es到底为什么检索那么快，下一篇不是Python三巨头就是Mysql vs Es，大家期待吧！ 年底了，希望大家都保重身体啊。 12345678910111213翻看着年初自己许下的承诺到了如今却只有沉默告诉镜子里的他你已经不小了你该学会衡量什么是你想要的你可以无畏自由的向天空宣泄大喊着我要走自己的路check~","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"完全搞懂Python的线程机制","slug":"完全搞懂Python的线程机制","date":"2020-12-01T05:28:46.000Z","updated":"2020-12-01T05:33:21.466Z","comments":true,"path":"2020/12/01/完全搞懂Python的线程机制/","link":"","permalink":"https://yemilice.com/2020/12/01/%E5%AE%8C%E5%85%A8%E6%90%9E%E6%87%82Python%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%9C%BA%E5%88%B6/","excerpt":"","text":"前言总觉得用了Python那么久，感觉隔一层面纱似的，只是会用而已。 现在Python更新了3.9，越来越厉害了，多了很多新的语法特性。 想想自己，也不能总是写一些Golang的东西，Python也要持续跟上，所以打算开一个Python三巨头的坑，把Python的线程，进程，协程都讲明白，这样第一个是让我加深理解，第二个是让我彻底搞懂这三者的机制，我认为这样我才可以走的更远。 在开发的过程当中，我们总是需要去提高效率，一般在Python里面，我们经常会听到所谓多线程，多进程，加上现在的协程的诸多方法去解决性能问题，那么，到底这些术语到底是个什么意思，我们什么时候用什么方法，才是最合适的呢？这才是促使我写这篇文章的原因吧。 因为这些东西，应该是Python最核心的了，搞懂这个，Python也就没什么特别难的问题了。所以，我们开始吧 1234567从来不畏惧到底明天会是什么模样活在今天告诉你生命不只一种颜色咬牙挺住却坚信黑暗之后即是黎明解剖生活才能看到未来的光 Python的多线程是什么首先，线程是什么，说的简单一点，线程就是进程的儿子，一个进程可以搞出多个线程，但是一个线程只能有一个爹（进程），不允许随便乱认爹（进程）。 这就好比你看电影，电影是一个进程，里面的画面是一个线程，声音是一个线程，字幕又是一个线程，这就是线程的一种表现。 如果是系统执行进程，首先需要划分独立的进程空间/内存，但是线程就不会这么麻烦。 线程是独立执行的，并且也是并发的，占用资源也小，一个线程可以去创建/杀死另一个线程，相当于“子子孙孙无穷匮也”，并且线程之间还支持通信，可以共享其中的数据/内存等等。 上面这些都是线程的优点，但是！但是！但是！Python的线程和这个不一样！ Python的线程其实是个假的，为啥呢，因为Python有GIL全局锁。 不知道你们看过《无限恐怖》这本小说没有，里面有个东西叫做基因锁，因为有基因锁的存在，导致人类的各项机能被限制了，同理，GIL全局锁也是一样，它的逻辑就是，只要你用了带GIL锁的解释器，任何时候，你都只能，也只可以在同一时间执行一个线程。 带GIL锁的解释器有哪些呢？当然是我现在说的CPython啦！ CPython用C实现的，用的人也最多，所以为什么市面上的教材都说Python的线程不好使，是因为大家全都是用的CPython。 有点儿绕吧，其实意思就是，Python的多线程实际上是个伪多线程，并不是真正的多线程，实际上，无论如何，它只能保证一个线程执行。 我来描述一下Python多线程执行的逻辑 12345678线程1获取到GIL锁执行业务代码线程1释放GIL锁线程2获取到GIL锁执行业务代码线程2释放GIL锁...... 这个是不是贼TM绕，我写个代码给大家伙儿瞅瞅到底这个是怎么表现出来的 12345678910111213141516171819202122232425262728293031323334353637383940import threadingimport timeexitFlag = 0# 继承的方法写一个多线程逻辑class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() # 这里模拟一个阻塞 time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()# join等待thread1.join()thread2.join()print (\"退出主线程\") 这里用了一个继承的方法，写了一个多线程逻辑 这里输出 123456789101112131415开始线程：Thread-1开始线程：Thread-2Thread-1: Tue Dec 1 09:58:21 2020Thread-2: Tue Dec 1 09:58:22 2020Thread-1: Tue Dec 1 09:58:22 2020Thread-1: Tue Dec 1 09:58:23 2020Thread-2: Tue Dec 1 09:58:24 2020Thread-1: Tue Dec 1 09:58:24 2020Thread-1: Tue Dec 1 09:58:25 2020退出线程：Thread-1Thread-2: Tue Dec 1 09:58:26 2020Thread-2: Tue Dec 1 09:58:28 2020Thread-2: Tue Dec 1 09:58:30 2020退出线程：Thread-2退出主线程 发现了没，这个，有个时间差，这两根本不是同时去运行的，这就是GIL的石锤 再看个图，这就是GIL的运行流程 整明白了嘛？ 但是你会说，哎呀，我没感觉到缓慢阿，害挺快的，是，这就是我下面要聊的，它到底用了什么技术，才能让我们感觉到挺快的。 Python的多线程在代码部分是怎么实现的？又涉及到看源码的东西了,这里首先追踪一把，threading的代码放置在 1https://github.com/python/cpython/blob/3.9/Lib/threading.py 先从入口的Start追踪 123456789101112131415161718192021222324252627282930313233def start(self): \"\"\"Start the thread's activity. It must be called at most once per thread object. It arranges for the object's run() method to be invoked in a separate thread of control. This method will raise a RuntimeError if called more than once on the same thread object. \"\"\" # 线程是否初始化（这里就是刚那个init函数 if not self._initialized: raise RuntimeError(\"thread.__init__() not called\") # 设置线程的开始状态（把线程状态置为start if self._started.is_set(): raise RuntimeError(\"threads can only be started once\") # 加锁，调用GIL with _active_limbo_lock: _limbo[self] = self # 去启动新的线程 try: _start_new_thread(self._bootstrap, ()) # 如果启动出了问题 except Exception: # 把锁给del了 with _active_limbo_lock: del _limbo[self] raise # 释放锁，阻塞。直到被唤醒/超时 self._started.wait() 其实threading的代码写的很好，已经大概把流程和步骤都说明白了，涉及到lock的部分是C写的, 首先追踪溯源，看一下启动线程的C代码 123456789101112131415void PyEval_InitThreads(void)&#123; if (gil_created()) return; // 创建GIL锁 create_gil(); // 申请GIL锁 take_gil(PyThreadState_GET()); // 主线程 main_thread = PyThread_get_thread_ident(); // 如果没有等待锁 if (!pending_lock) // 创建等待锁 pending_lock = PyThread_allocate_lock();&#125; 可以看到核心的GIL代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445static void take_gil(PyThreadState *tstate)&#123; MUTEX_LOCK(gil_mutex); // 加锁 if (!_Py_atomic_load_relaxed(&amp;gil_locked)) // 获取 GIL，若已释放，直接获取，跳转 goto _ready; while (_Py_atomic_load_relaxed(&amp;gil_locked)) &#123; // GIL 未释放 int timed_out = 0; unsigned long saved_switchnum; // 记录切换次数 saved_switchnum = gil_switch_number; // 利用 pthread_cond_tim 阻塞等待超时 COND_TIMED_WAIT(gil_cond, gil_mutex, INTERVAL, timed_out); /* 等待超时，仍未释放, 发送释放请求信号 */ if (timed_out &amp;&amp; _Py_atomic_load_relaxed(&amp;gil_locked) &amp;&amp; gil_switch_number == saved_switchnum) &#123; // 设置 gil_drop_request=1，eval_breaker=1 // 释放信号 SET_GIL_DROP_REQUEST(); &#125; &#125;_ready: /* We now hold the GIL */ _Py_atomic_store_relaxed(&amp;gil_locked, 1); // 设置 GIL 占用 _Py_ANNOTATE_RWLOCK_ACQUIRED(&amp;gil_locked, /*is_write=*/1); if (tstate != (PyThreadState*)_Py_atomic_load_relaxed(&amp;gil_last_holder)) &#123; _Py_atomic_store_relaxed(&amp;gil_last_holder, (uintptr_t)tstate); ++gil_switch_number; &#125; if (_Py_atomic_load_relaxed(&amp;gil_drop_request)) &#123; // 重置 gil_drop_request=0 RESET_GIL_DROP_REQUEST(); &#125; if (tstate-&gt;async_exc != NULL) &#123; _PyEval_SignalAsyncExc(); &#125; MUTEX_UNLOCK(gil_mutex); // 解锁&#125; 这里实现了互斥锁gil_mutex，如果GIL被占用，那么将持续等待，超时后将修改重置变量。 这点代码给我看的累死了。 回到本段开始的问题，为什么GIL有时候感觉不到慢？ 首先，GIL类似一个信号锁，意思就像是尚方宝剑，持有它的线程告诉其他线程，都不许动阿，我现在正用着呢，你们要么等着我主动释放，要么等我超时了自己释放，然后继续竞争切换持有GIL的线程。 核心的意思就是，多线程的好处在于，阻塞并不会影响其他的线程，因为阻塞的线程持有的GIL马上就被释放了，其他线程可以接力马上干活儿，不会出现阻塞的情况。 这里可以看一下切换线程的代码 12345678910111213141516171819202122232425262728293031323334353637PyObject *_PyEval_EvalFrameDefault(PyFrameObject *f, int throwflag)&#123; ... for (;;) &#123; if (_Py_atomic_load_relaxed(&amp;eval_breaker)) &#123; if (_Py_OPCODE(*next_instr) == SETUP_FINALLY || _Py_OPCODE(*next_instr) == YIELD_FROM) &#123; goto fast_next_opcode; &#125; if (_Py_atomic_load_relaxed(&amp;pendingcalls_to_do)) &#123; if (Py_MakePendingCalls() &lt; 0) goto error; &#125; // 如果检测到gil_drop_request，释放GIL if (_Py_atomic_load_relaxed(&amp;gil_drop_request)) &#123; /* Give another thread a chance */ if (PyThreadState_Swap(NULL) != tstate) Py_FatalError(\"ceval: tstate mix-up\"); drop_gil(tstate); // 继续去调用GIL抢占 take_gil(tstate); // 检查是否退出线程 if (_Py_Finalizing &amp;&amp; _Py_Finalizing != tstate) &#123; drop_gil(tstate); PyThread_exit_thread(); &#125; if (PyThreadState_Swap(tstate) != NULL) Py_FatalError(\"ceval: orphan tstate\"); &#125; &#125; ... &#125;&#125; 当检测到 eval_breaker、gil_drop_request 时，会被动的释放 GIL，跟其他线程一起再次竞争 GIL，所以它几乎没有阻塞，虽然这狗GIL把你给锁住了，但是也保证了效率，当某个线程执行时间过长，可以迅速切换下一个线程调用。 类似这样 如何绕过GIL锁？如何绕过GIL锁，这个也是老生常谈的问题了。 在我这里的话，如果是我，涉及到需要绕过的地方 我会直接写C代码，用CPython去调用 我会用JPython 我会用Golang 大概就这么几个方法，没别的方法了，再也不用看了 Python多线程适用于哪些场景？前面说了，Python多线程并不是真正意义的多线程，其实是个假的，但是还是有很多老哥不遗余力的推荐它，到底为啥，上一节也说得很清楚了，GIL虽然恶心，但是人家还是支持自动切换比较慢的阻塞线程的，不会影响其他线程运行，所以，你品一下，在咱们的开发岁月中，多线程，到底适用于哪些场景？ 首先，发生阻塞的是什么情况，网络的连接时间过长，或者是处理多个业务，读取多个文件，访问多个网页等等。 网上很多文章都说： I/O 密集场景，多线程最合适 你抄我，我抄你，抄到最后就这么一句话，讲真，我看了那么多文章，真的没几个说清楚的，举个例子的都没。 那行嘛，那我来举例子吧。 首先，I/O密集型，指的是涉及到网络、磁盘IO的任务，现在互联网的web大部分都是IO密集的场景 举几个常用的自用例子吧 网络爬虫，这个都写烂了 web应用，例如多用户访问，多用户登录，多用户下载 数据库写入，Mysql/Es等等 RPC框架 大概就这些常用的，Python多线程，大概就这些比较合适。 Python多线程的几个基础用例说了那么多，最后还是加几个基础的用例，拿去举一反三，你们都是聪明人 基础的多线程框架这个基础的多线程框架包含的功能 启动/停止线程 展示线程的状态 1234567891011121314151617181920212223242526272829303132333435363738import threadingimport timeexitFlag = 0# 利用继承的方法class myThread (threading.Thread): def __init__(self, threadID, name, counter): threading.Thread.__init__(self) self.threadID = threadID self.name = name self.counter = counter def run(self): print (\"开始线程：\" + self.name) print_time(self.name, self.counter, 5) print (\"退出线程：\" + self.name)def print_time(threadName, delay, counter): while counter: if exitFlag: threadName.exit() time.sleep(delay) print (\"%s: %s\" % (threadName, time.ctime(time.time()))) counter -= 1# 创建新线程thread1 = myThread(1, \"Thread-1\", 1)thread2 = myThread(2, \"Thread-2\", 2)# 开启新线程thread1.start()thread2.start()thread1.join()thread2.join()print (\"退出主线程\") 多线程的线程通信框架（利用队列）有些时候我们需要在线程之间交换信息和数据，所以多线程之间需要互相通信 多线程的线程通信框架包含的功能 利用队列共享数据（queue） 创建一个生产者消费者模型，启动生产者，消费者线程 这种框架同样适用于爬虫 123456789101112131415161718192021222324252627282930313233343536import threadingimport timefrom queue import Queuequeue = Queue(20)# 生产者def Producer(): i = 0 print(\"开始线程\") while True: i = i + 1 print(\"生产数据\", i, \"现有数据\", queue.qsize()) time.sleep(1) queue.put(i)# 消费者def Consumer(): while True: i = queue.get() time.sleep(0.5) print(\"消费数据\", i)if __name__ == \"__main__\": Th1 = threading.Thread(target=Producer, ) Th2 = threading.Thread(target=Consumer, ) Th2.start() Th1.start() Th1.join() Th2.join() 大概就是这样，这个害挺简单的。 线程锁框架当需要修改共享数据的时候，多个线程会造成冲突，所以对执行的部分进行加锁很有必要，这里采用互斥锁逻辑 线程池加锁框架大概实现的功能 在程序中加锁，避免竞争冲突 这部分代码我懒得写了，直接用了https://www.cnblogs.com/tashanzhishi/p/10775641.html 这位老兄的代码写的很好，看一遍就懂了，感恩! 1234567891011121314151617181920212223242526272829303132333435363738import threadingimport timecount = 0# 做一个累加的函数def add_num(): global count if lock.acquire(): # 获得锁，并返回True tmp = count time.sleep(0.001) count = tmp + 1 lock.release() # 执行完释放锁def run(add_fun): global count thread_list = [] # 累加100次 for i in range(100): t = threading.Thread(target=add_fun) t.start() thread_list.append(t) # 等待线程执行完 for j in thread_list: j.join() print(count)if __name__ == '__main__': # 添加全局锁 lock = threading.Lock() # 执行函数 run(add_num) 线程池框架线程池相当于冰箱里的啤酒 你只要想喝打开冰箱拿就行 你不喝人家也不会跑 就在冰箱里，不吵不闹 等待你的下一次临幸 1234567891011121314151617181920212223242526272829303132from socket import AF_INET, SOCK_STREAM, socketfrom concurrent.futures import ThreadPoolExecutor# 假装跑一个服务器clientdef echo_client(sock, client_addr): ''' Handle a client connection ''' print('Got connection from', client_addr) while True: msg = sock.recv(65536) if not msg: break sock.sendall(msg) print('Client closed connection') sock.close()# 假装跑一个serverdef echo_server(addr): # 定义一个线程池 pool = ThreadPoolExecutor(128) sock = socket(AF_INET, SOCK_STREAM) sock.bind(addr) sock.listen(5) while True: client_sock, client_addr = sock.accept() # 从池子里拿线程消费 pool.submit(echo_client, client_sock, client_addr)echo_server(('',15000)) 结尾线程这块，基本核心的东西都弄完了，其实梳理完，觉得还好，最起码我弄明白人家是干嘛的了，以后碰到任何线程的问题，我也不害怕了，这是12月第一篇blog，我要坚持三四个月，直到黎明的到来。 end。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang的并发机制探究","slug":"Golang的并发机制探究","date":"2020-11-27T02:19:02.000Z","updated":"2020-11-30T01:20:04.090Z","comments":true,"path":"2020/11/27/Golang的并发机制探究/","link":"","permalink":"https://yemilice.com/2020/11/27/Golang%E7%9A%84%E5%B9%B6%E5%8F%91%E6%9C%BA%E5%88%B6%E6%8E%A2%E7%A9%B6/","excerpt":"","text":"前言虽然上两篇文章讲了几个并发示例和Goroutine的使用，但是我仔细看了一下，还是不够清楚，这次这篇文章将会是一篇纯理论的文章，主要讲一下Go的并发机制的原理还有Goroutine还有channel。 至于为啥要写呢。。。。。 12345678910111213141516171819朋友们好啊，我是Go开发人员Yk，刚才有个朋友问我，Y老师，发生甚么事了，我说怎么回事，给我发了一篇我的博客截图，我一看，嗷！原来是前一阵，我写了两篇Go的文章，一个Go并发，一个Go例子，他们说，唉，Y老师你这并发讲的不清楚，哎，能不能重新写一个说明白，我说行，我说你在kindle上看死书，不好用。他不服气。我说小赤佬，你一篇文章来怼我两篇，你搞不动我。他说你这没用，我说我这个有用，这是Golang精华，隔壁200多页大PDF我都看了。他非要和我试试，我说可以，我一说他就“啪”就把键盘拿起来了，很快嗷！年轻人，我劝你耗子为汁，来偷袭我20多岁的老同志，这好吗？这不好。我说你不讲码德阿，我们Golang开发人员要以和为贵，不要搞窝里斗，谢谢朋友们！ 还是要感谢这么几本书，《Go并发编程实战》，《Go语言圣经》，《Go高级编程》，感谢这几本书的作者和译者！感谢你们！ Go的线程模型Go的并发机制是个什么，主要就是Go有一个特有的线程模型，这个线程模型里面，有个特有的线程，叫做Goroutine，这个东西可以理解为一个可执行可并发的代码块，通过channel管道去进行状态同步或者消息传递。 首先来看一下那个线程模型，术语叫做”两级线程模型”，名字其实没啥狗屁用，就听听就得了。 Go的线程模型，有三个核心元素 M：machine，代表工作线程，你想成僵尸母体就行了 P：processor，上下文环境，意思就是执行Go代码的所需要的资源，或者是存储要执行的goroutine，你想成僵尸传播渠道就行了 G：goroutine，Go代码片段，你要执行并发的那一块儿程序。你想象成被感染的小僵尸就行了 他们的大致关系如下 这三个元素是互相依赖，互相依存的关系，我用僵尸传播理论来说明一下他们的关系吧。 首先，G需要P和M的支持，也就是说，一个G的出现，是先有了M（僵尸母体），然后通过渠道（P），感染其他的小僵尸（G）。一个M对应一个P，P对应多个G，G也对应多个P，因为感染人数不只是一个人，所以，他们的关系就像这样 如图所示 这么理解一波，M是内核线程，按照一般的逻辑，一个内核线程一般运行一个任务，但是，GOlang比较牛逼，通过调度器，使得M可以运行多个用户线程G，其中，P的作用是，当遇到内核线程阻塞的时候，M可以放弃P，这样，其他的G就可以被调度到其他M上，持续接力执行。 类似这样 所以，同样配置的机器，Golang的效率就会成倍增长，并且可以迅速切换goroutine。所以这就是Go为什么比其他语言快的原因，这也是Go最核心的东西，说真的，Go这个玩意儿，比Python那套好使多了，不过不同任务不可同日而语，继续一波。 Go的调度器上面我讲到了调度器，什么是调度器？ 顾名思义，就是调度用的，相当于交通警察，看哪儿阻塞了就给你安排到不赌的路上去，这么想是不是就整明白了，但是Go里面的调度器没那么简单，它的功能相对来说复杂一点。例如空闲的M列表，空闲的P列表，需要运行的G列表等等，都属于调度器的管理部分。 那么调度器是怎么把上面说的G，M，P串联起来的呢？这个翻了一大堆资料，总算弄明白了一点东西，在这里大概讲一下吧。 首先，调度器调度的主要对象就是M，P，G的实例，每个M在运行的时候都会执行调度任务，看过黑社会吗，调度器就是选老大时候的邓伯那帮人，选阿乐还是选大D都是他们协调说了算的。 调度器调度了个什么？寂寞吗，看看图，大概就是这样 调度器是有自己的数据结构的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748type schedt struct &#123; goidgen uint64 lastpoll uint64 lock mutex midle muintptr // idle m's waiting for work nmidle int32 // 当前等待工作的空闲 m 计数 nmidlelocked int32 // 当前等待工作的被 lock 的 m 计数 mnext int64 // 当前预缴创建的 m 数，并且该值会作为下一个创建的 m 的 ID maxmcount int32 // 允许创建的最大的 m 数量 ... pidle puintptr // 空闲 p's ... // 全局的可运行 g 队列 runqhead guintptr runqtail guintptr runqsize int32 // dead G 的全局缓存 gflock mutex gfreeStack *g gfreeNoStack *g ngfree int32 // sudog 结构的集中缓存 sudoglock mutex sudogcache *sudog // 不同大小的可用的 defer struct 的集中缓存池 deferlock mutex deferpool [5]*_defer ...忽略一些没啥必要的参数 gcwaiting uint32 // 是否要因为任务停止调度 stopwait int32 //需要停止但仍未停止的数量 stopnote note //停止的通知机制 sysmonwait uint32 //停止调度期间任务是否还在等待 sysmonnote note //sysmonnotewait 的通知机制 procresizetime int64 // 上次修改 gomaxprocs 的纳秒时间 ...&#125; 下面说一下调度具体干了什么 调度的具体步骤调度器结构体里面有几个重要参数，我先在这里整出来，后面你们方便看 调度器的具体流程这里整了一个图，大家凑合着看一下吧。图的来源是https://www.infoq.cn/article/r6wzs7bvq2er9kuelbqb，很感谢他！ 看一下逻辑，首先将其分为四个阶段，绑定，创建，执行，释放。调度在其中的作用体现在了这里 首先第一个步骤绑定开始，这里也是M启动的过程，首先从空闲的P列表里面拿取一个P，然后绑定在M上，P里面有两个列表去管理G，一个runq是存放当前P中可运行G的一个队列，另外一个gfee是存放空闲G的一个队列，启动M之后，则会等待拿取可执行的G 第二个步骤，创建G，首先创建完之后，扔一个G到当前绑定P的runq队列当中 第三个步骤，执行G，M从绑定的P那里的runq队列中拿取一个G进行执行 第四个步骤，释放G，执行完G之后，将执行完毕的G放入gfee队列，当再次创建G的时候，从gfee列表中获取，这里是一个复用的逻辑，避免频繁创建G占用系统内存。 所以这里是类似一个自循环的逻辑，执行完G1之后持续执行，当M1繁忙时，自动开启新的M来执行 多线程下的调度机制（偷取G机制）前阵子我在开发的时候，有一种场景是下载大文件，一般这种情况就是划块下载，但是下载时间是不可控的，也是未知的，很可能有的下的快，有的下的慢，就会出现有的下载队列已经空了，但是有的依旧还很满这种情况。 其实在Go里面，调度器在这一步就会寻找可执行的G，这里是它们的具体流程 如图 这里用流程图表示就是 我将这里的大概步骤编写如下 从本地P的可运行G队列（p.runq）中获取G. 调度器首先会尝试从此处获取G，并且返回一个结果 从调度器的可运行G（sched.runq）队列获取G。调度器首先会尝试从此处获取G，并且返回一个结果 从其他P中可运行的G队列中获取G。 在某些条件下，调度器会使用伪随机算法在全局P列表中选取一个P，并且尝试从他们的可运行G队列中盗取（转移）一半的G到本地的P可运行队列中，这里会重复多次盗取动作，成功之后就把盗取的一个G作为结果进行返回。 这里就完成了盗取机制。 那么偷取部分是怎么实现的呢？ 偷取部分的源码如下 1234567891011121314151617181920// runtime/proc.go// 从其它地方获取Gfunc findrunnable() (gp *g, inheritTime bool) &#123; ...... // 尝试4次从别的P偷 for i := 0; i &lt; 4; i++ &#123; for enum := stealOrder.start(fastrand()); !enum.done(); enum.next() &#123; if sched.gcwaiting != 0 &#123; goto top &#125; stealRunNextG := i &gt; 2 // first look for ready queues with more than 1 g // 在这里开始针对P进行偷取操作 if gp := runqsteal(_p_, allp[enum.position()], stealRunNextG); gp != nil &#123; return gp, false &#125; &#125; &#125;&#125; 转移部分的代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344// runtime/proc.go// 偷取P2一半到本地运行队列，失败则返回nilfunc runqsteal(_p_, p2 *p, stealRunNextG bool) *g &#123; t := _p_.runqtail n := runqgrab(p2, &amp;_p_.runq, t, stealRunNextG) if n == 0 &#123; return nil &#125; n-- // 返回尾部的一个G gp := _p_.runq[(t+n)%uint32(len(_p_.runq))].ptr() if n == 0 &#123; return gp &#125; h := atomic.Load(&amp;_p_.runqhead) // load-acquire, synchronize with consumers if t-h+n &gt;= uint32(len(_p_.runq)) &#123; throw(\"runqsteal: runq overflow\") &#125; atomic.Store(&amp;_p_.runqtail, t+n) // store-release, makes the item available for consumption return gp&#125;// 从P里获取一半的G,放到batch里func runqgrab(_p_ *p, batch *[256]guintptr, batchHead uint32, stealRunNextG bool) uint32 &#123; for &#123; // 计算一半的数量 h := atomic.Load(&amp;_p_.runqhead) // load-acquire, synchronize with other consumers t := atomic.Load(&amp;_p_.runqtail) // load-acquire, synchronize with the producer n := t - h n = n - n/2 ...... // 将偷到的任务转移到本地P队列里 for i := uint32(0); i &lt; n; i++ &#123; g := _p_.runq[(h+i)%uint32(len(_p_.runq))] batch[(batchHead+i)%uint32(len(batch))] = g &#125; if atomic.Cas(&amp;_p_.runqhead, h, h+n) &#123; // cas-release, commits consume return n &#125; &#125;&#125; 第三步，我说到”满足一个条件，才可以偷取”，这个条件其实定义的稍微复杂一些，分为两种 121. 除了本地的P外，其他有不为空的P2. M一直没有找到G来运行，也就是前两步一直没有找到G，这里的术语被称为“自旋状态” 当满足上述条件的时候，才可以开启偷取机制。 总之，调度器会权力查找可执行的G，它会调用多方资源来满足当前M，也就是我刚描述的，下载任务有快慢，会占用多余资源，但是调度器解决了闲置的问题，充分发挥了资源优势，这，相当牛逼了。 GC机制在Golang里面，垃圾回收是基于CMS算法的，CMS算法我在这里简单描述一下吧 洋文叫：Concurrent Low Pause Collector，jvm也是这套算法，玩java的一眼就明白吧。 要说这套算法，Golang也用它，说明人家是经过考验的 Golang这套CMS算法分为三种执行模式 gcbackgroundMode 并发垃圾收集/清理 gcforceMode 串行垃圾收集，并发垃圾清理 gcforceBlockMode 串行垃圾收集，串行垃圾清理 一般涉及到并发，调度器部分会自动GC，都是采用了gcbackgroundMode模式，首先会检查Go 程序的内存用量，检测增量过大的时候才会来一发GC。 一般在Golang当中，我们可以通过环境变量GODEBUG控制GC，一般修改 1234// 转为gcforceMode 串行垃圾收集，并发垃圾清理gcstoptheworld=1// 转为gcforceBlockMode 串行垃圾收集，串行垃圾清理gcstoptheworld=2 一般GC的触发，是在Go程序分配的内存翻倍增长时被触发的。如果想要手动GC，可以调用 1runtime.GC() 进行一次手动GC 串行的GC触发方式为 1runtime.freeOsMemory() 如果手动调用GC，将不会检测原有Go程序的内存使用量，是为强制GC。 隐藏的特殊成员-g0在启动Go程序的时候，有一个特殊的隐藏G，叫做g0。 这里的G，不是Go程序代码里面的那个G，是一开始，初始化流程中自动分配给M的g，这个g0和上面那个GC对应起来了，它负责的就是监控内存，垃圾回收，执行调度。 一般由Go代码生成的G，称为用户G，而g0，则被称为系统G，一个系统一个用户，谁权限大是不是显而易见了。 每个M都会生成一个g0，Go运行的时候会进行切换，g0是不会被阻塞的，也不会被垃圾回收监控扫描。 所以g0，想象成一个守护神，伴随M，和M同生公死，相当于皇帝身边的大太监一样。 结尾这篇文章写完，我是真的彻底搞懂了调度器原理和Golang并发核心机制，其实学习最好的方法就是写博客，记笔记，边写边记。其实慢慢来，都会有好的结果，已经到了年底了，今年大家都过的好嘛？或许今年过的很苦，但今天我们可乐。 end。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"完全理解Golang并发模式(2)","slug":"完全理解Golang并发模式-2","date":"2020-11-10T02:46:02.000Z","updated":"2020-11-10T03:04:35.531Z","comments":true,"path":"2020/11/10/完全理解Golang并发模式-2/","link":"","permalink":"https://yemilice.com/2020/11/10/%E5%AE%8C%E5%85%A8%E7%90%86%E8%A7%A3Golang%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%BC%8F-2/","excerpt":"","text":"前言这几天的攻关都是在Golang并发上面，也算是有了一些收获，把一些基础的并发场景和并发模式都过了一遍，觉得自己又提升了一层楼，其实我发觉，在我的开发生涯中，总是纠结实现，却不是去看最底层的东西，任何东西，都是由简到难，或者就是从底层到核心，无论是Python还是Golang，或者是我正在狂刷算法的Java，我都是去纠结实现，但是不会钻研核心，所以我写代码都是面向搜素引擎编程。所以，也是时候该改变一些东西。 12345决意想要改变心情就像离弦的箭收不回的思绪每天在反复缠绵 并发的超时处理如果我们在开发一个Web框架，势必在运行一个goroutine的时候，会出现运行时间过长的问题，一般这种情况，如果不进行超时控制，到最后的结果就是阻塞在那里，迟迟不返回，这样肯定是不行的，所以我们要对并发进行一个超时限制，说人话就是，加一个timeout之后自动退出或者报错。 首先这里有个新东西，或者是新包，叫做”Context”，这个我的博客里面的久文章也写过了，在这不多废话。你不会还想让我介绍一下它吧！ Context的几个调用方法寻思了一下，如果不介绍，很可能你们不知道我在说什么，还是讲几个基础用法吧，其实这个还是比较简单的，Golang的语法比起Rust简单多了。 Context的接口如下 12345678910type Context interface &#123; Deadline() (deadline time.Time, ok bool) Done() &lt;-chan struct&#123;&#125; Err() error Value(key interface&#123;&#125;) interface&#123;&#125;&#125; 其中有四个方法 Deadline返回绑定当前context的任务被取消的截止时间；如果没有设定期限，将返回ok == false。 Done 当绑定当前context的任务被取消时，将返回一个关闭的channel；如果当前context不会被取消，将返回nil。 Err 如果Done返回的channel没有关闭，将返回nil;如果Done返回的channel已经关闭，将返回非空的值表示任务结束的原因。如果是context被取消，Err将返回Canceled；如果是context超时，Err将返回DeadlineExceeded。 Value 返回context存储的键值对中当前key对应的值，如果没有对应的key,则返回nil。 简单的超时取消模型咱们现在来实现一个超时的例子，其实这个直接调用context的timeout逻辑就可以了，有一张图可以明显说清楚超时处理的逻辑 1ctx, cancel := context.WithTimeout(context.TODO(), time.Second*2) 看一下context.WithTimeout的源码 123func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123; return WithDeadline(parent, time.Now().Add(timeout))&#125; 这个家伙传入了一个时间，并且调用了withDeadline函数，看下它的源码 123456789101112131415161718192021222324252627func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) &#123; if cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123; // The current deadline is already sooner than the new one. return WithCancel(parent) &#125; c := &amp;timerCtx&#123; cancelCtx: newCancelCtx(parent), deadline: d, &#125; // 监听parent的取消，或者向parent注册自身 propagateCancel(parent, c) dur := time.Until(d) if dur &lt;= 0 &#123; // 已经过期 c.cancel(true, DeadlineExceeded) // deadline has already passed return c, func() &#123; c.cancel(false, Canceled) &#125; &#125; c.mu.Lock() defer c.mu.Unlock() if c.err == nil &#123; c.timer = time.AfterFunc(dur, func() &#123; c.cancel(true, DeadlineExceeded) &#125;) &#125; return c, func() &#123; c.cancel(true, Canceled) &#125;&#125; 这里输出了两个值，一个是ctx，一个是cancel 你可以这么理解，ctx就是信号，cancel是阀门，ctx的信号结束时，关闭阀门（关闭goroutine） 写个简单的超时退出模型 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 定义一个超时时间/开始时间/信号var ( Timeout = 1 * time.Second starttime = time.Now() signal = make(chan bool))// 模拟一个执行时间很长的任务func do_something_work_1(ctx context.Context, url string) string &#123; // 执行任务 go func() &#123; // 假装阻塞在这里 time.Sleep(time.Second * 10) fmt.Println(url) // 如果执行完，singal为true signal &lt;- true &#125;() select &#123; // 如果接受到关闭信号（超时） case &lt;-ctx.Done(): fmt.Println(\"tomeout..........\") fmt.Printf(\"%.2fs - workers(%s) killed\\n\", time.Since(starttime).Seconds(), url) // 杀掉 return \"tomeout........\" case &lt;-signal: // 如果正常关闭，没超时 fmt.Println(\"success\") // 正常输出，正常杀掉 return \"success\" &#125; return \"success\"&#125;func main() &#123; // 定义一个Timeout，超时时间为1s ctxt, cancel := context.WithTimeout(context.Background(), Timeout) defer cancel() // 开始执行goroutine go do_something_work_1(ctxt, \"hallo\") //假装在做别的任务 time.Sleep(time.Second * 5) // 结束主程 fmt.Println(\"END\")&#125; 这里的输出结果是 123tomeout..........1.00s - workers(hallo) killedEND 解析一下这个框架吧，这个框架实现了一个简单的超时功能. 首先，我定义了一个假设执行时间很长的task，利用context，我给这个task定义了一个超时时间，并且通过select去监控它，当我监控到ctx有输出的时候，那么我就认为task超时，则直接输出超时并且杀死task，如果task直接run到底，那么会有一个信号signal被赋值，select接受到signal被赋值之后，将会认为任务执行成功，输出成功并且杀死task，大概的逻辑就是这样。 并发的取消和退出并发的退出，其实又回到了上面的一个例子，刚才我演示了一个叫做cancel()的东西，这个东西就相当于是杀死goroutine的侩子手。来瞅瞅这个东西到底是啥 首先又回到刚那个逻辑 1ctx, cancel := context.WithTimeout(context.TODO(), time.Second*2) 它输出了一个ctx，一个cancel，我们看下cancel到底是个什么东西 在源码里面，它是个 1type CancelFunc func() 是不是很蒙蔽，这具体是个啥呢，官方文档里面说了 123A CancelFunc tells an operation to abandon its work. A CancelFunc does not wait for the work to stop. A CancelFunc may be called by multiple goroutines simultaneously. After the first call, subsequent calls to a CancelFunc do nothing.大意就是这个参数是放弃操作用的，并不等待工作停止，多个任务可调用多个cancel，第一个任务调用cancel之后，其他调用的操作不起作用。 还是蒙蔽阿，瞅一眼其他调用代码，继续追踪，最后在withdeadline找到了 1234567891011121314151617181920212223242526func (c *cancelCtx) cancel(removeFromParent bool, err error) &#123; if err == nil &#123; panic(\"context: internal error: missing cancel error\") &#125; c.mu.Lock() if c.err != nil &#123; c.mu.Unlock() return // already canceled &#125; c.err = err if c.done == nil &#123; c.done = closedchan &#125; else &#123; close(c.done) &#125; for child := range c.children &#123; // NOTE: acquiring the child's lock while holding parent's lock. child.cancel(false, err) &#125; c.children = nil c.mu.Unlock() if removeFromParent &#123; removeChild(c.Context, c) &#125;&#125; 这部分就相对来说清楚一些了，这里主要是用了一个互斥锁问mutex.lock，看起来是访问共享内存，保护和协调内存访问的，首先先对ctx进行加锁，然后去遍历子goroutine，执行close，没有child之后再进行锁释放，这里的代码真的值得一看。 并发的退出（context代码） 123456789101112131415161718192021222324252627282930313233343536373839// 定义一个int值，这个值没啥意义，单纯就是做了一个传输，看看就得var c = make(chan int)func do_something_work(ctx context.Context) string &#123; i := 0 for &#123; select &#123; // 接收到退出信号 case &lt;-ctx.Done(): fmt.Println(\"Task Exit\") return \"Task Exit\" // 做点事儿 case c &lt;- i * i: i++ &#125; &#125; return \"Task Success\"&#125;func main() &#123; ctx, cancel := context.WithCancel(context.Background()) // 开始干活儿 go do_something_work(ctx) for i := 0; i &lt; 5; i++ &#123; fmt.Println(\"Next square is\", &lt;-c) &#125; // 杀掉任务 cancel() // 假装还在干别的活儿 time.Sleep(time.Second * 3) fmt.Println(\"END\")&#125; 再来一个其他模式的代码，还有一种是通过chan管道传递，其实实现的逻辑也差不多，这里也贴出来，然后给予讲解 chan类型退出框架 12345678910111213141516171819202122232425func do_somethings(done chan bool, url string) &#123; go func() &#123; for &#123; select &#123; // 接受到信号关闭 case &lt;-done: fmt.Println(\"退出\") return default: fmt.Println(url + \" \" + \"执行中\") time.Sleep(1 * time.Second) &#125; &#125; &#125;()&#125;func main() &#123; done := make(chan bool) // 假装干个活儿 do_somethings(done, \"hello\") // 假装正在干别的活儿 time.Sleep(3 * time.Second) // 关闭 close(done)&#125; 这里首先定义了一个chan，通过close chan来进行协程的退出，还是老样子，每次一定要有一个select去监控chan，当执行close时，chan会有输出，当获取到chan输出时，则结束杀死任务。 goroutine的心跳模式有些时候，我们需要一个后台常驻任务，去做一些有的没的，但是有些时候不确定goroutine是否还活着，所以你需要每隔一段时间通知一下，报告情况，虽然存在静默状态，但是会隔固定的时间进行一次通知，这里对并发代码很有用，避免了异常挂住或者zombie的问题。 一般我写心跳代码都是后台常驻的服务，比如监控服务，比如时不时跳出来的告警服务，比如前阵子我写了个网络服务，一直就后台挂着等着别人来访问，有些时候不确定啥时候来人访问，就写了个心跳代码，所以我感觉并发里面，心跳还是很有必要的，特别是分布式的系统。 首先看图，心跳在Golang里怎么表现的 分析下心跳的实现方法 我们建立一个空的channel，设定时间去关闭它 按照时间间隔定时向空的channel发送一个值，类似定时通知机制，并且每次都能读到channel的内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778func dowork(done &lt;-chan interface&#123;&#125;, pulseInterval time.Duration) (&lt;-chan interface&#123;&#125;, &lt;-chan time.Time) &#123; // 设定心跳通道 heartbeat := make(chan interface&#123;&#125;) //1 results := make(chan time.Time) go func() &#123; defer close(heartbeat) defer close(results) // 心跳间隔 pulse := time.Tick(pulseInterval) //2 // 工作间隔 workGen := time.Tick(2 * pulseInterval) //3 // 发送心跳 sendPulse := func() &#123; select &#123; case heartbeat &lt;- struct&#123;&#125;&#123;&#125;: default: //4 &#125; &#125; // 发送结果 sendResult := func(r time.Time) &#123; for &#123; select &#123; case &lt;-done: return case &lt;-pulse: //5 sendPulse() case results &lt;- r: return &#125; &#125; &#125; // 循环，如果关闭就renturn，获取pulse就续租 for &#123; select &#123; case &lt;-done: return case &lt;-pulse: //5 sendPulse() case r := &lt;-workGen: sendResult(r) &#125; &#125; &#125;() return heartbeat, results&#125;func main() &#123; done := make(chan interface&#123;&#125;) time.AfterFunc(10*time.Second, func() &#123; close(done) &#125;) const timeout = 2 * time.Second heartbeat, results := dowork(done, timeout/2) for &#123; select &#123; case _, ok := &lt;-heartbeat: if ok == false &#123; return &#125; fmt.Println(\"pulse\") case r, ok := &lt;-results: if ok == false &#123; return &#125; fmt.Printf(\"results %v\\n\", r) // 没有收到心跳 case &lt;-time.After(timeout): fmt.Println(\"worker goroutine is not healthy!\") return &#125; &#125;&#125; 峰值限制（防止过大的并发请求数）又是抽象的一B的东西，说人话就是，把系统的稳定和平衡性控制在可控范围内。举个简单的例子，如果你是一个动漫网站站长，你每天只允许100个人访问你的网站看动漫，那这个100就是你的限制，就是访问限制，如果第101个人想要看动漫，就只能阻塞在外面继续等待，等100个人中的其中几个人退出才可以继续进去。 这里一般的处理方法是令牌算法 令牌算法的解释如下 1234假设要使用资源，你必须拥有资源的访问令牌。没有令牌，请求会被拒绝。想象这些令牌存储在等待被检索以供使用的桶中。该桶的深度为d，表示它一次可以容纳d个访问令牌。现在，每次你需要访问资源时，你都会进入存储桶并删除令牌。如果你的存储桶包含五个令牌，那么您可以访问五次资源。在第六次访问时，没有访问令牌可用，那么必须将请求加入队列，直到令牌变为可用，或拒绝请求。 写个代码你看看 1234567891011bar24x7 := make(Bar, 10) // 此酒吧只能同时招待10个顾客for customerId := 0; ; customerId++ &#123; time.Sleep(time.Second) consumer := Consumer&#123;customerId&#125; select &#123; case bar24x7 &lt;- consumer: // 试图进入此酒吧 go bar24x7.ServeConsumer(consumer) default: log.Print(\"顾客#\", customerId, \"不愿等待而离去\") &#125;&#125; 这个其实相对来说可能比较简单，定义一个队列就可以了，但是这不是最好的办法 速率限制（设定某一时刻的并发请求数）和上面那个兄弟的机制没啥两样，其实一个是瞬时请求，一个是总请求，说人话就是，上面那个管全局，下面这个管某一时刻，比如在选课的时候，瞬间就有一大堆人过来抢课，这不把服务器撑爆了。所以，速率限制，常用来限制吞吐和确保在一段时间内的资源使用不会超标。 写个代码你看看 12345678910111213141516171819202122232425262728293031type Request interface&#123;&#125;func handle(r Request) &#123; fmt.Println(r.(int)) &#125;const RateLimitPeriod = time.Minuteconst RateLimit = 10 // 任何一分钟内最多处理10个请求func handleRequests(requests &lt;-chan Request) &#123; quotas := make(chan time.Time, RateLimit) go func() &#123; tick := time.NewTicker(RateLimitPeriod / RateLimit) defer tick.Stop() for t := range tick.C &#123; select &#123; case quotas &lt;- t: default: &#125; &#125; &#125;() for r := range requests &#123; &lt;-quotas go handle(r) &#125;&#125;func main() &#123; requests := make(chan Request) go handleRequests(requests) // time.Sleep(time.Minute) for i := 0; ; i++ &#123; requests &lt;- i &#125;&#125; 并发最快回应机制有时候，一份数据可能同时从多个数据源获取。这些数据源将返回相同的数据。因为各种因素，这些数据源的回应速度参差不一，甚至某个特定数据源的多次回应速度之间也可能相差很大。同时从多个数据源获取一份相同的数据可以有效保障低延迟。我们只需采用最快的回应并舍弃其它较慢回应. 写个代码你看看 1234567891011121314151617181920212223package mainimport ( \"fmt\" \"time\" \"math/rand\")func source(c chan&lt;- int32) &#123; ra, rb := rand.Int31(), rand.Intn(3) + 1 // 睡眠1秒/2秒/3秒 time.Sleep(time.Duration(rb) * time.Second) c &lt;- ra&#125;func main() &#123; rand.Seed(time.Now().UnixNano()) startTime := time.Now() c := make(chan int32, 5) // 必须用一个缓冲通道 for i := 0; i &lt; cap(c); i++ &#123; go source(c) &#125; rnd := &lt;- c // 只有第一个回应被使用了 fmt.Println(time.Since(startTime)) fmt.Println(rnd)&#125; 差不多就是这样，这里我偷懒了一下，借用了他人的代码，他的环境是，这篇文章给了我很大的启发，感恩！ 通道用例大全 结尾细细看了一下，写了不少了，但是其中有一两个东西我也没整的太明白，比如goroutine的心跳之类的，这个东西实在是用的不多，所以我感觉我还是，嗯，需要持续性进步才能解决问题，我写的不那么好，如果有错，请老铁们指出来，感恩！ 123456789予你开心叫我宝宝予你异见上我镣铐小人以为我拿它没办法光脚不惧穿鞋我又有何怕check~","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"完全理解Golang并发模式(1)","slug":"完全理解Golang并发模式-1","date":"2020-11-03T10:22:08.000Z","updated":"2020-11-06T04:54:49.088Z","comments":true,"path":"2020/11/03/完全理解Golang并发模式-1/","link":"","permalink":"https://yemilice.com/2020/11/03/%E5%AE%8C%E5%85%A8%E7%90%86%E8%A7%A3Golang%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%BC%8F-1/","excerpt":"","text":"前言其实我写Golang有段时间了，平常写一些业务代码，也涉及不到什么高端东西，Golang的核心其实就是在于goroutine这套东西，在处理高并发任务的时候非常强势，甩Python一个车位，所以，写下这篇博客，作为笔记，记录Golang核心的并发机制，并且给出一些自己写的代码作为示例，本次博客大部分代码为自己手写，参考了《Golang并发之道》，《Go语言圣经》这两本书，这两本书是我的进阶之路上的灯塔，感谢这两本书的译者，也希望大家去看看这两本书。 Golang在并发处理上有什么优势一个是方便，一个是随用随写。 Golang的特性goroutine是Go的基础语法，一般调用的方法十分简单 1go func() 这时的goroutine是一个并发的函数，说起来非常抽象，举个例子，你现在想要执行一个打招呼的逻辑 1234567func Work()&#123; fmt.Println(\"im working!\")&#125;func main() &#123; go Work()&#125; 一个基础打招呼的逻辑就形成了。同理，你可以干多个事儿，类似 123456789101112func Work()&#123; fmt.Println(\"im working!\")&#125;func Exit()&#123; fmt.Println(\"im go home!\")&#125;func main() &#123; go Work() go Exit()&#125; 这些都是goroutine的好处，就是随便写随便用，混用混写。 Golang并发模型的标准Go遵循一种 fork-join的并发模型标准/规则 fork的意思是程序中的任意一点，goroutine和主程序一起运行，join的意思他们最终合并在一起，用中国话来说叫殊途同归，拿上面那个打招呼的例子详细说一下。 123456...func main() &#123; go Work() go Exit() fmt.Println(\"END\")&#125; 如果你自己跑一下这个程序，就有可能发现，END的输出，是不会等待你的work和exit完成的，很大概率几乎这两个goroutine都没执行，说白了就是，主程跑起来，跑完了，你子程，我才不管你跑了没呢！像不像个渣男，只顾着自己爽，出来了就完了。 画个图解释一下 这里其实是没有join的，这么想一下吧，大家都坐过高铁，高铁上人来人往，把高铁想成主函数main，我们每个人就是goroutine，我们要去的终点是不一样的，如果有人在中途下车上厕所，没上来，不通知高铁一声，高铁就跑了，就不会管你是不是到终点，所以这个join，就类似通知，或者是链接主函数的一个点。现在改写一下这个程序。 利用WaitGroup来改写一下，对主程进行一个等待和通知的操作 1234567891011121314var wg sync.WaitGroupWork := func() &#123; defer wg.Done() fmt.Println(\"im working!\")&#125;Exit := func() &#123; defer wg.Done() fmt.Println(\"im go home!\")&#125;wg.Add(2)go Work()go Exit()wg.Wait()fmt.Println(\"END\") 这里写的稍微粗糙了一点，其实很简单，利用了waitgroup建立一个连接点，这里其实就会等待work和exit完全执行完毕再进行END的输出。可以总结成一个图 总结一下，Go的并发模型，就是无论你goroutine怎么疯，怎么耗时，怎么难搞，都要通过join逻辑通知主程去做一个等待/通知，从而实现并发。 这个东西应该才是Golang并发模式的核心吧，以后编写的代码，也都是遵循这种框架。 Golang并发的几个基础用例解析随想想用Golang实现并发模型，一般有几个固定的组件，例如waitgroup, context, channel等，大家都会根据自己项目的需求选择不一样的并发组件进行开发，我记得我以前针对这三种都写过对应的博客，分别是 context随想 Watigroup随想 Channel随想 这三篇Blog都已经大概说了最常见的几种并发模型，我这几天查了一点资料，看了一下Golang并发的几个用例，发觉遗漏了一些重要部分，这里还是继续更新一下吧。 我会将基础的使用场景和用例代码贴出，并且加上我自己的解析，如果有错误，请给予我指点，感谢！ 如何处理并发循环问题？有时候我们可能会面临这种需求，一次性访问多个网页，或者一次循环切片中多个数据，类似这样 1234567891011121314func do_something(url string) &#123; fmt.Println(url) time.Sleep(time.Second * 3)&#125;func main() &#123; url_lists := []string&#123;\"baid.com\", \"wangyi.com\"&#125; for _, url := range url_lists &#123; do_something(url) &#125; fmt.Println(\"END\")&#125; 这时的循环模式是单个循环，一循到底部，这里就是一个个循环下去，效率非常低那种。 我们现在把它改成并发循环 改写我们的并发循环代码，实现基础并发循环其实很简单，改动一个地方就行 123456789101112131415func do_something(url string) &#123; fmt.Println(url) time.Sleep(time.Second * 3)&#125;func main() &#123; url_lists := []string&#123;\"baid.com\", \"wangyi.com\"&#125; for _, url := range url_lists &#123; go do_something(url) &#125; fmt.Println(\"END\")&#125; 在这里，你会发现压根没打印就直接输出了END，看到了吧，问题来了，你没有遵循fork-join的并发逻辑。 你是不是想加个Sleep去等待它完成，其实你想的没错，但是Sleep不是一个join，它只是一个计时器而已。 赶紧，上一个WaitGroup，你也可以用chan，这都是一样的。 waitgroup写法 123456789101112131415161718var wg sync.WaitGroupfunc do_something(url string) &#123; defer wg.Done() fmt.Println(url) time.Sleep(time.Second * 3)&#125;func main() &#123; url_lists := []string&#123;\"baid.com\", \"wangyi.com\"&#125; for _, url := range url_lists &#123; wg.Add(1) go do_something(url) &#125; wg.Wait() fmt.Println(\"END\")&#125; chan写法 12345678910111213141516171819func do_somethings(url string) &#123; fmt.Println(url) time.Sleep(time.Second * 2)&#125;func main() &#123; ch := make(chan struct&#123;&#125;) ips := []string&#123;\"string1\", \"string2\"&#125; for _, ip := range ips &#123; go func(ip string) &#123; do_somethings(ip) ch &lt;- struct&#123;&#125;&#123;&#125; &#125;(ip) &#125; for range ips &#123; &lt;-ch &#125;&#125; 并发循环中Wg的控制上面的代码里，有个函数叫做 1wg.Add(1) 这兄弟是干嘛的呢，它其实就是增加一个计数器，你可以认为他就是增加一个子线程 1wg.Done() 这个兄弟是减去一个计数器，意思就是销毁，干掉 1wg.Wait() 这个兄弟是阻塞主程的，直到计数器为0的时候，再继续往下。 并发循环中输出错误有些时候在并发循环中遇到了错误，不能够忽略，要求即刻输出，改写一下我们刚才的代码。 chan写法 12345678910111213141516171819202122232425func do_somethings(url string) (err error) &#123; fmt.Println(url) if url == \"string2\" &#123; return fmt.Errorf(\"bad............\") &#125; time.Sleep(time.Second * 2) return nil&#125;func main() &#123; ips := []string&#123;\"string1\", \"string2\"&#125; errors := make(chan error) for _, ip := range ips &#123; go func(ip string) &#123; err := do_somethings(ip) errors &lt;- err &#125;(ip) &#125; for range ips &#123; if err := &lt;-errors; err != nil &#123; fmt.Println(err) return &#125; &#125;&#125; 其实chan就是在各个goroutine中做传递的管道，相当于感情的通讯员~ 控制并发goroutine的数量举个简单的例子，如果我们的机器太破，咱不可能开无限个goroutine去做事儿吧，有些时候我们需要对并发的数量进行控制，比如说给定一个最大并发量为6，一次性只能并发6个，也就是一次性只能有6个消费者同时进行消费，那么咱们该怎么实现这个操作呢？ 一般人都会说，咱们来个池子，随用随取。但是Golang这么搞就没必要了，显得很没有Go style。 首先要明确我们的需求，我们的最终目标是，限制并发数，避免过度并发。 说一下我的解决方案 首先定义一个有长度限定的channel 1var jobs = make(chan string, 6) 这里将会存储6个work 再写一个消费逻辑 123for url := range jobs &#123; do_somethingss(url)&#125; 这时就大概完成了基础的消费逻辑，那么，我们该如何往这个空channel里传数据呢？ 1234for _, url := range worklist &#123; jobs &lt;- url fmt.Println(\"add\", url) &#125; 现在我们有了消费者，也有了生产者，那么我们把代码封装一下 详细代码如下 12345678910111213141516171819202122232425262728293031323334353637func do_somethingss(url string) (err error) &#123; fmt.Println(\"hello:\" + url) if url == \"string2\" &#123; time.Sleep(time.Second * 10) fmt.Println(\"all die\") return nil &#125; time.Sleep(time.Second * 2) return nil&#125;func main() &#123; worklist := []string&#123;\"string1\", \"string2\", \"string3\", \"string4\", \"string5\", \"string6\", \"string7\"&#125; wg := sync.WaitGroup&#123;&#125; var jobs = make(chan string, 6) //最大6个消费者 for i := 0; i &lt; 6; i++ &#123; go func() &#123; // 消费数据 for url := range jobs &#123; do_somethingss(url) //消费完通知，移除一个已经消费的值 wg.Done() &#125; &#125;() &#125; // 将worklist里的数据上传到jobs当中 for _, url := range worklist &#123; jobs &lt;- url wg.Add(1) fmt.Println(\"add\", url) &#125; //增加等待，避免退出 wg.Wait()&#125; 其实很简单，我们捋一下逻辑 创建一个有长度限制的空channel 空channel是一个消费者队列 创建一个生产者逻辑，生产者就是往channel传递数据 遍历channel进行消费 增加wait等待，避免没消费完自动退出 结尾这一节给出了几个基础并发模型，讲了一下Golang并发的哲学思维，这里其实是做了一个笔记，可以持续性发散思维解决问题。下一节我会实现一个分布式并发框架，都会用到这里面所有的东西。over。 并发循环这套东西，说多不多，说少不少，重头戏Context我放到下一节去写了，因为我认为那个还是需要花点功夫的，最近是年底了，学习还是不能停下来，向前吧老铁们！","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"架构设计和项目管理心得-写于第三个独立开发项目之后","slug":"架构设计和项目管理-写于第三个独立开发项目之后","date":"2020-10-20T02:15:51.000Z","updated":"2020-10-21T08:40:33.049Z","comments":true,"path":"2020/10/20/架构设计和项目管理-写于第三个独立开发项目之后/","link":"","permalink":"https://yemilice.com/2020/10/20/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86-%E5%86%99%E4%BA%8E%E7%AC%AC%E4%B8%89%E4%B8%AA%E7%8B%AC%E7%AB%8B%E5%BC%80%E5%8F%91%E9%A1%B9%E7%9B%AE%E4%B9%8B%E5%90%8E/","excerpt":"","text":"前言本月20号，我完成了我第三个独立开发项目，并且通过测试顺利交付了。 首先先总结一下我这半年都干了什么吧。 回想一下，从去年开始，我就被安排独立开发，从无到有，从惶恐到上手，从不知所措到游刃有余，其实还是度过了一个比较漫长的阶段，还好挺过来了。 总计开发三个项目，基本从架构到设计，后端的框架/代码都是我开发的，代码量涉及10W+行， 开发语言横跨Python/Golang/Java, 涉及框架Flask，Django，Gin等等， 后端数据库涉及Mysql，ElasticSearch，ETCD。 我会通过这三个项目，总结一下自己踩坑的问题和自己的心得，做一个记录，也是对自己这半年痛苦的一个回望吧，希望明年会更好。 写出来才知道自己究竟都干了些什么，不知道这阵996的日子是怎么熬过来的，写一句歌词吧。 1234567不知道你会不会想起未来的我在照亮你 在灯下想到现在的我我知道这封信是给你 给我的Kong2020年秋 get it 第一个项目-初试牛刀其实怎么说呢，第一个项目算是野蛮成长的典型，我的习惯就是拿到需求的时候就要分析一下，首先还是老样子，分析需求，这边由于一些隐私相关，我会将项目的核心模糊化处理，请见谅. 第一个项目-需求分析你知道，在国内的开发环境里，很多时候都是老板/大领导拍脑袋提一个模棱两可的一句话需求，例如：我们要做一个xxx，大概有什么功能。 这样就非常坑爹，但是如果咱们遇到了，也要咬牙给它扛了对吧，这时候就需要对接产品，要找产品去详细了解，到底是一个什么样的功能，我们到底该怎么做，这里就衍生出来第一个问题，如何正确去理解需求。 其实正确理解需求，这句话说起来太容易了，但是做起来就是很难。 如果有一个低水平PM（产品经理），那真的是个天大的灾难，我这几次开发都遇到了这种，只会抄竞品的，只画图的，或者画图不说清楚功能干嘛的，强行加一些完成不了的功能的，这些都是开发人员要面对的。 作为独立开发人员，就算势力单薄，也要弄明白到底需求是个什么样，不能完全的盲从产品，这样会给自己带来很严重的开发问题。包括在后期的架构设计上，也会有很大问题。 如何正确去理解需求呢？首先要明白功能大致是干嘛的，拿我开发这个项目来说，当时，大老板只说了一句，说：我们要做一个数据同步的系统，支持对象存储-本地文件系统互相传输同步。 好了，这就是我们的所有信息，我们分析一下，首先 1数据同步的系统，支持对象存储-本地文件系统互相传输同步 思考一下，数据同步，系统，互相传输，对象存储，文件系统。 首先明白是一个数据同步系统，可以对象存储-文件系统同步传输，反推一下，那当然也可以文件系统-对象存储传输了，文件系统同时也分为nfs，cifs，本地文件系统等，对象存储也分为本地，远端两种，这样系统的初步雏形就出来了，为提高效率，很可能是分布式系统，分布式系统还涉及选主，日志记录等，这些都是要注意的部分。预先去准备查询一下这方面的资料，就能在开发中占到先机。 开发第一条：明白你在做什么，或者说，明白你要完成的是什么样的功能 第一个项目-拿到PRD图和设计文档后PRD图这种东西是产品画的，这东西一般就详细说明了你该干什么，做什么，做出来的东西大概什么样子，这东西就相当于，买房子时候的样板房。给你看看的。 核心其实是在设计文档上，一般专业点的PM，在设计文档上会细化到每个功能是干嘛的，大概是做什么的，这个非常重要，对于开发人员来说，这个就类似结构图。 这里要细细的去浏览，一定要精确到每个功能，精准到每个功能具体干嘛，因为这里你稍微不看清楚，未来就是大坑，因为如果你做一个系统，你自己都不了解自己在做什么，那真的没有做的必要了，其实我们需要跳出自己固有的技术思维，不要考虑如何去实现，是不是好实现，要在脑子里有一套完全的大概框架，或者说勾画，明白我们到底在干嘛。 这里衍生出我另一个不足的地方 我在拿到PRD和设计文档后，没有仔细去看设计文档，就只过了一遍PRD，然后大概知道我要做什么了就完了，这里我犯了个错，设计文档里面东西更细化，我没有注意设计文档中的细节，开发当中有些功能甚至没注意到，淦。 第一个项目-需求评审会上提出要求在你大概明白你要做什么的时候，就会召集开发人员/测试人员/产品人员/相关领导 来进行一次需求讨论，所有人都会过一遍需求，并且讨论需求是否合理。 将会从测试/开发/产品/领导的多方角度进行讨论，这次会议对你来说非常重要，记住，非常重要，这可能是你唯一一次可以砍需求的部分了，如果开发进行到后期你是无法砍需求的，所有人都不会同意。 如果前面你进行了铺垫，或者你了解你大概要干嘛了，这次需求会，你的核心要在需求评审上，如果有认为自己可能完成不了的需求，需要及时提出质疑，并且说出理由。 淦，我第一次就掉坑了，有些东西没认真看，糊里糊涂我就答应下来了，后面真的十分痛苦。有些需求做的太难了，不过还好都hold住了。 第一个项目-进行业务架构设计架构这狗东西，说真的，我是被折磨够呛的，说句简单的话，你要考虑架构设计，就先抛开技术层面，首先确定业务架构和逻辑架构，技术的东西可以后面再讨论，但是具体做什么，怎么做，流程是什么样的，需要现在就讨论清楚。 我的逻辑是，先根据PRD和设计文档，划分出具体的功能模块，然后对功能模块进行业务流程规划，然后把功能模块中的业务进行拆分，最后再把他们结合到一起，这就是业务架构。 这里比较抽象, 举个例子，功能模块如下 基于功能模块，业务架构如下 具体流程如下 这里画的比较简陋，随便看看就行了 第一个项目-进行技术框架设计这里就涉及到技术了，主要就是根据项目进行技术选型，数据库选型，开发框架设计，表设计等等。 这个不用多说了吧，大家都是开发人员，技术可以通过多测试得到结果，太虚的东西是没有说服力的，数据库选型这里我还提出了好几个测试报告。 第一个项目-开发时间预估这部分我吃了大亏，开发时间预估，我感觉真的不好判断，因为不确定开发中到底会出现什么事儿，因为我同时还要维护一个检索服务器，或者修改一些bug，或者出差之类的。。。 我个人认为，对自己得有点B数，如果是你本身比较熟悉的语言/框架，时间估计还是可以自己估摸，如果是你不确定得框架/不熟悉的语言，那这里你的时间应该要再加一半，总结一个公式，就是 1不熟悉语言的开发时间 = （预估时间）/2 + 预估时间 + 测试时间 + 调试时间 时间要的不够，你就996吧，到时候整不完把身体整坏了，那就非常不值得了。 第一个项目-项目管理部分其实第一次开发，我印象比较深的还是项目管理部分，按理说项目管理理应产品来做，但是这次产品非常不专业，所以一切还是我自己扛下来了，终于一个人扛下了所有（狗头 首先我拉了一个Excel表，按照开发开始-结束时间划拉了相应的表格长度，然后把日期填充上去，上面是计划，下面是今日进度，每天来公司我就写计划，回撤我就写进度，中间因为疫情在家开发我也没断过，找了个大概的图大家康康。 记录每天的开发进度，并且对功能模块开发进行详细划分开发，上面已经细分了功能模块中的功能，针对每个功能去开发就好了，开发完整个模块进行一次模块调度联调，留出两天时间编写测试代码，大概就是这些。 第一个项目-中期遇到困难的沟通项目开发到中期，由于一开始我的预估不足，出现了很严重的技术难题，这时候千万不要闭口不要，及时抛出问题，抛出问题的好处就是能找到一帮人来帮你解决，至少你不是单打独斗，在独立开发当中，我感觉我一直是孤独的，但是抛出问题的时候，大家伙儿还是愿意帮你解决，一起讨论，让我觉得我不是那么孤单，这样的感觉就很好啦。 第一个项目-项目延期的解决方法项目延期是很正常的事儿，遇到延期，在预估自己可能无法正常完成的时候，需要及时和产品/管理人员沟通，提出项目无法正常完成的原因，我是因为疫情（淦 大家会表示理解并且愿意给你时间去开发的，开发的质量，永远高于速度。 第二个项目-逐渐Dark♂化第一个项目做了差不多三个月，日夜不眠996下终于整完了，没休息几天，第二个项目就来了，TMD是纯粹不让我休息，我算是明白了。有了第一个项目的摧残，对第二个项目我充满信心 第二个项目-突发状况的处理这项目其实一帆风顺，但是，开发到最后，遇到一个很大的事儿，被其他同事不小心给删库了！！！！ 你知道这意味着什么，就意味着你两个月等于白干了，996的结果等于你什么也没做，好家伙，那给我气的 这次删库说明什么，很重要的就是代码管理和备份，因为疫情的原因，我只有一台树莓派，我没把代码存到本地，一直在公司的服务器开发，这就很危险了，所以未来我写了几个脚本，直接定时备份，本地-远端，多个机器一起备份，这次是不会丢了。。。。 第二个项目-第三方工具的调研这次开发调用了大量的第三方工具，例如tika，fscrawler等等（你不用整明白这干嘛的），在第三方工具的调用选型部分，踩了一些坑，这里我详细说一下，如果你想要调用第三方工具，你需要一个什么样的调研报告 工具的具体介绍 工具在本项目内的工作（完成什么） 工具的基础使用方法 工具的测试报告 这里的测试报告很宽泛，主要就是指工具的性能，包括基础的压测，部署，和项目的耦合程度等等等等。 第二个项目-项目打包与项目发布各位老铁的公司一般都要运维吧，可惜我这里没有，作词作曲都是老子自己，岂可修！ 打包这块，如果是rpm，相关的spec你要自己写，并且git拉代码自动编译的东西，你也要自己整，这个就相当麻烦，这么麻烦也不见我司给我涨钱啊，fuck。 这里如果你们想听，我可以重开一篇详细说。 第三个项目-完全Dark♂化我已经逐渐习惯一个人干活了。。。我就是孤独猎手独行侠，每次都把很难得活儿抛给我，我真的无语，没有耕坏的地，只有累死的牛（狗头 第三个项目-心情控制我在开发这个项目的时候，已经非常浮躁了，因为我一直没有休息过，我想停下来安心看一下算法，或者是其他高级知识，但是繁重的项目和加班让我没有心情去准备，几个面试也失败了。所以，控制好心情很重要 一个是释放压力，另一个是项目的进度加快，保证项目时时刻刻在可控的范围内，这个对我来说还是比较重要的。 做表是个很好的方法，真的，你能时刻看到自己的进度，其实类似日报，不过日报这种强制写的狗屁东西，反而还不如自己的计划可控。 结尾写的比较潦草，这是我这近半年时间收获的一些经验和接受的教训，期望可以帮助大家吧。下一篇博客应该会是Python一类的高级特性，请期待吧。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"},{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"keywords":[]},{"title":"Elasticsearch大数据量下的优化方法","slug":"Elasticsearch大数据量下的优化方法","date":"2020-10-09T01:10:22.000Z","updated":"2020-10-21T08:37:20.515Z","comments":true,"path":"2020/10/09/Elasticsearch大数据量下的优化方法/","link":"","permalink":"https://yemilice.com/2020/10/09/Elasticsearch%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%87%8F%E4%B8%8B%E7%9A%84%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95/","excerpt":"","text":"前言十一在家待着玩了两天COD，突然想起来似乎放假前有一个Elasticsearch的问题需要处理，的确，现在距离开工也只剩下四天了，哎，假期的日子过的飞快，又到时候说拜拜，又要开始社畜的生活啦，想到心里就万分悲痛。 悲痛完了之后，也的确要想办法去解决问题，所以，今天（10／5），我研究了一下ElasticSearch检索／导入大文件的一些方案，并且输出了一些我个人的建议，这些基本都是实战建议，不会那么偏向理论，所以理论家们，就不要挑我的刺啦，想看理论，咱们回头去写源码解析！多多支持！ 问题描述现在有个ElasticSearch做为基础的检索服务，里面存储很多文档，这些文档多种多样，有PDF，DOC等等，需要对这些文档进行全文检索，所以将这些文档的内容也导入进ElasticSearch当中，文档的内容可能会很大，导入／查询的时候出现了如下问题 导入一些比较大的文件的时候ElasticSearch节点直接Down机，出现了内存溢出OOM的问题，如下所示 1java.lang.OutOfMemoryError: Java heap space 检索的时候，返回的比较慢，当数据量大于100w条，并且基本都要支持全文检索的时候，翻页／高亮，查询非常慢，经常转很久的菊花出不来，翻页也慢，干嘛都慢。 基础环境分析首先需要分析下我自己的干活儿环境，对症下药。 ElasticSearch的集群配置 1234567891011121314cluster.name: Es_testnode.name: es_node1node.master: truenode.data: trueindex.number_of_shards: 5index.number_of_replicas: 1network.host: 10.0.6.244http.port: 9200transport.tcp.port: 9300discovery.zen.ping.unicast.hosts: [\"10.0.6.244\"]discovery.zen.minimum_master_nodes: 1http.cors.enabled: truehttp.cors.allow-origin: \"*\"network.bind_host: \"::\" 然后就没了，算是最基础的ElasticSearch配置了 jvm.options设置为 12xms: 1gxmx: 1g 基础的环境配置就是这样 优化查询和导入的方法1. 配置优化有一句话怎么说的来着，当一切都可以通过加钱来解决的时候，那就不是个问题嘛。 你看看我那个堆内存配置，只有1个G，而且总共测试的机器内存只有8G，这个根本没办法再加，公司的默认测试机都是8G，除开这个还要跑其他服务，例如存储／web等，我想啊，本来就是拖拉机你还想当跑车开？吃肉的东西你让他吃草能行吗，所以再怎么优化，数据量上来了最终还是要沦落到加钱上好机器的最终结局。 不过现在只有拼命在这个烂机器的基础上去优化了 所以，需要修改一波jvm.options配置 12xms: 4gxmx: 4g 这里修改了过后，一般就能解决大部分问题，但如果需要支撑大规模的数据检索和近乎实时的查询任务，这个是非常不靠谱的机器配置，完全是无法支撑业务的，但是领导非要往里面塞这个，还要求优化到极限，我能怎么办。 言归正传，第一步就是 调整JVM的配置 将JVM的配置调整为整个机器内存的一半，比如你的机器是64G内存，你设置xms和xmx就设置成32G，这个是官方推荐的，靠谱！ 2. 减少refresh_interval刷新比率这个可能抽象一点啊，首先这个refresh_interval是干嘛的呢，这玩意儿说白了就是个刷新器，你每次导入数据到ElasticSearch中不能马上被查到，有个固定刷新间隔，也就是refresh_interval控制的，刷新成功之后，数据才能被马上查到。 refresh_interval 如果不设置的话，默认是1s一次，像我们这种导入数据比较频繁的，刷新比率过高，会导致CPU／Memory就像开了氮气加速一样极速前进。。。所以把这东西设置一下，如果不是实时比率要求高的，直接改成30s刷新一次，或者1分钟刷新一次，不要害怕丢数据之类的，当你节点down机，Es自己都保不住了，还管刷新比率？ 修改refresh_interval刷新比率，直接在elasticsearch的配置文件修改 1\"refresh_interval\": \"30s\" 3. 查询缓慢，响应时间长的解决方法这里我更倾向于问题描述是从ElasticSearch获取数据比较慢，比较慢的愿意可能有哪些呢？ 文档过大，可能某个字段非常长，返回的太慢。 ElasticSearch响应慢，CPU／内存占比过高 网络响应慢 我们针对这些问题一个个去解决，对症下药。 3.1 文档过大，某个字段大，返回慢首先看看能不能把过长的字段给拆分出去，拆成另外一张表。如果不可以拆分出去，就在显示的部分想办法。 首先举个例子，假设我们有个字段叫content，里面存的都是解析出来的PDF，DOC文件的文字，这种一般文字都非常多，但是我们需要进行全文检索并且返回检索到的值，Es查询到值以后就会全部返回，这样就非常慢，我们可以通过一些别的手段解决这个问题。 例如，我们原本的返回字段是 12345&#123; \"name\": \"xxx\", \"id\": \"xxx\", \"content\": \"............\"&#125; 展示部分，不展示此字段，对此字段，也不进行返回，在ElasticSearch请求返回值的步骤时，强制性不返回Content字段（返回指定字段），减少查询压力，这样就无需等待全部字段返回了，加快查询速度。 123456&#123; \"_source\":&#123; \"includes\":[\"name\",\"id\"], \"excludes\":[\"desc\"] &#125;&#125; 1234&#123; \"name\": \"xxx\", \"id\": \"xxx\"&#125; 检索部分，当发现检索关键字的时候，进行全文检索，配置highlight高亮，返回检索结果时只返回highlight结果，只匹配第一个highlight结果，其他结果直接丢弃。加快返回的速度。 这里我感觉我说的更抽象了，其实说白了，我们需要配置ElasticSearch的Highlight返回，指定content字段才可以高亮，当检索到匹配值的时候，Es会返回一个highlight的切片（列表），无论如何，我们只取第一个highlight结果，其他结果全部丢弃，这样可以加快检索，返回给前端的部分也有了，这样岂不是很棒？ 4. 分页部分优化ElasticSearch的分页机制有两种，第一种是From + Size的机制，这个相对来说比较简单，还可以进行控制，另一种是Scroll机制，这个就复杂一些，我下面说。 From + Size 它的基础逻辑就是，它首先会确定doc的顺序，进行排序，然后再进行返回，逻辑上来说，它也需要取出所有数据，所以当数据量非常大的时候，从ElasticSearch中取出数据会占用大量CPU／内存，如果跳页过大，例如从第1页瞬间跳到第100页，就会取出第1页到第99页的所有数据，然后排序，然后进行切分，然后再展示第100页数据。。。这个又抽象了，说白了就是，这个分页比较适合一页页往后翻，你要闲的没事儿天天跳来跳去，人家谁Hold住. Scroll的基础逻辑就是，首先，Scroll会维护一个游标，记录你当前读取的doc位置，而不是取出来做除法切分，这个更适合一次性拿一大堆数据出来，它其实类似一个快照，每次你查询的时候，都会记录你上次查询的位置，下次访问就直接从这个位置／快照开始，免去了拿取所有数据的步骤，有更好的检索效率，CPU／内存使用也不会那么大。 4.1 限定分页的数量首先无论如何，我们先限定死，分页的数量，最大1000页，多了不让翻。这是为了保证From + Size机制使用时，跳页数量过大，导致CPU／内存飙升导致服务OOM或者是挂掉，这个可以让前端同学强制限制一波。 4.2 根据数据量大小，逐步替换From + Size 翻页逻辑如果数量过大，前面我也说了，你整From + Size肯定是不行，而且你把客户想象成熊孩子，没事儿干就乱点，乱跳页，动不动就CPU／内存暴增，那不就拉垮了嘛。所以快速切换 From + Size 为 Scroll就得了。 5. 建表（索引）时候的优化在创建表的时候，需要指定一些字段属性，这样会减少查询和检索的内存消耗或者是，这里给出几个我总结的字段优化方法 全文检索的时候，指定的字段类型一定得是 text 其他检索的时候，需要检索字段完整值，需要使用 keyword，如果想做模糊匹配，需要使用wildcard或者*检索 时间字段可以使用date，可以自己定义数据格式 不确定数据长度，需要用long进行设置，避免以后长度超出。 建表的时候，需要设置索引的压缩功能，减少存储空间占用，设置的方法就像这样，”codec”: “best_compression”。 避免自定义Doc的ID，尽量用人家Es自己生成的，你自己整ID一般都是UUID时间戳，还容易重复也慢。 定义分词器没必要所有字段都用，指定几个需要的字段就行了。 确定不会修改的doc需要设置dynamic，禁止更新。 6. ElasticSearch存储位置的转移安装好ElasticSearch之后，默认的位置是在系统盘。 我估摸着数据量一大，没多久你就给系统盘整崩溃了，所以，改换系统盘位置，做好数据迁移是非常有必要的。 修改配置文件，手动切换存储位置, 这里举个简单例子 1path.data: /media/data/elasticsearch 迁移数据文件,修改文件夹权限 123mv /var/lib/elasticsearch/nodes /media/data/elasticsearchchown -R elasticsearch:elasticsearch * 7. ElasticSearch写入性能优化7.1 推荐使用bulk批量写入其实按照我现在的使用场景，发现PDF／DOC有更新／上传到文件系统，就传入到ElasticSearch当中，其实ElasticSearch的批量写入bulk的效率比一条条写效率高多了，这里建议批量写入数据，而不是一条条传入。 7.2 多线程写入ElasticSearch多线程并发写可以利用集群的资源，我这里用Golang做了后端，直接走了一波协程 + 线程，这样可以减底层fsync开销，可以减少单个Es节点压力。 7.3 Translog事务日志的优化translog是用来恢复数据的。Es用“后写”的套路来加快写入速度 — 写入的索引并没有实时落盘到索引文件，而是先双写到内存和translog文件， es存储数据时，先把输出存储在内存中，等到refresh(该时间可以在设置mapping时的setting中设置intavel_refresh=xxx)时间后，才把数据存储到lucene中的segment中，清空内存缓冲区，往磁盘里写入commit point信息，文件系统的page cache(segments) fsync到磁盘，之后把translog旧日志删除掉。 按照逻辑来说，如果降低translog可以提高效率，但是会降低容灾能力。 修改配置，不需要每次都刷新。 12index.translog.durability: asyncindex.translog.sync_interval: 3600s 结尾这次我主要开发了一个ElasticSearch的检索服务器，主要就是用apache tika去读取对象存储中的PDF／DOC等文件，解析文字，传入ElasticSearch当中，主要是全文检索，这个真的费了点功夫，因为我的服务器，实在是太烂了，只有他娘的8个G，还要跑Ceph存储等等等等，优化起来那个麻烦啊，这就相当于你开拖拉机，要我改车给你改成法拉利的速度，你这不是扯嘛。 预告一下下一篇blog，TIKA提取对象存储中的PDF／DOC中的文字，有点儿绕是吧，绕就对了！哈哈哈，走你，下次见！","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"},{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Python的协程知识","slug":"Python的协程知识","date":"2020-09-01T02:20:47.000Z","updated":"2020-09-14T02:33:40.178Z","comments":true,"path":"2020/09/01/Python的协程知识/","link":"","permalink":"https://yemilice.com/2020/09/01/Python%E7%9A%84%E5%8D%8F%E7%A8%8B%E7%9F%A5%E8%AF%86/","excerpt":"","text":"前言最近心情一直不是太好，写出来的东西感觉也没有灵感，有些时候做了很多事，但是回想起来感觉自己还是什么都没有做。这是9月份第一次更新blog，也更新一篇相对高级一些的技术吧，有一阵没看Python了，想想还是不要落下了，剧透一下，下一篇文章还是针对Elasticsearch或者是前端框架React的，学习还是不能停下来，最近写歌也有问题，感觉自己什么也写不出来，仿佛失去了灵感，是生活还是时间消磨了我的灵气呢？我不愿意这么想，我会努力的，状态会调整过来的。 什么是协程？首先上一个官方的解释 12协程: 协程，又称微线程，纤程，英文名Coroutine。协程的作用，是在执行函数A时，可以随时中断，去执行函数B，然后中断继续执行函数A（可以自由切换）。但这一过程并不是函数调用（没有调用语句），这一整个过程看似像多线程，然而协程只有一个线程执行. 你觉得抽象吗，那就让我给你一个完美的解释（狗头） 大白话解释，协程是个什么，其实就是告诉你，在线程的执行中，可以随时停止某个子程序，然后去执行别的子程序，在指定的时候，继续切回来干活，你可以把子程序认定为是Python中的函数，其实就是，几个兄弟干活，一个兄弟拉跨了，其他兄弟把他从工作岗位上扒拉下来，告诉他，小B崽子滚犊子，一边玩去，一会休息好了你再回来，还不耽误其他人干活，休息好了继续投身工作岗位。 一般协程在涉及到I/O操作的时候特别好用，你可以把协程理解为轻量级别的线程。 协程的好处是？第一个就是解决I/O问题，什么是I/O问题呐，一般就是通过网络或者存储去访问或者写入数据，一般就是数据库取数据，或者是往数据库里面写数据等等，这都属于I/O操作。协程说自己解决了I/O问题。其实就是协程由程序自己控制，减少线程切换的开销，不存在写变量的冲突，执行效率高于线程。 一般来说，由于GIL锁的限制，Python的线程相对拉跨，用了协程，就约等于起飞，至少在互联网，协程还是很重要的。 Python协程的使用场景一般都是高并发服务，用我自己的使用场景来说，举个例子 我现在有个服务，登陆的用户，需要定时更新自己的资料，当初的逻辑就是一个用户去开启一个线程访问，但是不停的开启，关闭线程开销太大了，如果登录用户过多，一次性开好几千个，岂不是很xx，这时候利用协程，一个线程开一大堆协程去处理这事儿，第一是减少了开销，第二是增加了效率。所以在频繁的I/O请求当中，协程是非常可取的。也是可靠的。 Python协程的基础实现这里分为Python2和Python3，这里的实现方式分很多种 Python2的协程Python2的协程支持不太好，但是兄弟们还是可以实现一下 Python2实现协程的方法就是 yield + send 和 *Gevent 首先，Python怎么支持协程呐，是通过Generator实现的，也就是生成器，协程也是生成器的一种，只是遵循指定的规则，这边儿兄弟就不说生成器的逻辑了，这个后面再去研究，今儿只说协程。 在Python2中，指定一个生成器的方法是使用关键字yield，这里写一个简单的生产者消费者模型来说明协程的使用场景 首先这是一个普通的生产者消费者模型，看代码，这段代码来自于廖雪峰的网站 1234567891011121314151617181920212223242526272829303132def consumer(): print(\"[CONSUMER] start\") r = 'start' while True: n = yield r if not n: print(\"n is empty\") continue print(\"[CONSUMER] Consumer is consuming %s\" % n) r = \"200 ok\"def producer(c): # 启动generator，send（None）是启动协程的必要环节 start_value = c.send(None) print(start_value) n = 0 #生产 while n &lt; 3: n += 1 print(\"[PRODUCER] Producer is producing %d\" % n) # 这里就是执行消费者的必要逻辑 r = c.send(n) print('[PRODUCER] Consumer return: %s' % r) # 关闭generator c.close()# 创建生成器c = consumer()# 传入generatorproducer(c) 这里其实很好理解 第一步，创建一个消费者生成器，生产者producer启动，c.send(None)的意思是启动/恢复生成器，这边启动一个生成器，开始生产。 第二步，消费者是一个生成器对象，可以被生产者调用，代码在继续执行，执行到生产者的c.send(n)时，发送了一个n值给消费者，消费者获取到值，进行消费操作。 当不再执行生产者，调用close，关闭操作。 这里有两个重要参数 send(None) ： 启动 send(value) ： 传递参数 生产者生产消息之后，通过yield直接执行消费者，消费者执行完之后立刻切换生产者，同函数内操作，避免了线程锁，队列等待等，还是比较快的。 旧的生产者消费者模型，是通过lock来控制队列，在协程当中，producer和consumer相互合作，从头到尾没有用到lock，所以，这才是协程的最佳表现呀。 Python3的协程Python3引入了牛逼的async，这时候调用起来更加起飞，这个上一篇我写了个读源码的，其实简单一句话，async首先会整一个事件循环的loop，然后轮询任务，直到最后一个任务结束，这个我上一篇写过一个读源码的，这里也就不多废话了。 写点代码来表述一下Python3的协程怎么用，这里我直接参考了网上的一个兄弟，这里很感谢他，如果代码是你写的，请联系我，我加上你的署名，感恩！ 1234567891011121314151617181920212223242526272829import timeimport asyncioasync def taskIO_1(): print('开始运行IO任务1...') await asyncio.sleep(2) # 假设该任务耗时2s print('IO任务1已完成，耗时2s') return taskIO_1.__name__async def taskIO_2(): print('开始运行IO任务2...') await asyncio.sleep(3) # 假设该任务耗时3s print('IO任务2已完成，耗时3s') return taskIO_2.__name__async def main(): # 调用方 tasks = [taskIO_1(), taskIO_2()] # 把所有任务添加到task中 done, pending = await asyncio.wait(tasks) # 子生成器 for r in done: # done和pending都是一个任务，所以返回结果需要逐个调用result() print('协程无序返回值：'+ r.result())if __name__ == '__main__': start = time.time() loop = asyncio.get_event_loop() # 创建一个事件循环对象loop try: loop.run_until_complete(main()) # 完成事件循环，直到最后一个任务结束 finally: loop.close() # 结束事件循环 print('所有IO任务总耗时%.5f秒' % float(time.time()-start)) 结尾基础的协程逻辑就是这些，最近很久没写blog了，下一篇应该是和Elasticsearch或者k8s有关，先这样吧。最近也太累了，想好好休息下，也要思考下换一份工作了。","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"},{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"读Python的协程库asyncio源码随想","slug":"读Python的协程库asyncio源码随想","date":"2020-08-27T06:39:33.000Z","updated":"2020-08-28T07:01:48.859Z","comments":true,"path":"2020/08/27/读Python的协程库asyncio源码随想/","link":"","permalink":"https://yemilice.com/2020/08/27/%E8%AF%BBPython%E7%9A%84%E5%8D%8F%E7%A8%8B%E5%BA%93asyncio%E6%BA%90%E7%A0%81%E9%9A%8F%E6%83%B3/","excerpt":"","text":"前言其实想了一下，Python有一阵没好好看了，这样不好。刚好前阵子看了一下Golang的协程，我寻思看了那么多协程逻辑，也该看看Python的。 一看Python，都更新到3.8.3了，真厉害啊！我们现在线上的项目还是2.7，迁移的代价太大了，Python现在更新了asyncio库，这个库可以傻瓜式完成协程，异步等等操作，看起来是相当牛逼，话不多说，去看看它的源码，弄明白它的运行逻辑，顺便学习一下Python官方的代码写作手段，可别到时候，代码没写好，整出一大堆格式问题呀。 这是我第一次写读源码类的文章，如果写的不好，请多多包涵呀！ Python中的协程是什么前阵子我说了一下Golang的协程，现在又跳到Python的协程来了，巧了嘿，golang的协程，其实就是用一个关键字go去完成的 类似 1go example() 而Python的协程是怎么表现的呢，其实就是通过一个关键字async定义，就像这样 12async def async_work(): return 1 理论上来说，Python的协程调用类似 12345678910&gt;&gt;&gt; import asyncio&gt;&gt;&gt; async def main():... print('hello')... await asyncio.sleep(1)... print('world')&gt;&gt;&gt; asyncio.run(main())helloworld 它并不像go一样，直接调用关键字就可以执行 简单地调用一个协程并不会将其加入执行日程，需要用到run()这个函数 所以还是有不一样的。。。这属于只是有Golang那味儿，但是核心不是人家西方那一套。 其实Python由于自身GIL线程全局锁，在处理一些需要高并发处理的操作时候就显得有些力不从心了，一般这种时候，在我用Python2开发的时候，我会用多进程+多线程混用操作，务必榨干Python2的所有性能，但是Python3之后引入了类似golang的关键字async，可以直接调用协程，这样不就有golang那味儿了嘛，所以我看了一下这个库的文档，也基本弄明白这东西怎么使了。 协程的创建（asyncio.create_task）create_task函数用来并发运行作为 asyncio任务的多个协程，举个例子 将 coro 协程 打包为一个 Task 排入日程准备执行。返回 Task 对象 该任务会在 get_running_loop() 返回的循环中执行，如果当前线程没有在运行的循环则会引发 RuntimeError。 1234async def coro(): worksomething...task = asyncio.create_task(coro()) 基础使用看完了，然后呢。。。 先去源码库里面看一下create_task的源码(Python的版本是3.8.3) 1234567891011121314def create_task(self, coro, *, name=None): \"\"\"Schedule a coroutine object. Return a task object. \"\"\" self._check_closed() if self._task_factory is None: task = tasks.Task(coro, loop=self, name=name) if task._source_traceback: del task._source_traceback[-1] else: task = self._task_factory(self, coro) tasks._set_task_name(task, name) return task 这里主要接受到一个协程作为参数，并且还有name 1task = tasks.Task(coro, loop=self, name=name) 这里会新建一个task实例并且返回。 协程的休眠（asyncio.sleep）有些时候需要让协程去等待，或者阻塞指定的时间，就需要调用sleep函数，sleep一般会把任务挂起，然后不影响其他任务运行。 以下协程示例运行 5 秒，每秒显示一次当前日期 12345678910111213import asyncioimport datetimeasync def display_date(): loop = asyncio.get_running_loop() end_time = loop.time() + 5.0 while True: print(datetime.datetime.now()) if (loop.time() + 1.0) &gt;= end_time: break await asyncio.sleep(1)asyncio.run(display_date()) 看下人家的源码 123456789101112131415161718192021222324252627282930313233@types.coroutinedef __sleep0(): \"\"\"Skip one event loop run cycle. This is a private helper for 'asyncio.sleep()', used when the 'delay' is set to 0. It uses a bare 'yield' expression (which Task.__step knows how to handle) instead of creating a Future object. \"\"\" yieldasync def sleep(delay, result=None, *, loop=None): \"\"\"Coroutine that completes after a given time (in seconds).\"\"\" if delay &lt;= 0: await __sleep0() return result if loop is None: loop = events.get_running_loop() else: warnings.warn(\"The loop argument is deprecated since Python 3.8, \" \"and scheduled for removal in Python 3.10.\", DeprecationWarning, stacklevel=2) future = loop.create_future() h = loop.call_later(delay, futures._set_result_unless_cancelled, future, result) try: return await future finally: h.cancel() 这里的写法让我一瞬间想到golang，粗略说一下把，这里主要是传入一个协程等待时间delay，通过调取get_running_loop()获取事件循环，等待yield，然后暂停执行协程达到的协程阻塞效果。 这里引出来一个重要概念，get_running_loop()，这个东西是干嘛的？ get_running_loop函数是干嘛的？首先去定位一下人家的源码 12345678910111213141516171819202122232425262728class _RunningLoop(threading.local): loop_pid = (None, None)_running_loop = _RunningLoop()def get_running_loop(): \"\"\"Return the running event loop. Raise a RuntimeError if there is none. This function is thread-specific. \"\"\" # NOTE: this function is implemented in C (see _asynciomodule.c) loop = _get_running_loop() if loop is None: raise RuntimeError('no running event loop') return loopdef _get_running_loop(): \"\"\"Return the running event loop or None. 输出一个event loop，主要是一个循环事件的TLS This is a low-level function intended to be used by event loops. This function is thread-specific. \"\"\" # NOTE: this function is implemented in C (see _asynciomodule.c) running_loop, pid = _running_loop.loop_pid if running_loop is not None and pid == os.getpid(): return running_loop 可以看出来一点，get_running_loop（获取事件循环）的主要功能就是返回当前 OS 线程中正在运行的事件循环，这样可能说起来抽象一点，大白话的意思就是事件循环是asyncio的核心，异步任务的运行、任务完成之后的回调、网络IO操作、子进程的运行，都是通过事件循环完成的。所以这个相当于是发动机了。 协程的结果（asyncio.Future）这里换种理解方法 有些时候我们想得到协程的返回值，但是在Python的协程里面任务有些时候会执行，但有些时候不会，所以Future相当于一个最终结果，无论协程是否执行。 Future是一个await（可等待）对象，await我下面会说，意思就是，它其实和Task一样，是一个可以被等待的。 其实理解一下，就是Future是协程的封装函数。 这部分源码太多了，我直接拿官方例子来说明 123456789101112131415161718192021222324252627282930async def set_after(fut, delay, value): # 设置一个等待时间 depay是秒数 await asyncio.sleep(delay) # 设置一个future的结果 fut.set_result(value)async def main(): # 来一个loop循环 loop = asyncio.get_running_loop() # 来一个新的future fut = loop.create_future() # Run \"set_after()\" coroutine in a parallel Task. # 创建一个task，去设置future的结果 # We are using the low-level \"loop.create_task()\" API here because # 开始 # we already have a reference to the event loop at hand. # Otherwise we could have just used \"asyncio.create_task()\". loop.create_task( set_after(fut, 1, '... world')) print('hello ...') # Wait until *fut* has a result (1 second) and print it. print(await fut)asyncio.run(main()) 上面那个例子就是创建一个Future对象，创建和调度一个异步任务去设置Future结果，最后再去等待结果。这就是基础的用法。 协程的等待（await）await其实就是声明协程挂起，其实就是在执行的时候挂起某个协程函数，等待挂起条件结束后，再回来执行。 它其实是一个关键字，就像async一样 这里举个例子 1234567891011&gt;&gt;&gt; import asyncio &gt;&gt;&gt; async def main():... print('hello') # 等待1s... await asyncio.sleep(1)... print('world') &gt;&gt;&gt; asyncio.run(main())helloworld 结尾这块真的好久没看了，我也是第一次写源码类文章，我估摸着写的的确不太好，不过一回生，二回熟，下次我会写的更好的，哈哈哈 今天终于周五啦,好开心啊，下一步应该是继续刷算法看书了，大家有什么不懂的可以给我发邮件的。","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"},{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"},{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"},{"name":"黑科技","slug":"黑科技","permalink":"https://yemilice.com/tags/%E9%BB%91%E7%A7%91%E6%8A%80/"}],"keywords":[]},{"title":"Golang语言的一些基础(针对面向基础的笔/面试)","slug":"Golang语言的一些基础-针对面向基础的笔-面试","date":"2020-08-25T01:43:13.000Z","updated":"2020-08-25T05:12:44.885Z","comments":true,"path":"2020/08/25/Golang语言的一些基础-针对面向基础的笔-面试/","link":"","permalink":"https://yemilice.com/2020/08/25/Golang%E8%AF%AD%E8%A8%80%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80-%E9%92%88%E5%AF%B9%E9%9D%A2%E5%90%91%E5%9F%BA%E7%A1%80%E7%9A%84%E7%AC%94-%E9%9D%A2%E8%AF%95/","excerpt":"","text":"前言昨天让无糖信息的面试官嘲讽了之后，我火速写了一篇博客嘲讽回去一波，但是嘲讽归嘲讽，该做的事儿还是要做的，所以昨天晚上花了一些时间总结了一些Golang的基础，作为查漏补缺和自己学习。 还有就是，无糖信息这种公司对待面试者的态度，也决定这个公司的基本格局，反正我是不会去了，如果看到这个blog的人，你们去面无糖信息的Golang还是要用点心，得有个大心脏，因为那个面试官根本就不会care你的感受。 嘿嘿，不过那个面试官，我不知道你的名字，我也不会care你是否能看到，我只希望你以后懂得尊重这个词语的意义。 面试官先生，你应该不会看到我的博客，那我用一些歌词回击你吧，不过看你那个样子，应该不懂音乐（狗头）。 12345自由的灵魂，从来都不需要拟行程，我们的目标在云层。 Golang的理论基础Golang的保留字段有哪些？12345break default func interface selectcase defer go map structchan else goto package switchconst fallthrough if range typecontinue for import return var Golang声明变量的方法？1234567var a int = 1 //第一种: var variable_name variable_namevalue := 1 //第二种: value_name := 1var b, c, d = 1, 2, 3 //第三种: 合并声明var( //第四种: 合并声明 value1 int = 1 value2 string = \"hello world\") Golang声明常量的方法？12345const var a int = 1const var ( b int = 1 c string = \"hello world\") Golang的init函数是什么？程序运行前的注册功能，理解为Python的init也可以 init函数的特性 1234561. init函数先于main函数自动执行，不能被其他函数调用；2. init函数没有输入参数、返回值；3. 每个包可以有多个init函数；4. 包的每个源文件也可以有多个init函数，这点比较特殊；5. 同一个包的init执行顺序，golang没有明确定义，编程时要注意程序不要依赖这个执行顺序。6. 不同包的init函数按照包导入的依赖关系决定执行顺序。 defer是什么？延迟函数的意思 举个例子 下面的函数返回什么值？ 123456func test1() (result int) &#123; defer func() &#123; result++ &#125;() return 0&#125; 此处应该返回一个1 defer后进先出是怎么表现的？举个例子 12345func main() &#123; for i := 0; i &lt; 5; i++ &#123; defer fmt.Printf(\"%d \", i) &#125;&#125; 此处会返回，4，3，2，1，0 Golang的协程是什么？这个问题很宽泛，无糖信息的那个面试官问了我一个很玄幻的问题：“你协程用的多吗？” 我当时很想问，什么叫我协程用的多，Golang有协程，Python也有，用的多不多你看我项目不就完了，分布式，大规模集群的，有几个没用过协程的，这问题就很可笑。 回到主题，协程是什么，按照golang的语法，创建一个协程只需要 1go example() 就可以了。 协程（coroutine）是Go语言中的轻量级线程实现，由Go运行时（runtime）管理。 Golang 的协程本质上其实就是对 IO 事件的封装，并且通过语言级的支持让异步的代码看上去像同步执行的一样。 协程的控制，一般是channel，waitgroup，context之类的，这个我写过文章详细说了，这里就不再描述，如果你们想看，翻一下我以前的blog就可以了。 struct是怎么用的？或者struct是干嘛的？这兄弟名字叫结构体，写过Python的话，你理解为一个固定了格式的dict就可以了 使用的方法 123456789101112131415161718192021import \"fmt\" type Example struct &#123; Name string Age int&#125; func main() &#123; // 声明 e := Example&#123;&#125; fmt.Println(t) t.Name = \"back\" t.Age = 10 fmt.Println(t)&#125; 返回的值:&#123; 0&#125;&#123;back 10&#125; interface是什么？有些东西名义上是接口，其实啥都能干 interface是一种值，它可以像是值一样传递。并且在它的底层，它其实是一个值和类型的元组，interface是一种万能数据类型，它可以接收任何类型的值。 举个例子 123456var a1 interface&#123;&#125; = 1var a2 interface&#123;&#125; = \"abc\"list := make([]interface&#123;&#125;, )list = append(list, a1)list = append(list, a2)fmt.Println(list) 判断interface的值的类型 123456switch v := i.(type) &#123;case int: fmt.Println(\"int\")case string: fmt.Println(\"string\")&#125; interface是一个nil，你理解为Python里面的nil就可以了。 nil也可以调用interfece panic是干嘛的？类似 try-catch-finally 中的 finally，接收一个interface{}类型的值（也就是任何值了）作为参数，Golang没有try catch，所以panic会直接挂掉程序，如果panic中有defer，那么将先会执行defer，然后，再次抛出panic错误，打印堆栈。 多个defer的执行顺序1234func c() (i int) &#123; defer func() &#123; i++ &#125;() return 1&#125; 这时候应该返回 2 一个Go project是如何管理的？很简单，go mod， 创建一个新的工程 1234// 初始化go modgo mod init// 下载依赖包/源码包go mod vendor vendor是一个源码包的集合。这个过于基础了，实在没想到这种题都能考。 slice切片的基础操作把切片理解为Python中的list，这样是不是就简单多了 声明空切片 1var sliceTmp []int 初始化一个切片 1sliceTmp2 := []string&#123;\"a\",\"b\",\"c\"&#125; 修改一个切片的值 1sliceTmp2[0] = \"b\" 追加切片值 1sliceTmp2 = append(sliceTmp2,\"d\") 截取切片段 1var sliceTmp5 = sliceTmp4[1:4] 遍历切片 123for index, value :=range s1&#123; doSomething&#125; make是干嘛的？简单地说，make就是告诉计算机，我要申请内存了，你给我腾地儿。 因为我们对于引用类型的变量，不光要声明它，还要为它分配内容空间 make用于内存分配，但只用于通道chan、映射map以及切片slice的内存创建。 举个例子 123456789101112131415161718192021// 创建一个指定长度的切片mySlice1 := make([]int, 5)//创建一个初始元素长度为5的数组切片，元素初始值为0，并预留10个元素的存储空间： mySlice2 := make([]int, 5, 10) //创建了一个键类型为string、值类型为PersonInfomyMap = make(map[string] PersonInfo) //也可以选择是否在创建时指定该map的初始存储能力，创建了一个初始存储能力为100的map.myMap = make(map[string] PersonInfo, 100) //创建并初始化map的代码.myMap = map[string] PersonInfo&#123; \"1234\": PersonInfo&#123;\"1\", \"Jack\", \"Room 101,...\"&#125;, &#125; //创建有缓存通道ch := make(chan int, 10)//创建无缓存通道ch := make(chan int) Golang中Json忽略字段有些时候有些字段我们要忽略掉，这里要在定义struct的时候做文章，这边采用了定义nil的手段 123456789101112131415type astruct struct &#123; A string B string C interface&#123;&#125;&#125;func main() &#123; var a = astruct&#123; A: \"hello\", b: \"hello\", C: nil &#125;&#125;定义nil直接忽略值就可。 map的一般用法想成Python中的dict，不同的是这东西需要你提前定义 map的常见操作有：声明、赋值、添加、删除、查询、遍历、清空等 123456789101112131415varstuMapmap[int]string //声明 var map名称 map[键类型]值类型mapScore:=make(map[string]float32) //或者这样声明​stuMap=map[int]string&#123;1001:\"Tom\",1002:\"Tim\"&#125; //赋值stuMap[1003] =\"Tem\" //添加delete(stuMap, 1003) //删除​data, flag:=stuMap[1003] //查询该数据是否存在，不存在时flag为false;存在时 //data存储数据，flag为true​forkey, data:=rangestuMap&#123; //遍历键和值 fmt.Println(key, data) delete(stuMap, key) //循环删除清空&#125;stuMap=make(map[int]string) //或者重新make新的空间以清空stuMap，推荐方法 map的常见方法有：键值存在性、排序、嵌套 1234567891011data, flag:=stuMap[1003] //判断存在性，查询该数据是否存在，不存在时flag为false;存在时 //data存储数据，flag为true​import\"sort\" //利用sort包完成排序功能varsortSlice[]int //定义sortSlice切片 forkey, _:=rangestuMap&#123; sortSlice=append(sortSlice, key) //合成切片&#125; sort.Ints(sortSlice)varstuMap2map[int](map[int]string) //嵌套，即值类型可以嵌套其他类型 Golang中的goroutine并发执行有什么规律？首先，并发，不是并行 如果设置了 1runtime.GOMAXPROCS(n) 这个东西相当于告诉程序，此刻你只能有n个协程去并行，那个n相当于就是一个控制因素 1234567891011121314151617181920import ( \"fmt\" \"time\") func ready(w string, sec int64) &#123; time.Sleep(time.Duration(sec * 1e9)) fmt.Println(w, \"is ready!\")&#125;func main() &#123; go ready(\"Tee\", 2) go ready(\"Coffee\", 1) fmt.Println(\"I'm waiting\") time.Sleep(5 * 1e9)&#125; 结果：I'm waitingCoffee is ready!Tee is ready! 结尾细细一看写了不少了，如果能帮到谁，那我真的非常开心，希望大家的技术都能越来越好。 也希望有些面试官真的，认清自己的能力，你的确有地方可以，但是，下场比划比划，你也有不是个数的地方，所以，对技术抱有敬畏之心，对未知抱有好奇之心，对他人抱有尊重之心，才是能走的更远的本质，这个我相信您一定能懂，不过我也不希望你懂，因为就您这态度，我希望你继续保持眼高于顶的态度。因为我希望你35岁被裁员的时候也会记得你有一天这么对待过别人。 嘿嘿，最后用歌词结束这两天不开心的心情吧。 1234567891011121314151617让时间去给看法错的会被正义斩杀你知道天堂很美孩子们千万别喊害怕你想要的东西必须用全力去争取金钱和权力才不是你想要的生活真谛check~","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"似乎要沉下心来处理一些事","slug":"似乎要沉下心来处理一些事","date":"2020-08-24T08:22:14.000Z","updated":"2020-08-24T11:12:54.683Z","comments":true,"path":"2020/08/24/似乎要沉下心来处理一些事/","link":"","permalink":"https://yemilice.com/2020/08/24/%E4%BC%BC%E4%B9%8E%E8%A6%81%E6%B2%89%E4%B8%8B%E5%BF%83%E6%9D%A5%E5%A4%84%E7%90%86%E4%B8%80%E4%BA%9B%E4%BA%8B/","excerpt":"","text":"前言今天面试感觉不是特别好 其实我一直都觉得自己的技术似乎还行，我估摸着”还行”这个定义真的稍微模糊了一点，更多可能就是我什么都懂一些，其实内部什么也不懂 面试的经过真的就算了，毕竟都没到问我核心的那一步。拿了个笔试题让我做，我看了一下基本都是基础，类似校招题那种，返回什么具体值，该怎么返回，xx是干嘛的之类的，这种我就答的很差，错很多，然后华丽GG。 主要是我平常干活基本都是多语言开发混用，有时候还写写自动化测试，写写前端（毕竟全栈。。。），对这种基础我觉得是真的8行，人家面试官也挺给力，判完卷子，直接就说了解了，就这样吧（你可以走了）。 行，那就这样吧，这么多东西你也不问，做了什么你也不问，我做的东西您也不问，算法您也没考，真的不知道怎么说，菜是原罪，我菜我认。 反思具体问题总归是要具体分析，不能像歪嘴赘婿一样，动不动就土味打脸，出一时之气，喊一句“莫欺技术不好，将来让我面试你”就完事儿了，但是讲真，今天还是有点那啥，不甘心 这次面试我发现了我几个很严重的问题 基础技术较差其实很多东西，IDE都帮咱补全了，特别是JB家的IDE，谁用谁知道，设计流程就完事儿了，这次的面试题基本偏向于具体值返回/某个包是干嘛的，其实这种题真的意义不大，真的要考完全可以请出电脑，咱们现场编码，但是我寻思，如果失去IDE，是不是我就是两眼一抹黑？但是IDE存在的意义不就是解放双手？呸，跑题了，回到基础差的主题。 其实有些题我真的知道一个大概，但是就是不知道怎么说，讲真，我觉得我可以和那个面试官好好聊一些别的东西，例如系统设计架构，或者是系统处理，业务高效处理之类的。而不是坐在这里聊一些什么值应该返回什么结果的问题，所以我觉得那个面试官，真的，您似乎不怎么了解我，不过您应该也不care我的想法，同理，我也不care你的。 基础的技术包含了基础的语法，基础的技术思想，或者是一些语法特性，语法糖之类的，如果你是新手，了解这个还是很有必要了，我现在就是复习and查漏补缺，慢慢写手册慢慢复习，对吧。 不知道谁会看到博客，不过我也不在意你们怎么看我，我真的认为啊，像我们这种工作了3年+的人，在每个项目中都扛了很多事儿，更应该了解一下咱们在项目中怎么能更好的处理业务，而不是纠结一个返回值是什么，我个人感觉这次面试完全表现失常，还Tm不如前段时间的几个电话面试发挥的好。您可以认为我是技术无法展现的不甘心，我倒是认为这是面试人员的一种。。。。怎么说呢，我觉得是一种傲慢。 其他我也编不出来了菜，菜，菜，菜菜子的菜，可能就是我太菜，只因为我太菜，哈哈哈。 谈一谈我想要的面试借着自己的这个小天地，我说说我想要什么样子的面试吧。 其实，面试不是考试，评判一个人是否适合公司业务线，或者是是否适合自己的团队，完全可以去引导面试对象，发掘出面试对象的优势。如果答不出来，完全可以走别的逻辑啊，引导到面试官的擅长方向，让面试对象去多说自己的优势，然后再去综合考量是否合适自己的团队。这才是我想要的面试，也是我正在努力的方向。我觉得今天那个面试官就挺xx的，估计一开始也就没认真看，或者就没想诚意招人。 大家都是平等的，真的，您不用高高在上的，觉得自己似乎在一个公司当一个领导是一个很xx的事儿，我也面试过别人，别人来，至少我都是笑着欢迎的，笑着送走的，人家答不出来，至少我还会给出我自己解答然后听他说，我自己是做到这一点的，所以我敢这么说，我面试几个大厂，人家也是这么对我的。 因为这是礼貌问题，也代表我的家庭教养，您这个态度吧，算了算了，对了，你要是看到了，对号入座了，那就很对不起了啊。 我也不知道说什么，就当结尾面试这种东西，本来就是双向的。有些人说，人家可能就是为了完成kpi，或者人家要的不是我这种人，所以你过去不就是自取其辱嘛，不过我不这么想 其实我认为这次倒是给我敲响了一个警钟，第一让我明白了自己的水平是个什么样子，第二让我明白了面试官的水平都是良莠不齐的，你可能可以遇到很好的，或者有点耐心的，你可也能遇到那种话都不说的，无所谓了。 其实说无所谓，心里还是有些不爽，不过这也是自己的一个警示，做事还是要。。以后投简历还是要好好看看，这公司到底需不需要我的技术栈，这次面试全程我和面试官无交流，所以，大家都不要浪费彼此时间了，如果有笔试，请您告诉我，我好好准备，如果没有笔试，咱们好好聊项目，就这样吧。 end，所以我，最近要努力啦！","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"}],"keywords":[]},{"title":"中文分词的算法分析","slug":"中文分词的算法分析","date":"2020-08-21T01:57:46.000Z","updated":"2020-08-21T03:10:41.908Z","comments":true,"path":"2020/08/21/中文分词的算法分析/","link":"","permalink":"https://yemilice.com/2020/08/21/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%9A%84%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90/","excerpt":"","text":"前言起因是一次电话面试，面一个技术比较好的公司，我认为自己玩Elasticsearch还是比较久了，还是能交锋几个回合吧，结果人家一问，中文分词的算法，你有了解吗？ 纳尼？中文分词，不就是调一下中文分词器做index嘛，我说了调用IK分词器，人家让我说一下中文分词的算法，或者你有没有了解过，我只有老实的说，我没。 后来当然是有点凉，我觉得我需要去详细看一下这方面的东西。所以这两天除了看房子，我也具体看了一下Elasticsearch和其他的，例如tika，fscrawler之类的分词逻辑，加上网上的一些资料，还是有一些收获，这里做个记录，也是未来的博客文章从基础转向高级的一个转折点吧。 分词是什么？什么是分词？它能干嘛？首先三连，这个我认为比较基础，简单的说，在我们搭建检索引擎或者设计搜索的时候，为了方便能更加简便的搜索出我们想要的东西，首先听一个术语，叫做分词粒度，例如，我们搜索 “我是吴彦祖”，下面是不同的粒度的分析划分。 我，是，吴彦祖 最细粒度 我是，吴彦祖 正常粒度 我，我是，我是吴，吴彦祖，是吴彦祖 混合粒度 你可以看见，不同的分词效果，带来的分词结果不同，举个例子，我们如果根据正常粒度，搜索 “我”，这时就搜索不出来，但是根据混合粒度，我们搜索 “我”，就能得到 “我是吴彦祖” 的搜索结果，所以，良好的分词，是增加搜索效率和搜索结果的重要因素，同理，分词也是一个搜索引擎的老大部分，这次咱们不说屁股的事儿，咱们光说中文，中文的分词算法组成到底有哪些，您往下看。 中文分词的几个算法解析根据我查询的一些资料，和阅读一些技术文档，我总结出了如下几个搜索算法 词典类分词法这个大类其实比较好理解，现在大部分的搜索引擎都是根据中文字典作为分词的方法，它首先是基于中文字典，然后根据算法做分词，具体的算法如下 最大匹配算法（Maximum Matching）这里分为两种，一种是正向最大匹配，一种是逆向最大匹配，这里我主要说一下正向最大匹配方法，下面我都用MM来代替算法名，后面也都一样。 正向最大匹配算法MM正向算法的原理，其实就是将等待分词的文本和字典进行匹配，遵循的是从左往右匹配的原则，如果匹配上了，切分出一个词汇，举个简单的例子 1234# 等待分词的列表wait_seg_word = [\"我\",\"是\",\"吴\",\"彦\",\"祖\"]# 词典word_dicts =&#123;\"我是\", \"吴彦祖\", \"我\", \"是吴彦祖\", \"彦祖\"&#125; 首先从wait_seg_word开始扫描 wait_seg_word[0] = “我” wait_seg_word[1] = “是” 这时候发现了 “我是” 已经在word_dicts中了，可以做切分了，但是我们需要做到最大匹配，所以继续切分 wait_seg_word[2] = “吴”，发觉 “我是吴” 不能够组成词组，继续往下 wait_seg_word[3] = “彦”, 不能组成任何词组 wait_seg_word[4] = “祖”, “是吴彦祖” 匹配了词典，所以最大匹配为 “是吴彦祖” 这就是基础的正向最大匹配算法 逆向最大匹配算法MM逆向算法其实就是MM正向算法的逆袭思维，我们简单说一下吧。 1234# 等待分词的列表wait_seg_word = [\"我是吴彦祖\"]# 词典word_dicts =&#123;\"我是\", \"吴彦祖\", \"我\", \"是吴彦祖\", \"彦祖\"&#125; 定义一个做大分割值为 4，从右往左切分等待分词的列表 取得到 “是吴彦祖”， 发觉它已经在词典中了 去掉最左边第一个字，得到 “吴彦祖” 以此类推，一直到无法被减去为止。 然后再做一次切分，取得到 “我是吴彦” 再次切分，对比。重复上述步骤。 双向最大匹配算法双向最大匹配法是将正向最大匹配法得到的分词结果和逆向最大匹配法的到的结果进行比较，从而决定正确的分词方法。 这个做个比较就好了，我简单说下它是干嘛的吧。 双向切分算法就是使用正向切分一次、逆向切分一次。如果两次切分结果一样的话就好说了，随便选一个结果就可以。 但是如果切分不一样的话使用那一次的切分结果呢？这就涉及到了结果的选取原则问题。切分词应该遵守以下原则： 1：最大匹配原则：上面一直在说这个，使用这个原则的原因是词的字数越多，表示的含义越丰富、对于一条语句分出来的词也就越少，相对的，准确性也就会越高。 2：词库中没有的单字词越少越好。这个原则有点依赖于词库了，至少词库中应该有一些常用的单字成词的字吧，比如：“你”、“我”、“他”、“和”、“的”、“了”等。使用这个原则的原因可以从上面提到的“我是吴彦祖”这个例子看出来： 正向结果：我是、是、吴彦祖 逆向结果：我是、我、是吴彦祖 虽然分出来的结果单字词都是一个，但是，逆向的单字词”和“在词库中存在，所以我们选择返回逆向切分结果。 其实说白了就是很依赖词库，如果没词库就是一个哑巴教一个不会说话的孩子念绕口令，纯属烧脑。。。。 统计类分词法统计分词是什么？其实说白了，通过相邻的字同时出现的次数越多，就越可能构成一个词，也就是出现的频率。同样的词组出现多次，被统计的概率越大，组成合理词组也就越精准，可信。因此字与字相邻出现的概率或频率能较好的反映词的可信度。 根据我查询的资料和实践所得，具体有这么几种算法 N-gram模型算法这个主要运用在tika当中，tika你不会不知道吧？你不知道？后面我写个文章你瞅瞅去吧。。。。 tika是我做全文检索插件的时候接触的，它的核心分词算法就是N-gram算法，这个比较重要，我会详细的说一下这个算法。 首先，N-gram是一种基于统计语言模型的算法。它的基本思想是将文本里面的内容按照字节进行大小为N的滑动窗口操作，形成了长度是N的字节片段序列。（这段出自知乎） 一个N-gram就是一个长度为N的词语组成的序列。 简单的流程 N-Gram 算法具体过程： 过滤掉文本数据中的标点符号和其他特殊字符； 对所有单词执行小写转换，并删除单词之间的空格、换行符等标志位； 使用长度为 N 的窗口对文本内容执行字符级滑动取词，将结果存入有序列表。 这里直接借鉴了别人的代码，看的懂就行 12345678910111213141516171819202122232425262728293031323334353637def text_filter(text: str) -&gt; str: \"\"\" 文本过滤器：过滤掉文本数据中的标点符号和其他特殊字符 \"\"\" result = str() for t in text: if t.isalnum(): if t.isalpha(): t = t.lower() result += str(t) return resultdef slide_word(text: str, l: int = 5) -&gt; list: \"\"\" 滑动取词器 Input: text='abcd',l=2 Output: ['ab','bc','cd'] :param text: 过滤后的文本 （只包含小写数字/字母） :param l: 滑动窗口长度，默认为 5 :return: \"\"\" tf = text_filter(text) result = list() if len(tf) &lt;= l: result.append(tf) return result for i in range(len(tf)): word = tf[i:i + l] if len(word) &lt; l: break result.append(word) return resultif __name__ == '__main__': banner = 'abcdefghigkLMN*^%$* \\r\\n)021' print(slide_word(banner)) 返回 1['abcde', 'bcdef', 'cdefg', 'defgh', 'efghi', 'fghig', 'ghigk', 'higkl', 'igklm', 'gklmn', 'klmn0', 'lmn02', 'mn021'] 隐马尔科夫模型算法 (HMM)通过模拟人对句子的理解，达到识别词的效果，基本思想是语义分析，句法分析，利用句法信息和语义信息对文本进行分词。自动推理，并完成对未登录词的补充是其优点。不成熟. 具体概念:有限状态机\\语法约束矩阵\\特征词库 以往的分词方法，无论是基于规则的还是基于统计的，一般都依赖于一个事先编制的词表(词典)。 自动分词过程就是通过词表和相关信息来做出词语切分的决策。 与此相反，基于字标注的分词方法实际上是构词方法。 即把分词过程视为字在字串中的标注问题。 由于每个字在构造一个特定的词语时都占据着一个确定的构词位置(即词位)，假如规定每个字最多只有四个构词位置：即B(词首)，M (词中)，E(词尾)和S(单独成词)，那么下面句子(甲)的分词结果就可以直接表示成如(乙)所示的逐字标注形式： 123(甲)分词结果：／上海／计划／N／本／世纪／末／实现／人均／国内／生产／总值／五千美元／(乙)字标注形式：上／B海／E计／B划／E N／S 本／s世／B 纪／E 末／S 实／B 现／E 人／B 均／E 国／B 内／E生／B产／E总／B值／E 五／B千／M 美／M 元／E 。／S 首先需要说明，这里说到的“字”不只限于汉字。 考虑到中文真实文本中不可避免地会包含一定数量的非汉字字符，本文所说的“字”，也包括外文字母、阿拉伯数字和标点符号等字符。所有这些字符都是构词的基本单元。当然，汉字依然是这个单元集合中数量最多的一类字符。 把分词过程视为字的标注问题的一个重要优势在于，它能够平衡地看待词表词和未登录词的识别问题。 在这种分词技术中，文本中的词表词和未登录词都是用统一的字标注过程来实现的。 在学习架构上，既可以不必专门强调词表词信息，也不用专门设计特定的未登录词(如人名、地名、机构名)识别模块。这使得分词系统的设计大大简化。 在字标注过程中，所有的字根据预定义的特征进行词位特性的学习，获得一个概率模型。然后，在待分字串上，根据字与字之间的结合紧密程度，得到一个词位的标注结果。 最后，根据词位定义直接获得最终的分词结果。总而言之，在这样一个分词过程中，分词成为字重组的简单过程。然而这一简单处理带来的分词结果却是令人满意的。 总结我估摸着我还是要好好把这些算法过一遍，未来还有很长的路要走，算法也太难了。。。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"},{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"},{"name":"算法","slug":"算法","permalink":"https://yemilice.com/tags/%E7%AE%97%E6%B3%95/"}],"keywords":[]},{"title":"一次Golang服务占用CPU过大的排查经过","slug":"一次Golang服务占用CPU过大的排查经过","date":"2020-08-17T01:51:47.000Z","updated":"2020-08-17T08:31:30.956Z","comments":true,"path":"2020/08/17/一次Golang服务占用CPU过大的排查经过/","link":"","permalink":"https://yemilice.com/2020/08/17/%E4%B8%80%E6%AC%A1Golang%E6%9C%8D%E5%8A%A1%E5%8D%A0%E7%94%A8CPU%E8%BF%87%E5%A4%A7%E7%9A%84%E6%8E%92%E6%9F%A5%E7%BB%8F%E8%BF%87/","excerpt":"","text":"前言前阵子写了个ETCD选主的代码，持续后台执行，相安无事一阵我就干别的事儿去了，我寻思小爷虽然代码写的一般，但是不至于出错啊。 但是我想的实在是太单纯了，应了那句话，我还是too young啊，高估了自己的姿势水平，一下搞出来一个大新闻。周六大半夜告警在那里 biubiubiu 的往我邮箱里塞，我当时正在COD战场上挥汗如雨，手机的震动就像电动马达一样给我腿都快整麻了，一看邮箱，好家伙，CPU占用百分之200多！Cgroup都没给它限制住。 所以我寻思，咱就好好分析下到底怎么回事儿吧。 工具准备一般验证一个server详细的CPU和内存占用，Python我会选择PDB，C++我会选择GDB，但是GOlang这个就相对来说比较陌生，经过我查询资料（谷歌）过后得知，Golang有神奇pprof，还可以分析整个函数占用，这就很牛逼了，果断学习了一波之后上手。 pprof的简单使用首先pprof分为两个大包 123net/http/pprof runtime/pprof 如果你的go程序是用http包启动的web服务器，你想查看自己的web服务器的状态。这个时候就可以选择net/http/pprof。你只需要引入包_”net/http/pprof”。 例如 12345import _ \"net/http/pprof\"go func() &#123; http.ListenAndServe(\"0.0.0.0:8080\", nil)&#125;() 我现在要分析我的go server为什么占用了过大的CPU，所以，我需要在我的Go server的main中添加几行导入pprof的代码，一些业务代码我这里会直接隐去，请见谅 12345678910111213141516171819202122232425262728import ( _ \"net/http/pprof\" \"github.com/gin-gonic/gin\" ······)func main() &#123; // 这里使用了gin框架，模拟我的业务环境 gin.SetMode(gin.ReleaseMode) router := gin.Default() //ETCD选主的逻辑，这里很可能是持续占用CPU的罪魁祸首 go infimanage.Retry(infiapi.InitSyncStart) //调用pprof的逻辑，指定6161端口 go func() &#123; http.ListenAndServe(\":6161\", nil) &#125;() //这里是原本的服务接口,这里只是举个例子，模拟一波 .... router.POST(\"/synctask/add\", addwork, AddSyncWorks) router.GET(\"/synctask/del\", DeleteSyncWorks) s := &amp;http.Server&#123; Addr: \":8788\", Handler: router, ReadTimeout: 10 * time.Second, WriteTimeout: 10 * time.Second, &#125; _ = s.ListenAndServe()&#125; 现在走一波 1go run main.go 现在server就启起来了，然后咱们要来一波分析首先指定监控main server 30s 1go tool pprof http://127.0.0.1:6161/debug/pprof/profile -seconds 30 会冒出下面一大堆东西，就相当于进入了pprof，类似pdb，gdb的调试shell下 123456Fetching profile over HTTP from http://localhost:6161/debug/pprof/profile?seconds=30Saved profile in /Users/eddycjy/pprof/pprof.samples.cpu.007.pb.gzType: cpuDuration: 1mins, Total samples = 26.55s (44.15%)Entering interactive mode (type \"help\" for commands, \"o\" for options)(pprof) 获取CPU占比前10的函数 123456789101112131415(pprof) top10Showing nodes accounting for 25.92s, 97.63% of 26.55s totalDropped 85 nodes (cum &lt;= 0.13s)Showing top 10 nodes out of 21 flat flat% sum% cum cum% 23.28s 87.68% 87.68% 23.29s 87.72% syscall.Syscall 0.77s 2.90% 90.58% 21.77s 80.90% runtime.selectgo 0.58s 2.18% 92.77% 0.58s 2.18% runtime.mcall 0.53s 2.00% 94.76% 1.42s 5.35% runtime.timerproc 0.36s 1.36% 96.12% 30.39s 98.47% go.etcd.io/etcd/clientv3/... 0.35s 1.32% 97.44% 0.45s 1.69% runtime.greyobject 0.02s 0.075% 97.51% 24.96s 94.01% main.main.func1 0.01s 0.038% 97.55% 23.91s 90.06% os.(*File).Write 0.01s 0.038% 97.59% 0.19s 0.72% runtime.mallocgc 0.01s 0.038% 97.63% 23.30s 87.76% syscall.Write 这一波就能看出来了，到底谁才是占用CPU过大的罪魁祸首，看到了么，有个select和etcd的keeplive，但是这样似乎还不那么直观，这时候你需要一个叫做火焰图的东西 pprof输出火焰图安装输出火焰图的server安装配置FlameGraph 1git clone https://github.com/brendangregg/FlameGraph.git 配置FlameGraph 1PATH=$PATH:/rootg/go/src/github.com/brendangregg/FlameGraph 配置go-torch，这是生成火焰图的必备工具 1go get -v github.com/uber/go-torch 生成火焰图确保都安装完成了之后 直接执行命令 此时你要确保第一步那些监控代码已经写入 1go-torch -u http://127.0.0.1:6161/debug/pprof/ -p &gt; cpu-local.svg 这里会生成一个svg，这个东西可以用浏览器打开，打开是这样的 看到没，这一下就暴露出来了，谁占比多，你还可以点进去看详细，比如 这下可以定位了，就是选主逻辑当中的select或者是for循环出了问题 解决问题我们回头去反查ETCD的选主逻辑代码 123456789101112131415161718192021//ElectMasterNode 争抢主节点服务func ElectMasterNode() error &#123; ips, err := GetNodeIp() if err != nil &#123; return err &#125; etcd, err := infidb.New() if err != nil &#123; return err &#125; for &#123; _ = etcd.Newleaseslock(ips) &#125;&#125;//Masterwork 选主尝试func Masterwork() &#123; select &#123; ElectMasterNode() &#125;&#125; 这里的问题就是，在select中重复调用了for循环，应该是出现了for死循环，导致了CPU持续被抢占，这边修改一下代码逻辑 12345678910111213141516171819//ElectMasterNode 争抢主节点服务func ElectMasterNode() error &#123; ips, err := GetNodeIp() if err != nil &#123; return err &#125; etcd, err := infidb.New() if err != nil &#123; return err &#125; _ = etcd.Newleaseslock(ips)&#125;//Masterwork 选主尝试func Masterwork() &#123; select &#123; ElectMasterNode() &#125;&#125; 这样问题应该就完全解决了。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"出埃及记_普通程序员的买房之路","slug":"出埃及记-普通程序员的买房之路","date":"2020-08-10T00:56:30.000Z","updated":"2020-08-25T06:02:44.570Z","comments":true,"path":"2020/08/10/出埃及记-普通程序员的买房之路/","link":"","permalink":"https://yemilice.com/2020/08/10/%E5%87%BA%E5%9F%83%E5%8F%8A%E8%AE%B0-%E6%99%AE%E9%80%9A%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E4%B9%B0%E6%88%BF%E4%B9%8B%E8%B7%AF/","excerpt":"","text":"出埃及记-前篇-买房理由有时候时间一晃，就过去了4年多，我2016年毕业，现在已经是2020年。 按道理说我也是老油条了，不比刚入行的小鲜肉了，但是依旧没个成就，也没个方向。说起买房，无非就是和兄弟朋友推杯换盏中听到的，谁又买了房，谁又结了婚罢了。 当房东再一次要我搬走的时候，我才觉得，有些时候你根本就没有选择的权力，因为人家的容错率很低，直接赔付你一个月房租即可，突然无比羡慕这些大城市中收取房租的人，有些时候会在加班的深夜反思，当年如果早买了房，是不是人生的选择就会多一点点？ 所以在搬了新家的第一个晚上，我躺在硬板床上，思绪似乎飞到九霄云外，我的亲人，朋友都在身边，但是睁开眼，只有我孤独一人空留在空白的房间徘徊罢了。 但是有两个字，我记住了，买房。 是啊，买房吧，那就现在就买吧。 出埃及记-中篇-买房过程选定了自己的购房需求，我就要根据自己的预算来选择房子。 首先需要研读一个比技术文档还要复杂的”限购/购房须知”。 绕来绕去我弄明白了一点，买房的区域是被严格限制了的。 说真的，我一直觉得这些限购的政策从来都是治不了本的，好比我在的高新区，不能够买旁边较为便宜的双流区的房子，只能去往买市中心和比较贵的天府新区的房子，哈哈，说白了，你我都懂得，有些人指定的政策完全都是为了消化指定区域的库存和大房子，正在建设的房子未来是哪里的韭菜接盘？ 像哥德巴赫猜一样，我大概猜出了我要买什么样的房子，奈何我的父母也不是大富大贵之人，手头预算有限，我大概也只能买个小房子去生活，并且这样就要掏空我的父母的大部分积蓄，我心里有些难受，一瞬间不想买房子了，但是母亲告诉我：房子，必须要买，买了房子，你才有家的感觉。 家的感觉？我从6岁开始就没有什么家的感觉了，我的父母很早就分开了，家对我来说永远都是孤独的水泥墙的存在，我更宁愿去相信母亲的意思是我不会被房东随便赶走，也有底气在这个大城市去生活吧。 手头资金不多，受限于政策，旁边的双流，更远龙泉地区，便宜的房子我是买不了的，我只能在南边去寻找合适的房子，是吧，那就买个合适的小房子吧？ 周六，周天跑了两天，我坐在滴滴上面，半眯着眼看着外面飞驰的树木，车辆，人流，看着远方立起的一座座高楼，会想着，我的家，会在哪里呢？这个钢筋水泥筑成的城市里，是否还有我的一席之地呢？ 出埃及记-后篇-未曾买房跑了两天，我还是拒绝了中介给我推荐的跃层，那个跃层很好，我很喜欢 但是他需要我自己将社保转移到双流/龙泉，然后进行别的操作 我听到哑然失笑，安得广厦千万间？当买个房子都这么麻烦的情况下，我有时候觉得自己就像个提线木偶，一直有人在掐住我的脖子而已。 不知道什么时候开始，没有以前那么有灵感，我一直不愿意让自己太懒，但是我有些时候有很多想说的，却堵在嘴边。 今天周一，我心情很复杂，未来，会变得更好吧？！","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"}],"keywords":[]},{"title":"Elasticsearch检索PDF和Office文档的方案测评","slug":"Elasticsearch检索PDF和Office文档的方案测评","date":"2020-07-29T06:02:32.000Z","updated":"2020-07-29T08:25:59.815Z","comments":true,"path":"2020/07/29/Elasticsearch检索PDF和Office文档的方案测评/","link":"","permalink":"https://yemilice.com/2020/07/29/Elasticsearch%E6%A3%80%E7%B4%A2PDF%E5%92%8COffice%E6%96%87%E6%A1%A3%E7%9A%84%E6%96%B9%E6%A1%88%E6%B5%8B%E8%AF%84/","excerpt":"","text":"前言这段时间主要攻关了一下Elasticsearch的一些特性，发觉Elasticsearch还是个挺牛逼的玩意儿，我以前经常用它存日志，还没想着拿来存别的东西，一般不都SQL嘛，但是我看了一下现在流行的检索方案，基本都是elasticsearch做检索引擎，说明这个东西经历了时间的考研，用了的人都说好。 我以前拿Elasticsearch来存储日志，搜东西相当方便，定义好检索语句直接走你，但是我看百度文库搜索，还可以做到docx，pdf关键字检索并且高亮，这个就很厉害了，这两天紧急攻关了一下，把自己踩的坑和收获记录下来，方便未来自己复习/查看 需求分析老样子，写任何blog，我都要做需求分析，这样才能更好的进行开发和写作。 我们要干嘛我们要实现一个elasticsearch检索pdf和office家族文件的功能，并且要对pdf/office文件进行一个全文检索，也就是说，搜索“Yemilice”，不仅仅是标题含有“Yemilice”，内容含有“Yemilice”的文件也要检索出来，并且给人家高亮。 我们的工作环境底层环境 Centos7服务器 Elasticsearch的版本 6.3.2 现有的检索解决方案经过我的发力工作（Google/baidu）,现在市面上流行这么几种方案 Elasticsearch 官方插件 ingest-attachment 第三方开源服务 fscrawler 大数据平台 Ambari 接下来麻烦事儿就来了，这三个方案，到底选哪个？才能更那啥呢，我倒不如把他们一一实现一遍，然后给大家伙儿展示一拨，然后最后再选一个合适的不就得了嘛！ 没事儿，苦了我一个，幸福大家伙儿呗！ 1. ingest-attachment插件这玩意儿是什么呢，说白了就是elasticsearch官方给大家贡献的一个插件，支持你把docx，pdf之类的东西导入到es当中。当然要你自己手动去实现接口。 1.1 ingest-attachment插件的安装首先，我认为你现在在CN境内，你就不要看网上那些老哥教的直接执行 1./elasticsearch-plugin install ingest-attachment 这样你会等到地老天荒也下载不完，现在你需要的就是下个离线包，然后再去安装 下载离线包的网址 1https://artifacts.elastic.co/downloads/elasticsearch-plugins/ingest-attachment/ingest-attachment-6.3.2.zip. 注意一点啊，一定要注意！你的ingest-attachment版本必须和你的elasticsearch一致，你要强行不听我的，到时候费心思整完，弄不好，那你就只能来颗华子再来一次了。 安装离线包 1./elasticsearch-plugin install ingest-attachment-6.3.2.zip 没报错就说明你安上了，不放心的话 1./elasticsearch-plugin list 看一下，有这个插件了说明你已经有了这个插件 1.2 ingest-attachment插件的基础使用看了下官网，其实他的逻辑很简单，整个管道，你把你的pdf/doc什么的给转成base64，然后通过管道把base64传进去，es会把所有的东西给你安排好。 我现在简单的整了个pdf，名字就叫1.pdf，现在开始吧。 抽取管道的函数编写，这里是告诉es，创建一个抽取管道pipeline 12345678910111213curl -X PUT \"localhost:9200/_ingest/pipeline/attachment\" -d '&#123; \"description\" : \"Extract attachment information\", \"processors\":[ &#123; \"attachment\":&#123; \"field\":\"data\", \"indexed_chars\" : -1, \"ignore_missing\":true &#125; &#125;, &#123; \"remove\":&#123;\"field\":\"data\"&#125; &#125;]&#125;' 创建一个index（表），名字叫pdf，设定1个分片（单节点，当然你自己可以改） 12345678910curl --location --request PUT '127.0.0.1:9200/pdf' \\--header 'Content-Type: application/json' \\-d '&#123; \"settings\": &#123; \"index\": &#123; \"number_of_shards\": 1, \"number_of_replicas\": 0 &#125; &#125;&#125;' 将pdf转为base64编码，然后上传到elasticsearch当中 这里网上那个方法是直接perl调base64，我这里一直报错，如果和我一样的老哥，用我下面给得另一种方法 方法1 1234curl --location --request PUT '10.0.7.234:9200/pdf/pdf/1?pipeline=attachment' \\--header 'Content-Type: application/json' \\-d '&#123; \"data\":\" '`base64 -w 0 /root/pdf/pdf.pdf | perl -pe's/\\n/\\\\n/g'`'\"&#125;' 方法2 直接导入base64码 1234curl --location --request PUT '10.0.7.234:9200/pdf/pdf/1?pipeline=attachment' \\--header 'Content-Type: application/json' \\-d '&#123; \"data\":\"JVBERi0xLjcNCiW1tbW1DQoxIDAgb2JqDQo8PC9UeXBlL0NhdGFsb2cvUGFnZXMgMiAwIFIvTGFuZyh6aC1DTikgL1N0cnVjdFRyZWVSb290IDE1IDAgUi9NYXJrSW5mbzw8L01hcmtlZCB0cnVlPj4vTWV0YWRhdGEgMzMgMCBSL1ZpZXdlclByZWZlcmVuY2VzIDM0IDAgUj4+DQplbmRvYmoNC......（这里我不展示完了）\"&#125;' 现在去查看index（表） 显示了作者，之类的杂七杂八信息，而content就是详细的全文，可以直接搜索，因为有我的大名我就马赛克了。。 这就导入了，搜索也是按一般的搜索方法 123456789GET pdf/_search&#123; \"query\": &#123; \"match\": &#123; \"attachment.content\": \"pdf\" &#125; &#125;&#125; 1.3 ingest-attachment插件的性能评测测试导入PDF（10M大小，无图片） base64命令在perl中执行了大概2s左右， 并且CPU/内存 在转换-&gt;存储这个阶段，占用了 可见在抽取文本 ——&gt; 传输存储入es的时候，插件可能会占用少部分CPU 测试导入PDF（40M大小，图片/文字混用） base64命令在perl中执行了大概10s左右，并且还返回了错误（perl长度过大的错误） 并且CPU/内存 在转换-&gt;存储这个阶段，占用了 在图片/文字混用并且pdf文件比较大的情况下，内存占用较大，并且返回较慢，这里需要注意，并且解析的base64会直接塞到系统内存当中，如果做多文件抽取，可能会有CPU/内存占用较大的情况出现。 1.4 ingest-attachment插件的优缺点优点： 安装方便，只需要下载zip安装包，调用elasticsearch本身自带的安装模块即可 使用方便，编辑一条管道抽取命令，可以直接利用linux的base64命令转码存入elasticsearch中 支持的格式比较多，支持ppt，pdf，doc，docx，xls等office常用的办公软件格式导入到elasticsearch当中。 导入后的文档可以直接输入中文进行检索 缺点： 大文件支持不够，如果超过100M的pdf，base64转码将比较缓慢，并且，存入到elasticsearch中的数据也十分庞大 必须要将文件下载到本地，然后必须进行base64转码才可以存到elasticsearch中，等于说，必须要实体文件，因为需要base64转码，如果文件在对象存储/云上，那就不可以这么操作了 对于pdf，doc中含有图片的情况，没有办法将图片中文文字识别出来，而且如果出现图片较多的情况，转码较慢，含有特殊字符的base64码导入也会无法识别。 1.5 ingest-attachment插件的使用场景 存储的文件不那么大的情况 存储的文件大部分都是纯文字的情况 存储的文件全文搜索精准度要求不那么高 2. fscrawler服务一个类似filebeat的监控服务，监控某个文件夹下面的文档，定时去遍历一次，如果发现了新添加的文档则会直接写入到elasticsearch当中。 2.1 fscrawler安装首先非常重要的一点，确定你的elasticseach版本， 如果你的版本 &lt;= 6.3.2，那你需要下载2.5 版本的fscrawler，这个非常重要，否则是无法启动任务的！！！！ 1https://repo1.maven.org/maven2/fr/pilato/elasticsearch/crawler/fscrawler/2.5/fscrawler-2.5.zip 如果你的版本 &gt; 6.3.2, 你就可以随意选择2.6，2.7的fscrawler了，区别还是有一些的，后面我会说。 下载下来，解压，这个你肯定会 1unzip fscrawler-2.5.zip 尝试跑一下 1./fscrawler 输出 12303:53:39,425 INFO [f.p.e.c.f.c.FsCrawler] No job specified. Here is the list of existing jobs:03:53:39,433 INFO [f.p.e.c.f.c.FsCrawler] [1] - work0103:53:39,433 INFO [f.p.e.c.f.c.FsCrawler] Choose your job [1-1]... 说明能用 2.2 fscrawler的使用方法启动服务 查看一下文件结构 编写指定的json去进行服务监控/设置 现在导入一个1.pdf的文件 监控到fscrawler发生了变化 去查看elasticsearch，已经有了这个1.pdf的文件 2.3 fscrawler的配置文件解析（彩蛋）一般来说，咱们fscrawler的配置文件都是默认在/root/.fscrawler/_settings.json下的，但是，如果你的es版本高于6.3.2，你下载的fs版本不是2.5，那么你的settings文件将会是yaml格式的，不知道是不是在向filebeat看齐。。。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#123; // 工程名 \"name\" : \"work01\", \"fs\" : &#123; // 监控的文件夹 \"url\" : \"/tmp/es\", // 多长时间去扫描一次 \"update_rate\" : \"30s\", // 添加例外 \"excludes\" : [ \"*/~*\" ], \"json_support\" : false, // 将文件名作为ID \"filename_as_id\" : false, // 文件大小添加 \"add_filesize\" : true, // 同步删除 \"remove_deleted\" : true, \"add_as_inner_object\" : false, \"store_source\" : false, \"index_content\" : true, \"attributes_support\" : false, \"raw_metadata\" : true, \"xml_support\" : false, \"index_folders\" : true, \"lang_detect\" : false, \"continue_on_error\" : false, // ocr开启 \"pdf_ocr\" : true, \"ocr\" : &#123; // ocr英文 \"language\" : \"eng\" &#125; &#125;, \"elasticsearch\" : &#123; \"nodes\" : [ &#123; // esip \"host\" : \"127.0.0.1\", \"port\" : 9200, \"scheme\" : \"HTTP\" &#125; ], \"bulk_size\" : 100, \"flush_interval\" : \"5s\", \"byte_size\" : \"10mb\" &#125;, \"rest\" : &#123; \"scheme\" : \"HTTP\", \"host\" : \"127.0.0.1\", \"port\" : 8080, \"endpoint\" : \"fscrawler\" &#125;&#125; 2.4 fscrawler的性能评测首先走一波导入文件测试 导入1M纯文字的pdf 瞬间就完成了，速度极快 elasticsearch监控信息如下 Fscrawler占用CPU/内存如下 导入10M纯文字的pdf 瞬间就完成了，速度极快 elasticsearch监控信息如下 Fscrawler占用CPU/内存如下 导入40M文字图片都有的pdf 速度很快，但是CPU占比一下就上去了，es还是没有什么变化 elasticsearch监控信息如下 Fscrawler占用CPU/内存如下 2.5 fscrawler的优缺点fscrawler我其实是比较推荐的 优点 支持的格式很多，并且自带OCR，如果内存/CPU富裕的情况可以直接上OCR，识别率虽然不是特别高但也够用了。 导入不用自己动手，设置好配置之后，fscrawler会帮你创建好index，然后自动导入文件 支持文件过滤，如果监控的文件夹里面闲杂文件比较多可以写正则过滤掉 CPU/内存占比比较低，我是用的自己的虚拟机，导入40Mpdf完全无问题，CPU占比上去了一瞬间就降下来了。 缺点 结合我们的使用场景，我们的文件在远端，需要下载下来，下载到指定文件夹，但是下载到指定文件夹后，fscrawler不会马上导入，是去定时扫描，下载到本地的话可能会把系统盘内存撑满，加快扫描时间会让CPU占比上升 安装部署比较麻烦，需要自己写service，自己写维护 配置文件需要自己定义，容错有问题，如果es down机，原有的文件发送一遍失败之后，不会继续发送 3. Ambari服务这个有个很奇葩的点，是要Es去依赖它，而不是它依赖Es，这东西本身是做大数据的！我感觉咱都有Es了还要啥自行车！ 这个是做大数据用的，安装一个大概1个多G，但是功能比较全面，支持各种大文件导入，还支持图片文字的读取，自动分词之类的，其实还是很好用。 3.1 使用一波AmbariAmbari的安装就不在这里介绍了。。这个安装比较复杂，但是网上大部分都是docker集成的，我们现在的环境没有docker，所以我只有手动安装了，在我的机器已经安上了，现在需要安装Ambari的Elasticsearch插件 1wget https://community.hortonworks.com/storage/attachments/87416-elasticsearch-mpack-2600-9.tar.gz 安装mpack 1ambari-server install-mpack --mpack=/path/to/87416-elasticsearch-mpack-2600-9.tar.gz --verbose 重启ambari-server 1ambari-server restart 在ambari-server 上部署elasticsearch 1curl --user admin:admin -i -H 'X-Requested-By: ambari' -X GET \"http://ambari.server:8080/api/v1/clusters/$cluster_name/configurations?type=cluster-env\" 启动elasticsearch 1systemctl restart elasticsearch 现在可以在Ambari的管理页面看到es服务器了 设置ambar的配置文件 123456789101112131415161718my-files: depends_on: serviceapi: condition: service_healthy image: ambar/ambar-local-crawler restart: always networks: - internal_network expose: - \"8082\" environment: - name=my-files - ignoreFolders=**/ForSharing/** - ignoreExtensions=.&#123;exe,dll,rar&#125; - ignoreFileNames=*backup* - maxFileSize=15mb volumes: - /media/Docs:/usr/data 现在尝试导入一个PDF 1234curl -X POST \\ http://ambar/api/files/Books/1984-george_orwell.pdf \\ -H 'content-type: multipart/form-data; boundary=----WebKitFormBoundary7MA4YWxkTrZu0gW' \\ -F 1984-george_orwell.rtf=@1984-george_orwell.pdf 这下就完成了导入 3.2 高级特性监控S3对象存储 设定ak，sk 12echo ACCESS_KEY_ID:SECRET_ACCESS_KEY &gt; ~/.passwd-s3fschmod 600 ~/.passwd-s3fs 挂载s3 bucket 1mkdir /mnt/s3-bucket 添加挂载到fstab中 1mybucket /mnt/s3-bucket fuse.s3fs _netdev,allow_other 0 0 修改配置文件 123456789101112131415161718my-files: depends_on: serviceapi: condition: service_healthy image: ambar/ambar-local-crawler restart: always networks: - internal_network expose: - \"8082\" environment: - name=my-files - ignoreFolders=**/ForSharing/** - ignoreExtensions=.&#123;exe,dll,rar&#125; - ignoreFileNames=*backup* - maxFileSize=15mb volumes: - /media/Docs:/mnt/s3-bucket OCR文件识别 ambari自带强势的ocr识别，可以识别多种文字/字母/格式的文件，但是需要富裕的CPU和内存 3.3 可能会出现的问题优点 它可以很好地处理大文件（&gt; 100 MB） 它从PDF中提取内容（即使格式不佳并带有嵌入式图像），并对图像进行OCR 它为用户提供了简单易用的REST API和WEB UI 部署非常容易（感谢Docker） 它是根据Fair Source 1 v0.9许可开源的 开箱即用地为用户提供解析和即时搜索体验。 缺点 部署可能会相当麻烦，没有docker部署，单独部署的话配置比较复杂 OCR会占用大量的CPU/内存 如果不是大数据，有些大材小用了 4. 总结我都分析成这样了，该用哪个，心里是不是有点数了，其实很简单 当你的pdf/doc文件不大的情况下，上ingest-attachment插件 当你的文件经常发生变动，上fscrawler 当你是大数据老哥，上Ambari 今天的文章就到这，憋了个大的，如果帮到你，我很开心。 end 2020-07-29","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"},{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"keywords":[]},{"title":"Grow_Up","slug":"Grow-Up","date":"2020-07-28T06:38:28.000Z","updated":"2020-07-28T07:10:11.825Z","comments":true,"path":"2020/07/28/Grow-Up/","link":"","permalink":"https://yemilice.com/2020/07/28/Grow-Up/","excerpt":"","text":"前言有时候觉得自己快要撑不下去 但是依旧不能放弃 为了爸妈 为了自己 为了所有人 ONE温热的咖啡升腾起轻薄的水雾 满屏未敲完的代码依旧在提醒 忙碌和疲惫的一天即将结束 next，即将来到下一个季节 坐上地铁戴上耳机这是属于我的时间 把今天的不堪和疲惫就在此丢失 曾今的挚友们一一远去 他们很多人已把我超越 盲目的赚钱和生活已经让我麻木 也曾今质疑过自己走过的路 但是选择只能让我勇往直前 脚踏实地是我的人生格言 等到积累更多，得到更多的时候 我才能就此歇下，远离喧嚣 TWO不知不觉我已经长大 回想自己经历过的一切 人生只有努力一条路没有捷径 无论如何也会勇敢的深入虎穴 因为要成为能值得被铭记的人物 so what 成功或者失败 就让我燃尽自己所有的能量 然后像灰烬一样洒向远方 挥洒血汗，我是吞噬金钱的野兽 抢风头从来不是我的style脚踏实地才是 和时间之神做个交易吧 将努力和汗水换为当票 典当时间，预支痛苦， 收获的是快乐和幸福 END其实我写这些往往都是DEMO 一般还要做beat，但是我最近实在是没时间写 我有时候挺后悔自己没和自己的兄弟去做说唱 但是世界上是没有后悔药的 现在就动起来吧。","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"},{"name":"说唱之路","slug":"说唱之路","permalink":"https://yemilice.com/tags/%E8%AF%B4%E5%94%B1%E4%B9%8B%E8%B7%AF/"}],"keywords":[]},{"title":"使用Golang的gRPC框架的一点随想","slug":"使用Golang的gRPC框架的一点随想","date":"2020-07-07T05:32:21.000Z","updated":"2020-07-07T08:20:17.510Z","comments":true,"path":"2020/07/07/使用Golang的gRPC框架的一点随想/","link":"","permalink":"https://yemilice.com/2020/07/07/%E4%BD%BF%E7%94%A8Golang%E7%9A%84gRPC%E6%A1%86%E6%9E%B6%E7%9A%84%E4%B8%80%E7%82%B9%E9%9A%8F%E6%83%B3/","excerpt":"","text":"前言（写文章的原因）最近开发项目太重了，我有些感觉自己状态不太对，想要去换一个地方生活，但是说到要做的事就一定要做，学习是不能停下来的。 最近开发使用了一下gRPC，不同于以前我自己写的Python 的 RPC，gRPC相对来说用起来更简单，写起来更容易，可能一开始有点不好使，其实熟悉了也还是不错的，那么，这篇文章主要就写一下，gRPC的基础使用和在我项目中的实际应用吧。 RPC框架是什么简单说下什么是RPC，RPC是什么，全称是Remote Procedure Call Protocol，中文名称是远程调用协议，这个就说的很明白了 RPC干嘛的，远程调用的呗！ 远程调什么？参数呗！函数呗！发消息呗！ 大白话来说，像调用本地服务一样调用远程服务，就是你现在要完成一个动作，你需要一个老哥（机器）和你联动一起完成，所以你就要通过一个渠道告诉他，说，老铁，我们要一起做这个东西，知道吗。 这个渠道，就叫RPC，一般我们在网络服务，分布式服务，微服务中都需要这个东西。 从技术的角度上来说，RPC更类似于一种client，server的通信过程，client发送消息给server，server接收到消息，然后返回消息给client。 gRPC是什么我是在写Golang网络服务的时候发现了这个框架gRPC，一看就是谷歌亲儿子框架，粗看了一下，感觉其实还好，所以我仔细看了一下这个框架 首先这货需要一个ProtoBuf序列化工具，是给客户端提供接口的，ProtoBuf这个东西需要另外安装，没他就不能解析接口，这个的好处是，你的开发语言不受这个影响，相当于就是翻译器，能把多种语言编写的接口api翻译出来，给gRPC去用 第二就是需要gRPC的本体，这个如果你有Golang环境直接go get 即可 除此之外，粗看一下gRPC，其实也需要client和server端，也是互相交互的。 gRPC主要的好处这货的好处 其实说白了，就是性能高，从Golang的开发来说，就表明了gRPC走的也是高性能的逻辑。 protobuf这东西，也是gRPC钦定的接口编写工具，这东西可以严格的约束住接口，告诉他，你可以传什么，不能传什么，加强了gRPC的安全机制 protobuf可以压缩编码为二进制，二进制你们懂吧，这个东西就更快了，耍起来那就是大杀器，首先相比大刀，他就是手枪，不仅小，威力还大，还可以达到kill 人的目的，因为压缩成二进制，传递的数据量也小了，通过基础的http2还可以实现异步请求，这就很nice了。 来玩玩gRPC吧安装protobuf首先你要先去protobuf的大本营 https://github.com/protocolbuffers/protobuf/releases，先找对应的版本下载 我这里是Centos7 64位， 所以我选了protoc-3.12.3-linux-x86_64.zip 下载，你们要去找对应的版本下载。 然后你需要解压 1unzip protoc-3.12.3-linux-x86_64.zip CD到目录, 进到目录的bin下，给protoc赋上可执行的权限 12cd protoc-3.12.3-linux-x86_64/binchmod 777 protoc 这下protoc可用了，你应该把它移动到bin下，方便未来调用 1cp protoc /usr/bin 定义一个protobuf接口重头戏来了，现在我们从零开始开发了，现在我们先创建一个项目文件夹hellogRPC,这下面现在什么也没有。 看图 现在我们创一个名字叫manage的文件夹，在下面创建一个名为manage.proto的接口定义文件，类似这样 看图 现在开始编写proto文件 123456789101112131415161718192021syntax = \"proto3\";option objc_class_prefix = \"HLW\";package manage;//定义服务service GreeterServer &#123; // 定义一个具体的接口，定义输出和输出的样式 rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// 定义输入 stringmessage HelloRequest &#123; string name = 1;&#125;// 定义输出 stringmessage HelloReply &#123; string message = 1;&#125; 这里具体的意思就是，我，下一道圣旨，以后，都按着这个给我输入输出，现在我只开了一个sayhello的接口，别的进不来，就这样。 编译protobuf文件这一步是要把protobuf生成为二进制文件，就像我们前面说的，这也是人家gRPC的一个有点，就是有点儿操蛋，因为麻烦。。。。 1go get -u github.com/golang/protobuf/protoc-gen-go 下下来之后，你还得把他移动一下下，到你的go path下面，我这里是/root/go 12cd /root/go/bincp -r protoc-gen-go /usr/bin 再编译一下，走一波编译 1protoc --go_out=plugins=grpc:. *.proto 这下你可以看见，多出一个同名得pb.go文件，类似这样 这就编译成功了。下一步继续干活儿 编写client服务client相当于发号施令的大哥，主要就是去找server，告诉server，你们要干嘛，要干嘛这种。 咱们现在创建一个client.go文件 现在开写 123456789101112131415161718192021222324252627282930package mainimport ( \"log\" pb \"/你的目录/hellogRPC/manage\" \"golang.org/x/net/context\" \"google.golang.org/grpc\")//HelloWork 定义一个hello world 方法func HelloWork(ip string, name string) &#123; conn, err := grpc.Dial(ip, grpc.WithInsecure()) if err != nil &#123; log.Fatalf(\"did not connect: %v\", err) &#125; defer conn.Close() c := pb.NewGreeterClient(conn) r, err := c.SayHello(context.Background(), &amp;pb.HelloRequest&#123;Name: name&#125;) if err != nil &#123; log.Fatalf(\"could not greet: %v\", err) &#125; log.Printf(\"Greeting: %s\", r.Message)&#125;func main() &#123; //传输要发送的ip，传输name HelloWork(\"127.0.0.1:4321\", \"work\")&#125; 编写server服务server服务就类似于等待发号施令的小弟，他们会常驻在后台等待，并且会开启一个专用端口去接受client发来的信息，类似这样 12345678910111213141516171819202122232425262728293031323334package mainimport ( \"log\" \"net\" pb \"/你的目录/hellogRPC/manage\" \"golang.org/x/net/context\" \"google.golang.org/grpc\")const ( //定义一个端口 port = \":4321\")// 定义servertype server struct&#123;&#125;//定义SayHello 记住，这里的SayHello要和你proto里面的接口名一致func (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) &#123; return &amp;pb.HelloReply&#123;Message: \"Hello \" + in.Name&#125;, nil&#125;func main() &#123; lis, err := net.Listen(\"tcp\", port) if err != nil &#123; log.Fatalf(\"failed to listen: %v\", err) &#125; s := grpc.NewServer() pb.RegisterGreeterServer(s, &amp;server&#123;&#125;) s.Serve(lis)&#125; 来跑一下先启动 server.go 1go run server.go 再启动 client.go 1go run clinet.go 发现输出了 12020/07/07 16:01:10 Greeting: Hello work 这时我们的目录结构如下，基础的gRPC服务也就此完成。 总结其实这个还是比较简单的，但是具体到后面使用，你可能会遇到，gRPC和ETCD冲突，编译的时候出现bug，编译的时候编译器版本对不上等等等等，我这次踩了不少坑，不过还好过来了，项目快要结束了，终于要结束了，我想我需要休息一下，然后去找一个适合我的job。 预告一下，未来我将进行kail linux 和渗透测试的文章更新，基础的技术我应该不会再更了，毕竟我15年入行，16年正式上班，是该有一些蜕变了，未来我将持续输出高质量的文章，请多多期待吧。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"},{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"keywords":[]},{"title":"恶性循环","slug":"恶性循环","date":"2020-06-17T04:43:19.000Z","updated":"2020-06-17T05:05:09.308Z","comments":true,"path":"2020/06/17/恶性循环/","link":"","permalink":"https://yemilice.com/2020/06/17/%E6%81%B6%E6%80%A7%E5%BE%AA%E7%8E%AF/","excerpt":"","text":"前言改 不 了 写 前 言 的 毛 病 这 个 月 心 情 很 不 美 丽 来 自 心 底 的 呐 喊 释 放 出 深 渊 的 野 兽 one我 得 了 名 为 平 庸 的 不 治 之 症 就 让 我 在 灰 暗 的 地 底 死 去 双 手 合 十 祈 求 神 明 的 营救 看 不 到 的 希 望 的 祷 告 不 会 得 到 回 应 无 尽 的 在 深 渊 中 反 复 轮 回 建 起 一 座 名 为 失 败 者 的 宫 殿 不 要 阻 止 我 不 要 拯 救 我 我 根 本 无 药 可 医 就 算 我 一命 呜 呼 我 也 要 夺 走 你 的 一切 这 是 我 的 战 争 宣 言 匹 夫 的 怒 火 只会 萦 绕 在 你 身 上 在 战 争 的 前 线 树 立 起 失 败 者 的 旗 帜 这 就 是 失 败 者 的 战 争 宣 言 two承 认 自 己 平 庸 不 如 让 我 放 弃 自 己 我 出 生 的 那 一 瞬 间 就 证 明 我 要 在 这 个 世 间 留 下 痕 迹 就 算 我 得 了 不 治 之 症 也 不 要 怀 疑 我 要 成 为 坐 拥 一 切 的 人 恶 性 循 环 只 会 让 我 越 来 越 恶 因 为 我 是 来 自 地 狱 的 恶 鬼 不 会 向 任 何 人 低 头 包 括 上 帝 双 手 合 十 可 他 并 没 有 出 现 虽 然 我 活 成 这 样 子 可 是 我 依 旧 不 赖 就 算 我 一 命 呜 呼 也 要 记 得 把 钱 都 给 我 把 鼓 吹 战 争 的 传 单 散 发 各 地 这 就 是 我 的 宣 战 宣 言 高 高 举 起 梦 想 成 真","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"},{"name":"说唱之路","slug":"说唱之路","permalink":"https://yemilice.com/tags/%E8%AF%B4%E5%94%B1%E4%B9%8B%E8%B7%AF/"}],"keywords":[]},{"title":"我的自我介绍","slug":"我的自我介绍","date":"2020-06-02T07:05:31.000Z","updated":"2020-06-02T08:20:43.249Z","comments":true,"path":"2020/06/02/我的自我介绍/","link":"","permalink":"https://yemilice.com/2020/06/02/%E6%88%91%E7%9A%84%E8%87%AA%E6%88%91%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"我的自我介绍hello, 这是我， 你可能不认识我， 那么， 现在由我来进行自我介绍。 do it。 我 叫 Y k，你 可 以 叫 我 l k，来 自 c d c 出 生 在 钟 鸣 鼎 食 之 家，其 他 都 是 secret 有 个 很 爱 我 的 妈 妈，更 多 一 点 不 能 告 诉 你 ok，ok，让 我 们 继 续 下 去 以 前 是 个 Coder 现 在 依 旧 是 Coder 兼 职 玩 个 Rap 但 是 绝 不 是 Faker 从 来 不 穿 Aj but 我 只 爱 air force 嫉 妒 我 的 hater 我 从 来 不 care about 真 正 的 键 盘 侠 用 键 盘 当 做 武 器 project 像 拿 了 绿 卡 一 路 run 到 底 把 项 目 奖 金 和 fake coder 全 扫 进 包 包 里 从 不 追 逐 金 钱 因 为 大 家 都 会 show me the money 不 会 过 多 犹 豫，代 码 就 像 killer shoot you body Github 上 又 多 了 几 颗 星 星，荣 誉 勋 章 记 录 总 不 停 堆 积 成 山 压 力 从 不 畏 惧 ，制 定 策 略 就 像 指 挥 沙 盘 游 戏 运 筹 帷 幄 将 代 码 握 在 手 里 ，因 为 我 是 coder 届 的 汤 姆 克 兰 西 没 有 天 分 我 需 要 更 加 努 力， 感 谢 你 来 我 场 地 看 到 这 里 照 顾 不 周 随 便 看 看 有 意 见 就 提，回 头 去 你 场 子 battle 乐 此 不 疲。","categories":[],"tags":[{"name":"说唱之路","slug":"说唱之路","permalink":"https://yemilice.com/tags/%E8%AF%B4%E5%94%B1%E4%B9%8B%E8%B7%AF/"}],"keywords":[]},{"title":"Python写一个自动点餐程序","slug":"Python写一个自动点餐程序","date":"2020-06-02T02:17:12.000Z","updated":"2020-07-07T08:20:12.479Z","comments":true,"path":"2020/06/02/Python写一个自动点餐程序/","link":"","permalink":"https://yemilice.com/2020/06/02/Python%E5%86%99%E4%B8%80%E4%B8%AA%E8%87%AA%E5%8A%A8%E7%82%B9%E9%A4%90%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"Python写一个自动点餐程序为什么要写这个公司现在用meican作为点餐渠道，每天规定的时间是早7：00-9：40点餐，有时候我经常容易忘记，或者是在地铁/公交上没办法点餐，所以总是没饭吃，只有去楼下711买点饭团之类的玩意儿，所以这是促使我写点餐小程序的原因。 点餐的流程登录 —&gt; 点餐 —&gt; 提交 哈哈，是不是很简单，其实这个还好，说白了，就是登录上去，然后拿到cookie，保持一个登录状态，然后再去点餐，点餐就是构造请求，发送到指定的点餐URL上就可以了。 登录首先我们点开 https://meican.com/ 上面要求我们登录，我们这里输入自己的账号密码，登录上去之后可以看见一个请求. 这个请求就是登录的请求，我们看下需要传什么参数，然后我们去完全构造这个请求，也就是参数一致，并且带浏览器头,这里我们也需要去保存cookie，也就是说，我们需要自己的账号时刻保持online状态，所以需要保存cookie，需要时候调用 所以我们需要实现如下功能 登录请求构造 保持登录状态 保存cookies 使得后来的访问都带cookie 代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import jsonimport requestsimport http.cookiejar as HCsession = requests.session()session.cookies = HC.LWPCookieJar(filename='cookies')def login_meican(): \"\"\" 登录美餐，寻找cookie文件，没cookie文件就重新载入 :return: \"\"\" # 储存cookie作为日后使用，三天clear一次 try: session.cookies.load(ignore_discard=True) except: print('未找到cookies文件') save_cookie()def save_cookie(): \"\"\" 如果没cookie，登录逻辑 :return: \"\"\" login_url = 'https://meican.com/account/directlogin' # Headers hearsers = &#123; \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36\", \"Referer\": \"https://meican.com/login\", \"Origin\": \"https://meican.com\", \"Host\": \"meican.com\", \"Accept\": \"*/*\" &#125; # Login need data data = &#123; \"username\": \"xxxxxxxxxxx\", \"loginType\": \"username\", \"password\": \"xxxxxxxxxxx\", \"remember\": \"true\" &#125; try: r = session.post(login_url, headers=hearsers, data=data) r.raise_for_status() session.cookies.save() except Exception as e: print(\"login error!\") return 0 上面的代码实现了登录。 点餐找到菜单这里需要找到菜单，因为截图忘了截，这里就直接公布吧，找到菜单需要两个参数，一个是uuid，另一个是addrid，也就是你登陆的凭证+你所在地区的id，没有这两个是无法找出菜单的，并且也无法继续点餐流程。 如何获得这两个参数在登录的时候我发现了一个URL，这个URL是 https://meican.com/preorder/api/v2.1/calendaritems/list?withOrderDetail=false&amp;beginDate=2019-09-04&amp;endDate=2019-09-04， 这个URL下的返回有我们要的参数，uuid 和 addrid，所以构造请求去获取这两个参数 123456789101112def get_for_my_order(): \"\"\" 找到usertorken, addrid :return: \"\"\" user_dict = &#123;&#125; Now_date = datetime.date.today() z = session.get(\"https://meican.com/preorder/api/v2.1/calendaritems/list?withOrderDetail=false&amp;beginDate=&#123;Now&#125;&amp;endDate=&#123;Now&#125;\".format(Now=Now_date)) x = json.loads(z.text) user_dict[\"uuid\"] = x[\"dateList\"][0][\"calendarItemList\"][0][\"userTab\"][\"uniqueId\"] user_dict[\"addrid\"] = x[\"dateList\"][0][\"calendarItemList\"][0][\"userTab\"][\"corp\"][\"addressList\"][0][\"uniqueId\"] return user_dict 构造获取菜单请求找到获取菜单的URL https://meican.com/preorder/api/v2.1/recommendations/dishes?tabUniqueId={uuid}&amp;targetTime={Now}+09:40 这里需要一个参数uuid，调取我们获取参数的函数 1234567891011121314151617def get_menu(): \"\"\" 获取餐单逻辑 :return: \"\"\" menu_dict = &#123;&#125; menu_list = [] Now_date = datetime.date.today() uuid = get_for_my_order()[\"uuid\"] z = session.get(\"https://meican.com/preorder/api/v2.1/recommendations/dishes?tabUniqueId=&#123;uuid&#125;&amp;targetTime=&#123;Now&#125;+09:40\".format(uuid = uuid, Now=Now_date)) menu = json.loads(z.text)[\"myRegularDishList\"] for i in menu: menu_dict[\"id\"] = i[\"id\"] menu_dict[\"name\"] = i[\"name\"] z = copy.deepcopy(menu_dict) menu_list.append(z) return menu_list 输出所有的菜单，以一个list作为输出 提交构造点餐请求首先先找到点餐的URL https://meican.com/preorder/api/v2.1/orders/add 查看点餐需要的参数： 12345678 data = &#123; \"corpAddressUniqueId\": addrid, \"order\": x, \"remarks\": y, \"tabUniqueId\": uuid, \"targetTime\":target_time, \"userAddressUniqueId\":addrid&#125; 构造点餐请求 123456789101112131415161718192021222324252627282930def order_action(): \"\"\" 点餐逻辑 :return: \"\"\" addrid = get_for_my_order()[\"addrid\"] uuid = get_for_my_order()[\"uuid\"] menu_list = get_menu() menu_id = choice(menu_list)[\"id\"] target_time = str(datetime.date.today()) + \" \" + \"09:40\" x = str([&#123;\"count\":1,\"dishId\":menu_id&#125;]) y = str([&#123;\"dishId\":menu_id,\"remark\":\"\"&#125;]) data = &#123; \"corpAddressUniqueId\": addrid, \"order\": x, \"remarks\": y, \"tabUniqueId\": uuid, \"targetTime\":target_time, \"userAddressUniqueId\":addrid &#125; headers = &#123; \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36\" &#125; try: z = session.post(\"https://meican.com/preorder/api/v2.1/orders/add\", headers=headers, data=data) z.raise_for_status() except: return \"点餐错误！\" 所用的知识点一览 Python requetst的post，session cookie的保存和调用 json的输出和浏览 random.choice 的列表元素随机选择 Python构造请求和登录逻辑","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang中Context使用的一点随想","slug":"Golang中Context使用的一点随想","date":"2020-06-01T02:18:36.000Z","updated":"2020-06-01T02:20:05.151Z","comments":true,"path":"2020/06/01/Golang中Context使用的一点随想/","link":"","permalink":"https://yemilice.com/2020/06/01/Golang%E4%B8%ADContext%E4%BD%BF%E7%94%A8%E7%9A%84%E4%B8%80%E7%82%B9%E9%9A%8F%E6%83%B3/","excerpt":"","text":"Golang中Context使用的一点随想前言这一篇是三巨头最后一篇了，前两篇介绍了channel，waitgroup，今天这篇来介绍一下context，相比于其他两种，我倒是更推荐context（上下文）这种控制goroutine的方法，为什呢，下面我就来详细的说一说吧。 什么是Context（逻辑上下文）Context是一种链式的调用逻辑，一般是用来控制goroutine，例如说，控制goroutine的启动，停止，暂停，取消等等。 我这里举一个简单的例子来说明Context怎么用 123456789101112131415161718192021222324252627282930313233//WorkDir 定义一个遍历目录逻辑，假设这个目录很大，但是咱们需要随时把它结束掉func WorkDir(ctx context.Context, name string) &#123; //假装这是一个大列表，很大很大那种 filePathList := []string&#123;........&#125; for _, file := range(filePathList) &#123; //假装这里处理一下目录, 打印一下目录 fmt.Println(file) select &#123; //检测到ctx发生了变化 case &lt;-ctx.Done(): fmt.Println(name,\"任务退出，骨灰都给你扬了\") return //否则什么都不做 default: &#125; &#125;&#125;func main() &#123; //定义一个waitcancel ctx, cancel := context.WithCancel(context.Background()) //将ctx作为参数传入函数当中 go WorkDir(ctx, \"三秒之内撒了你\") //让程序跑个几秒 time.Sleep(3 * time.Second) fmt.Println(\"该杀任务了\") //杀任务操作 cancel() //没有监控输出，就表示停止 time.Sleep(2 * time.Second) fmt.Println(\"任务让我杀了\")&#125; 怎么样，是不是很简单，简单来说，ctx就是传递的信号，你给每一层传递的ctx，不管传的再多，都只有一个爹 1ctx, cancel := context.WithCancel(context.Background()) cancel是来通知goroutine结束的，当爹ctx执行了cancel之后，就表示，我死了，你们得和我一起被株连，大家一起完蛋。 链式的意思就是，爹ctx是母体，它可以不断的继续下发产生多个子ctx，当cancel通知母体死亡的时候，子ctx也要跟着一起完蛋，所以链式就是，一荣俱荣，一关俱关的，cancel就是丧钟，调用就会释放所有的被感染（ctx下发）的goroutine。 Context的几个重要方法WithCancel方法WithCancel方法的接口 1func WithCancel(parent Context) (ctx Context, cancel CancelFunc) 这里会返回一个ctx和cancel，ctx是一个可以被拷贝的context，这个context可以作为父节点继续向下传递，cancel则是通知ctx退出的信号，调用CancelFunc的时候，关闭c.done()，直接退出goroutine。 举个简单的例子，算了我偷个懒，用上面的例子，ctrl c ctrl v一波 1234567891011121314151617181920212223242526272829303132//WorkDir 定义一个遍历目录逻辑，假设这个目录很大，但是咱们需要随时把它结束掉func WorkDir(ctx context.Context, name string) &#123; //假装这是一个大列表，很大很大那种 filePathList := []string&#123;........&#125; for _, file := range(filePathList) &#123; //假装这里处理一下目录, 打印一下目录 fmt.Println(file) select &#123; //检测到ctx发生了变化 case &lt;-ctx.Done(): fmt.Println(name,\"任务退出，骨灰都给你扬了\") return //否则什么都不做 default: &#125; &#125;&#125;func main() &#123; //定义一个waitcancel ctx, cancel := context.WithCancel(context.Background()) //将ctx作为参数传入函数当中 go WorkDir(ctx, \"三秒之内撒了你\") //让程序跑个几秒 time.Sleep(3 * time.Second) fmt.Println(\"该杀任务了\") //杀任务操作 cancel() //没有监控输出，就表示停止 time.Sleep(2 * time.Second) fmt.Println(\"任务让我杀了\")&#125; WithDeadline方法WithDeadline方法的接口 1func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) 这下机制出现了变化，cancel换成了deadline，参数也换了，换成了time，聪明的你应该想到了什么吧，这个函数其实是设置一个具体的死亡时间（deadline），当到达了指定的deadline时间之后，将所有的goroutine进行退出。咱们简单点儿，告诉你，就是到点儿退出。这里咱们照旧，举个例子，用例子来个详细说明。 123456789101112131415161718192021222324252627282930313233func WorkDir(ctx context.Context, name string) &#123; //假装这是一个大列表，很大很大那种 filePathList := []string&#123;........&#125; for _, file := range(filePathList) &#123; //假装这里处理一下目录, 打印一下目录 fmt.Println(file) select &#123; //检测到ctx发生了变化 case &lt;-ctx.Done(): fmt.Println(name,\"任务超时了，骨灰都给你扬了\") return case &lt;-time.After(1 * time.Second): fmt.Println(\"我还在......\") //否则什么都不做 default: &#125; &#125;&#125;func main() &#123; //定义一个WithDeadline，这里定义了一个具体的时间点 ctx, cancel := context.WithDeadline(context.Background(), time.Now().Add(10 * time.Second)) //将ctx作为参数传入函数当中 go WorkDir(ctx, \"从现在开始计时，10s之后撒了你\") //让程序跑个几秒 time.Sleep(3 * time.Second) fmt.Println(\"该杀任务了\") //杀任务操作 cancel() //没有监控输出，就表示停止 time.Sleep(2 * time.Second) fmt.Println(\"任务让我杀了\")&#125; 千万注意，后面还有个方法叫WithTimeout，它们两个说一样也不一样，WithTimeout是设置一个超时时间，WithDeadline是设定一个具体时间点，比如我上面那个，10s之内撒了goroutine，这个较为抽象，后面WithTimeout讲解的时候我会多费点功夫的。 WithTimeout方法WithTimeout方法的接口 1func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) 对比一下上面那个WithDeadline，看到没，都需要传入一个时间变量，但是还是那句话，上面的WithDeadline需要的是具体时间，下面的WithTimeout就简单多了，就需要一个时间就行了，说简单点，上面的WithDeadline，要的是一个具体时间，例如 “2020-01-01 12:00:00”， 1time.Now().Add(5*time.Second) 但是下面的WithTimeout，就很简单，就要一个超时时间就好了，例如5s 1timeout := 3 * time.Second 类似crontab的用法。好了，继续举个例子 123456789101112131415161718192021222324252627282930313233func WorkDir(ctx context.Context, name string) &#123; //假装这是一个大列表，很大很大那种 filePathList := []string&#123;........&#125; for _, file := range(filePathList) &#123; //假装这里处理一下目录, 打印一下目录 fmt.Println(file) select &#123; //检测到ctx发生了变化 case &lt;-ctx.Done(): fmt.Println(name,\"任务超时了，骨灰都给你扬了\") return case &lt;-time.After(1 * time.Second): fmt.Println(\"我还在......\") //否则什么都不做 default: &#125; &#125;&#125;func main() &#123; //定义一个WithDeadline，这里定义了一个具体的时间点 ctx, cancel:= context.WithTimeout(context.Background(), 5 * time.Second) //将ctx作为参数传入函数当中 go WorkDir(ctx, \"不管怎么样，没返回，5s之后撒了你\") //让程序跑个几秒 time.Sleep(20 * time.Second) fmt.Println(\"该杀任务了\") //杀任务操作 cancel() //没有监控输出，就表示停止 time.Sleep(2 * time.Second) fmt.Println(\"任务让我杀了\")&#125; 其实这两个用法都差不多，就是一个要求指定时间，一个随机时间，都是可以自己定义的. WithValue方法WithValue方法的接口 1func WithValue(parent Context, key interface&#123;&#125;, val interface&#123;&#125;) (Context) 这个看一下人家的传入，一个context，一个key, 一个接口interface，这明显就是一个key value类型的参数，这个方法的主要功能就是传递消息用，传递的元数据一般都是在子ctx中要使用到的，这个函数其实我用的不多，我参考了一下其他老哥的写法，总结了一下，具体的例子如下 1234567891011121314151617181920212223242526272829//定义一个keyvar key string = \"keywork\"func main() &#123; ctx, cancel := context.WithCancel(context.Background()) //附加值 valueCtx := context.WithValue(ctx, key, \"【监控1】\") go watch(valueCtx) time.Sleep(10 * time.Second) fmt.Println(\"可以了，通知监控停止\") cancel() //为了检测监控过是否停止，如果没有监控输出，就表示停止了 time.Sleep(5 * time.Second)&#125;func watch(ctx context.Context) &#123; for &#123; select &#123; case &lt;-ctx.Done(): //取出值 fmt.Println(ctx.Value(key), \"监控退出，停止了...\") return default: //取出值 fmt.Println(ctx.Value(key), \"goroutine监控中...\") time.Sleep(2 * time.Second) &#125; &#125;&#125; Context的使用注意事项 Context 始终要以参数的形式进行传递，整个结构体是不太行的，当然，利用map存储进行设计管理还是可以的。 Context 做参数你得永远把它放第一位，无论什么情况都切记 Context 可以在多个goroutine中进行传递，无需担心，它是线程安全的。 结尾两天终于把这个系列整完了，其实相当于自己复习了一下，也借鉴了一些别人的代码，value那个转手是在太多，我找不着原作者了，要是谁看到说是你写的，马上邮件我啊，我加上你的名字。 下一步我要开个大坑，我要用Golang 整个大活儿，爬虫之类的我都不想写了，我现在打算用Golang复写我的一些安全工具，或者是写一个Elasticsearch相关的东西，期待吧！","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang中WaitGroup使用的一点随想","slug":"Golang中WaitGroup使用的一点随想","date":"2020-05-26T05:29:11.000Z","updated":"2020-06-01T02:17:04.495Z","comments":true,"path":"2020/05/26/Golang中WaitGroup使用的一点随想/","link":"","permalink":"https://yemilice.com/2020/05/26/Golang%E4%B8%ADWaitGroup%E4%BD%BF%E7%94%A8%E7%9A%84%E4%B8%80%E7%82%B9%E9%9A%8F%E6%83%B3/","excerpt":"","text":"Golang中WaitGroup使用的一点随想前言（为什么又要写一篇随想文）上次我写了一个channel的文章，我寻思，这Golang控制三大巨头，channel，waitgroup，context，我得尽快都安排上，最近工作太忙，压力过大，但是Update Blog还是不能够停下来，所以继续补上，学习还是不能停，那么来吧。 WaitGroup的简单用法(等待组)你品一下人家这名字，等待组。等待什么，等待goroutine完成啊。有些时候，我们启动多个goroutine去执行任务，我举个例子 123456listip := []string&#123;\"10.0.9.11\",\"10.0.9.22\",\"10.0.9.33\"&#125;for _, ip := range(listip) &#123; //假设我们执行一个ping ip 的逻辑 go PingIPWork(ip)&#125; 我这里执行了一个多ip去ping的逻辑，一般这种时候，你要是执行一波，人家肯定毛都不会返回给你，为什么？因为人家主线程直接就退出了，还是那句话，你又没告诉人家主线程要等这ip全部都ping 完，所以你必须要加个等待，等着Goroutine完成，这里我再举一个网上的例子 123456789101112131415161718package mainimport ( \"fmt\")func main() &#123; go func() &#123; fmt.Println(\"Goroutine 1\") &#125;() go func() &#123; fmt.Println(\"Goroutine 2\") &#125;() //来个睡眠，等Goroutine结束 time.Sleep(time.Second * 1)&#125; 看到了么，加了一个sleep，用sleep去等着Goroutine跑完，上面我举的那个例子也可以这么来 12345678listip := []string&#123;\"10.0.9.11\",\"10.0.9.22\",\"10.0.9.33\"&#125;for _, ip := range(listip) &#123; //假设我们执行一个ping ip 的逻辑 go PingIPWork(ip)&#125;time.Sleep(time.Second * 1) 加个sleep可以等待完成，但是万一啊，Goroutine有的跑的快，有的慢，你那sleep就一秒，要是有的Goroutine没跑完不就白瞎了吗，所以咱们需要一个机制，这个机制可以帮助咱们去管理Goroutine，让我们知道Goroutine这东西什么时候停，什么时候完成。所以，WaitGroup这个东西，就可以帮助我们解决这个问题，还是老样子，我举一个简单的例子来说明我的想法。 1234567891011121314151617181920212223242526272829303132333435package mainimport ( \"fmt\" \"sync\")func PingIPWork(ip string) &#123; fmt.Println(ip)&#125;func main() &#123; //定义一个等待阿祖 var wg sync.WaitGroup wg.Add(3) // 因为有3个Ip，咱们定义三个动作，所以来三个计数 listip := []string&#123;\"10.0.9.11\",\"10.0.9.22\",\"10.0.9.33\"&#125; for _, ip := range(listip) &#123; //假设我们执行一个ping ip 的逻辑 go func(ip string) &#123; //执行一个work PingIPWork(ip) //操作完成之后，done一个计数，也就是3-1 wg.Done() &#125;(ip) &#125; //等待 wg.Wait() // 等待，直到计数为0&#125; 这里我举了一个简单的例子，其实wg的用法较为简单，在这个例子里面我们用到了 12345678wg.wait等待Goroutine结束之后退出主进程wg.Add添加Goroutine，其实你可以把它想成，可添加的最大Goroutine数wg.Done想象成销毁参数，当Goroutine结束之后调用，意思就是，你没了，我减1 WaitGroup的其他注意事项将Wg作为参数进行传递的时候，需要使用指针有些时候，咱们不想写的这么麻烦，就寻思怎么才能简单一点，或者可变性稍微强一点，有些时候我们要把wg最为参数，在函数内部调用，我们该怎么写呢？ 123456789101112131415161718192021222324252627282930package mainimport ( \"fmt\" \"sync\")func PingIPWork(ip string, wg *sync.WaitGroup) &#123; fmt.Println(ip) wg.Done()&#125;func main() &#123; var wg sync.WaitGroup wg.Add(3) // 因为有两个动作，所以增加2个计数 listip := []string&#123;\"10.0.9.11\",\"10.0.9.22\",\"10.0.9.33\"&#125; for _, ip := range(listip) &#123; //假设我们执行一个ping ip 的逻辑 go PingIPWork(ip, &amp;wg) &#125; wg.Wait() // 等待，直到计数为0&#125; 看到了么，如果你把Wg作为参数进行传递，你得要用指针的形式传值，否则就会死锁！！！！！！！！ Wg.Add的数值不能为负wg.Add()的数值必须为正数，如果为负数，将会抛出异常。 1234567panic: sync: negative WaitGroup countergoroutine 1 [running]:sync.(*WaitGroup).Add(0xc042008230, 0xffffffffffffff9c) D:/Go/src/sync/waitgroup.go:75 +0x1d0main.main() D:/code/go/src/test-src/2-Package/sync/waitgroup/main.go:10 +0x54","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang中Channel使用的一点随想","slug":"Golang中Channel使用的一点随想","date":"2020-05-25T10:25:38.000Z","updated":"2020-05-25T11:37:10.053Z","comments":true,"path":"2020/05/25/Golang中Channel使用的一点随想/","link":"","permalink":"https://yemilice.com/2020/05/25/Golang%E4%B8%ADChannel%E4%BD%BF%E7%94%A8%E7%9A%84%E4%B8%80%E7%82%B9%E9%9A%8F%E6%83%B3/","excerpt":"","text":"Golang中Channel使用的一点随想前言（为什么要写这篇文章）在Golang中，搞同步/并发控制的方法有很多，有channel(管道)，WaitGroup(等待线程结束)，context(上下文管理)，我一直想深入研究一下它们，因为这次开发我遇到了很多比较棘手的问题，我认为万变不离其宗，所以我看了一下他们的源码，然后简单的写了几个Demo，结合了我自己的开发经验，写成此文，做记录的同时，希望可以帮到其他兄弟，未来我还会出context随想，waitgroup随想，一点一点来吧。 什么是channel首先你要了解两个东西，一个是goroutine，一个是CSP(Communicating Sequential Processes) goroutine：Go协程，比线程小，内存占用小，Go的主打 CSP:一种模型，并发模型，说白了，就是依赖channel，认为信息的载体更加重要。这里相对来说比较复杂，请大家参考 http://www.usingcsp.com/cspbook.pdf 去学习一个。 那么channel到底是什么呢，其实就是一种在goroutine之间通用的通信方式，这么理解吧，军队每天都看到人守夜，每天都有不同的口号，比如哨兵a，哨兵b进行交接的时候，就要对暗号，我们理解一下，哨兵a,b是两个goroutine，那么口令就是channel，通过channel，我们可以控制哨兵下岗，上岗，巡逻，那么换算到goroutine中，我们就可以控制goroutine启动，停止，这就是channel的牛逼之处。 channel长什么样？（我们怎么定义channel）channel的定义方法非常简单，利用chan 关键字就可以 1test := make(chan bool) 这里的make，没有定义缓存值，channel可以定义一个缓存值，例如 1make(chan int, 100) 这里代表channel 的缓存大小为100，如果不设置缓存值，那么channel没有缓存，在没有通讯的情况下，将被阻塞。 是的，这个就定义好了，现在你就有一个名叫test的bool类型的channel，你可能会问，卧槽，这东西有什么用？行，我马上就举个例子告诉你这玩意儿怎么使。我知道你们大部分都不爱看理论，只爱看解决问题的模型，没问题，我惯你！ 来个channel的并发例子你细分析分析，一般你什么时候会用到goroutine间通信？那不就是一个不够使，多开几个，增加咱们program的效率嘛。是，你可以用 go example() 这种类型，开它十几二十个，但是你怎么知道他们结束了呢？估摸着你写sleep啊，就像 123456listip := []string&#123;\"10.0.9.11\",\"10.0.9.22\",\"10.0.9.33\"&#125;for _, ip := range(listip) &#123; //假设我们执行一个ping ip 的逻辑 go PingIPWork(ip)&#125;time.sleep(time.Second * 5) 这样其实没啥毛病，因为你不加那个sleep，人家估摸着就会一闪而过，你什么消息都收不到，我们这里有三个Ip，相当于你 go PingIPWork(ip)这里执行，外部的主程会直接退出去，人家才不管你搞完没呢，你又没和人家说是吧，所以channel就是干这个的，就是告诉主程，里面还有人呢嘿，别关门！ 123456789101112listip := []string&#123;\"10.0.9.11\",\"10.0.9.22\",\"10.0.9.33\"&#125;ch := make(chan struct&#123;&#125;)for _, ip := range listip &#123; go func(ip string) &#123; //假设执行一个ping ip的逻辑 go PingIPWork(ip) ch &lt;- struct&#123;&#125;&#123;&#125; &#125;(ip)&#125;for range ips &#123; &lt;-ch&#125; 这里去并发去执行PingIPWork，并且主程会等待所有goroutine完成之后才会彻底退出。发现了没，channel和goroutine一般都是放在一起的。 在for…i range中使用channel有时候我们需要阻塞range，或者是控制循环不退出，这时候就可以用到channel 12345678910111213listip := [\"10.0.9.11\",\"10.0.9.22\",\"10.0.9.33\"]//创建channelforever := make(chan bool)go func() &#123; for _, d := range msgs &#123; log.Printf(\"Received a message: %s\", d) &#125;&#125;()//阻塞，让它不退出&lt;-forever 在select中使用channel类似switch的骚操作，一般来说，你给人家整死循环了，你不得负责给人家搞退出，或者说满足必要条件退出 1234567891011121314151617// 创建 quit channelquit := make(chan string)// 启动生产者 goroutinec := boring(\"Joe\", quit)// 从生产者 channel 读取结果for i := rand.Intn(10); i &gt;= 0; i-- &#123; fmt.Println(&lt;-c) &#125;// 通过 quit channel 通知生产者停止生产quit &lt;- \"Bye!\"fmt.Printf(\"Joe says: %q\\n\", &lt;-quit)select &#123;case c &lt;- fmt.Sprintf(\"%s: %d\", msg, i): fmt.Println(\"work....\")case &lt;-quit: quit &lt;- \"See you!\" return&#125; 有些时候我们不想等那么久，所以我们需要（timeout）机制 1234567891011c1 := make(chan string, 1)go func() &#123; time.Sleep(time.Second * 2) c1 &lt;- \"result 1\"&#125;()select &#123;case res := &lt;-c1: fmt.Println(res)case &lt;-time.After(time.Second * 1): fmt.Println(\"timeout 1\")&#125; 关闭一个channel不用的东西要打包放好，否则你开一大堆channel在那里，搞一大堆panic: send on closed channel很吼么？ 随意关闭channel的姿势你也要学到，其实关闭的逻辑也很简单，关键字close 123c := make(chan int, 10)c &lt;- 1close(c) 这就关掉了，但是这样关不严谨，你还是能拿到c已经发出去的数据，而且还能不断的读到0值，所以一定要换个方法 1234c := make(chan int, 10)close(c)i, ok := &lt;-cfmt.Printf(\"%d, %t\", i, ok) 这样就能判断，当close时，读到的值是零值还是正常值，也就避免了上面出现的那种情况，一直读，一直有。 后记我感觉我学的还是不够深，我希望我的技术能更进一步，所以我还是要不断学习，我可以的，我会做到的。这里面其实都是些皮毛。。我感觉，我希望未来一定要多学多读多看。哈哈，这篇文章写完了我也要去吃饭了，今天我吃仔肺粉 + 锅盔，我去吃饭啦！有问题给我留言或者邮件吧！ 写于2020-05-25 19:36分","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"分布式数据库如何选择，几种分布式数据库优缺点一览","slug":"分布式数据库如何选择，几种分布式数据库优缺点一览","date":"2020-05-22T08:16:20.000Z","updated":"2020-05-22T08:29:46.945Z","comments":true,"path":"2020/05/22/分布式数据库如何选择，几种分布式数据库优缺点一览/","link":"","permalink":"https://yemilice.com/2020/05/22/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%EF%BC%8C%E5%87%A0%E7%A7%8D%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E7%BC%BA%E7%82%B9%E4%B8%80%E8%A7%88/","excerpt":"","text":"分布式数据库如何选择？几种分布式数据库优缺点一览为什么选择分布式数据库？优点如下： 具有灵活的体系结构 适应分布式的管理和控制机构 经济性能优越 系统的可靠性高、可用性好 局部应用的响应速度快 可扩展性好，易于集成现有系统。 相关的技术概念介绍什么是分布式数据库？常见的分布式系统分为， 支持持久化存储的分布式存储系统 着重计算的分布式计算框架 分布式消息队列 根据不同的应用的领域，把上述分类细化，常见分布式存储系统分为： 分布式协同系统（分布式日志复制） 分布式任务调度框架 流计算框架 分布式文件/对象系统 分布式NoSQL存储 分布式关系数据库（OLAP、OLTP）； 各种消息队列mq 不同的分布式数据库如何区分？ Key-value NoSQL : 例如Redis Riak等； column family NoSQL(wide column store) : 典型的是Hbase Cassandra document NoSQL : 典型的是mongodb 需要什么样的数据库? 支持数据持久化，数据落盘，异常备份，高并发，大数据量存储。 要支持频繁的数据读写 分布式，多节点并行 和以前的数据库不冲突 可选的方法及其特点 根据上述的要求，分布式数据库，符合大数据存储的，支持频繁读写的数据库有如下几个，它们的特点会简单说明。 Elasticsearch数据库Elasticsearch简介分布式的实时文件存储，每个字段都被索引并可被搜索，分布式的实时分析搜索引擎可以扩展到上百台服务器，处理PB级结构化或非结构化数据 Elasticsearch应用场景分布式的搜索引擎和数据分析引擎，全文检索，结构化检索，数据分析 对海量数据进行近实时的处理，站内搜索（电商，招聘，门户，等等），IT系统搜索（OA，CRM，ERP，等等），数据分析 Elasticsearch的优缺点缺点：没有用户验证和权限控制，没有事务的概念，不支持回滚，误删不能恢复，需要java环境. 优点：将你的文档分割到不同容器或者分片中，可以存在单个节点或多个节点复制每个分片提供数据备份，防止硬件问题导致数据丢失。 Elasticsearch的持久化方案gateway 代表 elasticsearch 索引的持久化存储方式，elasticsearch 默认是先把索引存放到内存中去，当内存满了的时候再持久化到硬盘里。当这个 elasticsearch 集群关闭或者再次重新启动时就会从 gateway 中读取索引数据。elasticsearch 支持多种类型的 gateway，有本地文件系统（默认），分布式文件系统，Hadoop 的 HDFS 和 amazon 的 s3 云存储服务。 ElasticSearch是先把索引的内容保存到内存之中，当内存不够时再把索引持久化到硬盘中，同时它还有一个队列，是在系统空闲时自动把索引写到硬盘中。 Redis数据库Redis简介redis是开源BSD许可高级的key-value存储系统(NoSQL)，可以用来存储字符串，哈希结构，链表，集合，因此，常用来提供数据结构服务，Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加 载进行使用。 支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。Redis支持数据的备份，即master-slave模式的数据备份。 Redis应用场景A）常规计数：粉丝数，微博数 B）用户信息变更 C）缓存处理，作为mysql的缓存 D）队列系统，建有优先级的队列系统，日志收集系统 Redis的优缺点优点(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) (2) 支持丰富数据类型，支持string，list，set，sorted set，hash (3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 (4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除 缺点（1）Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复 （2）主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性 （3）redis的主从复制采用全量复制，复制过程中主机会fork出一个子进程对内存做一份快照，并将子进程的内存快照保存为文件发送给从机，这一过程需要确保主机有足够多的空余内存。若快照文件较大，对集群的服务能力会产生较大的影响，而且复制过程是在从机新加入集群或者从机和主机网络断开重连时都会进行，也就是网络波动都会造成主机和从机间的一次全量的数据复制，这对实际的系统运营造成了不小的麻烦 （4）Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。 Redis的持久化方案redis提供两种方式进行持久化，一种是RDB持久化（原理是将Reids在内存中的数据库记录定时dump到磁盘上的RDB持久化），另外一种是AOF（append only file）持久化（原理是将Reids的操作日志以追加的方式写入文件）。 RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。 Mongodb数据库Mongodb简介MongoDB本身是一种非关系型数据库。它的每一条记录是一个Document，每个Document有一组键值对组成。MongoDB中的Document与JSON对象相似。 Document中字段的值可能包括其他Document，数组等。 Mongodb应用场景mongodb的主要目标是在键/值存储方式（提供了高性能和高度伸缩性）以及传统的RDBMS系统（丰富的功能）架起一座桥梁，集两者的优势于一身。mongo适用于以下场景： a.网站数据：mongo非常适合实时的插入，更新与查询，并具备网站实时数据存储所需的复制及高度伸缩性。 b.缓存：由于性能很高，mongo也适合作为信息基础设施的缓存层。在系统重启之后，由mongo搭建的持久化缓存可以避免下层的数据源过载。 c.大尺寸、低价值的数据：使用传统的关系数据库存储一些数据时可能会比较贵，在此之前，很多程序员往往会选择传统的文件进行存储。 d.高伸缩性的场景：mongo非常适合由数十或者数百台服务器组成的数据库。 e.用于对象及JSON数据的存储：mongo的BSON数据格式非常适合文档格式化的存储及查询。 Mongodb的优缺点优点： (1) 弱一致性（最终一致），更能保证用户的访问速度 (2) 文档结构的存储方式，能够更便捷的获取数据 (3) 内置GridFS，支持大容量的存储 (4) 在使用场合下，千万级别的文档对象，近10G的数据，对有索引的ID的查询不会比mysql慢，而对非索引字段的查询，则是全面胜出。 缺点： （1）不支持事物 （2）占用空间过大，会造成磁盘浪费 （3）单机可靠性比较差 （4）大数据量持续插入，写入性能有较大波动 Mongodb的持久化方案/异常处理当执行写操作时，MongoDB创建一个journal来包含确切磁盘位置和改变的字节。因此，如果服务器突然崩溃，启动时，journal会重放崩溃前并没有刷新到磁盘上的任何写操作。 数据文件每隔60s刷新到磁盘上，默认情况下，因此journal只需要持有60s内的写入数据。journal预分配了几个空文件用于此目的，位于/data/db/journal，命名为_j.0,j.1等等。 MongoDB运行很长时间情况下，在journal目录下，你会看到类似于_j.6217,_j.6218和_j.6219文件。这些文件是当前的journal文件，如果MongoDB一直运行，这些数字会持续增加。当正常关闭MongoDB时，这些文件将被清除，因为正常关机不在需要这些日志的。 如果服务器崩溃或kill -9, mongodb再次启动时，会重放journal文件，会输出冗长难懂的检验行，这表明在正常的恢复。 Mysql分布式集群Mysql分布式集群简介MySQL集群是一个无共享的(shared-nothing)、分布式节点架构的存储方案，其目的是提供容错性和高性能。 数据更新使用读已提交隔离级别（read-committedisolation)来保证所有节点数据的一致性，使用两阶段提交机制（two-phasedcommit)保证所有节点都有相同的数据(如果任何一个写操作失败，则更新失败）。 无共享的对等节点使得某台服务器上的更新操作在其他服务器上立即可见。传播更新使用一种复杂的通信机制，这一机制专用来提供跨网络的高吞吐量。 通过多个MySQL服务器分配负载，从而最大程序地达到高性能，通过在不同位置存储数据保证高可用性和冗余。 Mysql分布式集群应用场景解决海量存储问题，比如京东B2B就用的Mysql分布式集群。 适用几十亿的PV对DB的访问。 Mysql分布式集群的优缺点优点： a) 高可用性 b)快速的自动失效切换 c)灵活的分布式体系结构，没有单点故障 d)高吞吐量和低延迟 e)可扩展性强，支持在线扩容 缺点： a)存在很多限制，比如：不支持外键 b)部署、管理、配置很复杂 c)占用磁盘空间大，内存大 d)备份和恢复不方便 e)重启的时候，数据节点将数据load到内存需要很长时间 Mysql分布式集群的持久化方案负载均衡。 管理节点备份。","categories":[],"tags":[{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"keywords":[]},{"title":"开发中常用的Golang高级用法","slug":"开发中常用的Golang高级用法","date":"2020-05-22T06:37:09.000Z","updated":"2020-05-22T08:04:26.123Z","comments":true,"path":"2020/05/22/开发中常用的Golang高级用法/","link":"","permalink":"https://yemilice.com/2020/05/22/%E5%BC%80%E5%8F%91%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84Golang%E9%AB%98%E7%BA%A7%E7%94%A8%E6%B3%95/","excerpt":"","text":"开发中常用的Golang高级用法前言忙碌了两个月，这次开发终于要结束了，今天下午公司在重组集群机器，也没办法干活儿了，就写一些东西，相当于，留住一些东西，来纪念这辛苦的两个月吧。做一个纪念，也是为了方便以后自己去查看。在这次开发中，学习了不少Golang的高级特性，并且付诸于实现，也踩了不少坑，留下这篇文字，也是方便其他人能够查看，或者借鉴，如果帮到你，那么我也会很开心你。 开发常遇到的问题Golang判断一个元素在不在切片/列表当中在Python中，我们可以直接用 in 的方式去判断，例如 1if \"i\" in lists 但是在Golang中，没有这种语法糖或者是关键字可以帮助我们处理这种问题，所以还是只能靠循环去处理这种问题，为此我封装了一个Golang函数，函数如下 123456789//FindType 循环对比，匹配到返回true，不匹配返回falsefunc FindType(a string, typelist []string) bool &#123; for _, b := range typelist &#123; if b == a &#123; return true &#125; &#125; return false&#125; Golang获取文件的详细信息Golang获取文件信息的方法相对来说容易一些，都已经有了对应的package，我这里只是把怎么用展示出来 12345678910111213141516171819202122232425262728//timespecToTime 转换func timespecToTime(ts syscall.Timespec) time.Time &#123; return time.Unix(int64(ts.Sec), int64(ts.Nsec))&#125;//GetFileinfo 获取文件信息func GetFileinfo(path string) &#123; fileInfo, err := os.Stat(path) if err != nil &#123; return 0 &#125; //文件大小 filesize := fileInfo.Size() //文件创建时间 stat_ts := fileInfo.Sys().(*syscall.Stat_t) Ctime := timespecToTime(stat_ts.Ctim).Format(\"2006/01/02\") //文件修改时间 Mtime := timespecToTime(stat_ts.Mtim).Format(\"2006/01/02\") //文件访问时间 Attim := timespecToTime(stat_ts.Atim).Format(\"2006/01/02\") //获取文件所有者 stat_ts := fileInfo.Sys().(*syscall.Stat_t) uid := strconv.Itoa(int(stat_ts.Uid)) usrs, err := user.LookupId(string(uid)) username := usrs.Username //获取文件名 filename := fileInfo.Name()&#125; Golang比较两个list/切片的不同之处（差集）在开发中，我需要比较两个list，然后取出他们之中不同的部分，这里Golang也没有合适的法子，一般的方法就是转map进行处理 12345678910111213141516171819202122232425262728293031323334353637383940//difference 进行比对，输出不同的[]stringfunc difference(slice1, slice2 []string) []string &#123; m := make(map[string]int) nn := make([]string, 0) inter := intersect(slice1, slice2) for _, v := range inter &#123; m[v]++ &#125; for _, value := range slice1 &#123; times, _ := m[value] if times == 0 &#123; nn = append(nn, value) &#125; &#125; return nn&#125;//intersect 把两个对比的列表进行map化处理func intersect(slice1, slice2 []string) []string &#123; m := make(map[string]int) nn := make([]string, 0) for _, v := range slice1 &#123; m[v]++ &#125; for _, v := range slice2 &#123; times, _ := m[v] if times == 1 &#123; nn = append(nn, v) &#125; &#125; return nn&#125;func main() &#123; infinode := []string&#123;\"10.0.9.1\",\"10.0.9.2\"&#125; syncnodes := []string&#123;\"10.0.9.1\",\"10.0.9.2\", \"10.0.9.3\"&#125; ips := difference(infinode, syncnodes)&#125; Golang格式化时间golang 一般都可以通过Format的方法进行时间格式化，一般你可以直接调format，例如 1fmt.Println(time.Now().Format(\"2006-01-02 15:04:05\")) 有些时候是他娘的时间戳 1fmt.Println(time.Unix(1389028339, 0).Format(\"2006-01-02 15:04:05\")) 有些时候会让你搞成别的样子，比如”2006/01/02 15:04:05” 1fmt.Println(time.Now().Format(\"2006/01/02 15:04:05\")) 有些时候会让你比较个时间大小，例如 123456789101112//比对时间，看看它在不在开始时间/结束时间的范围内starttime := \"2020-05-12\"endtime := \"2020-05-20\"ctime := \"2020-05-15\"ft, err := time.Parse(\"2006-01-02\", ctime)st, err := time.Parse(\"2006-01-02\", starttime)et, err := time.Parse(\"2006-01-02\", endtime)if ft.After(et) &amp;&amp; ft.Before(st) &#123; fmt.Println(\"在里面儿！\")&#125; else &#123; fmt.Println(\"不在里面儿！\")&#125; Golang并发循环的使用我们处理循环的时候，在Python中，我举个例子 123lists = [1, 2, 3, 4]for i in lists: print i 这里打印的话是 12341234 Golang有个黑科技是并发循环，简单说，就是能一下给你把这四个都给你打印出来，不是一条条循环，也不用等上一个循环的结果返回，也可以选择略过错误。我在这里简单实现一个 直接并发循环（无需考虑错误）这里不考虑error的情况，具体代码如下 12345678910111213ips := []string&#123;\"10.0.9.1\",\"10.0.9.2\"&#125;ch := make(chan struct&#123;&#125;)//并发循环ipfor _, ip := range ips &#123; go func(ip string) &#123; //模拟一个展示ip fmt.Println(ip) ch &lt;- struct&#123;&#125;&#123;&#125; &#125;(ip)&#125;for range ips &#123; &lt;-ch&#125; 输出错误的并发循环(考虑错误)1234567891011121314ips := []string&#123;\"10.0.9.1\",\"10.0.9.2\"&#125;//定义一个errorerrors := make(chan error)for _, ip := range ips &#123; go func(ip string) &#123; _, err := test(ip) errors &lt;- err &#125;(ip)&#125;for range ips &#123; if err := &lt;-errors; err != nil &#123; return err &#125;&#125; Golang做一个不退出的无限循环有些时候我们希望一个服务/脚本/函数不断运行，或者每隔一段时间来一发（运行一次），这时候我们就需要定义无限循环 1234567func main() &#123; for &#123; //每隔1s打印一次start work time.Sleep(time.Second * 1) fmt.Println(\"Start work......\") &#125;&#125; Golang实现一个遇到错误的重试机制当我们最开发的时候，有些时候遇到错误，需要进行重试，这时候我们就需要进行错误捕获和函数重载 1234567891011121314151617181920212223//Retry 重试逻辑//传入函数，如果捕获到错误，则重载函数，重新来一次执行，直到没错误为止func Retry(fn func() error) error &#123; if err := fn(); err != nil &#123; if s, ok := err.(stop); ok &#123; return s.error &#125; return Retry(fn) &#125; return nil&#125;//TestWork 测试函数，无意义func TestWork() error &#123; //测试函数，这里是伪代码。 _, err := GetIpNode() if err != nil &#123; return err &#125; return nil&#125;func main() &#123; go Retry(TestWork)&#125; Golang执行Linux命令有些时候我们需要执行linux相关命令，Golang封装了相应的包，但是少部分时候我们需要控制一些很久不返回结果的命令，所以我加了一个超时时间，代码如下 1234567891011121314151617181920212223242526272829303132var ( //这里我写死了，你可以自己定义，更灵活一些 Timeout = 60 * time.Second)//Command 执行shellfunc Command(arg string) ([]byte, error) &#123; ctxt, cancel := context.WithTimeout(context.Background(), Timeout) defer cancel() cmd := exec.CommandContext(ctxt, \"/bin/bash\", \"-c\", arg) var buf bytes.Buffer cmd.Stdout = &amp;buf cmd.Stderr = &amp;buf if err := cmd.Start(); err != nil &#123; return buf.Bytes(), err &#125; if err := cmd.Wait(); err != nil &#123; return buf.Bytes(), err &#125; return buf.Bytes(), nil&#125;func main() &#123; _, err := Command(\"ls\") if err != nil &#123; fmt.Println(err) &#125;&#125; Golang 简单的日志逻辑这边贡献一个简单的日志实现代码，往文件里面写，可以自己定义格式，代码如下 1234567891011121314151617181920212223242526272829303132333435import ( \"fmt\" \"os\" \"github.com/op/go-logging\")func Monlog() (logs *logging.Logger) &#123; var log = logging.MustGetLogger(\"monlog\") //定义格式 时间 go文件 行数 等级 错误信息 var format = logging.MustStringFormatter( `%&#123;time:2006-01-02T15:04:05&#125; %&#123;shortfile&#125; %&#123;shortfunc&#125; %&#123;level&#125; %&#123;message&#125;`) //文件的写入位置 追加模式/没有自动创建 logFile, err := os.OpenFile(\"/var/log/monlog.log\", os.O_WRONLY|os.O_APPEND|os.O_CREATE, 0666) if err != nil &#123; panic(fmt.Sprintf(\"Open faile error!\")) &#125; //头相关, 具体意思就是支持追加，然后格式化，且按照那个格式往里面写 backend1 := logging.NewLogBackend(logFile, \"\", 0) backend2 := logging.NewLogBackend(os.Stderr, \"\", 0) backend2Formatter := logging.NewBackendFormatter(backend2, format) backend1Formatter := logging.NewBackendFormatter(backend1, format) backend1Leveled := logging.AddModuleLevel(backend1Formatter) backend1Leveled.SetLevel(logging.INFO, \"\") logging.SetBackend(backend1Leveled, backend2Formatter) return log&#125;func main() &#123; log := Monlog() log.Info(\"info\") log.Notice(\"notice\") log.Warning(\"warning\")&#125; Golang 使用 Aws-sdk 获取到指定bucket中全部的item我前阵子写过一篇文章，是Golang 调用 s3对象存储的，使用指定的api可以获取其中的item，但是人家限定100条，估摸着怕撑爆内存，但是如果我们想要获取到所有的item，这个该怎么做呢？其实循环获取就好了，但是我还是徒手实现一下吧，大家抄抄得了。 1234567891011121314151617181920212223242526func GetRgwItem3(buckets string) ([]*s3.Object, error) &#123; var items []*s3.Object sess, err := session.NewSession(&amp;aws.Config&#123; Credentials: credentials.NewStaticCredentials(ak, sk, \"\"), Endpoint: aws.String(endpoint + \":7480\"), Region: aws.String(\"us-east-1\"), DisableSSL: aws.Bool(true), S3ForcePathStyle: aws.Bool(false), //virtual-host style方式，不要修改 &#125;) if err != nil &#123; return nil, err &#125; svc := s3.New(sess) err := svc.ListObjectsPages(&amp;s3.ListObjectsInput&#123; Bucket: &amp;buckets, &#125;, func(p *s3.ListObjectsOutput, last bool) (shouldContinue bool) &#123; for _, obj := range p.Contents &#123; items = append(items, obj) &#125; return false &#125;) if err != nil &#123; return items, err &#125; return items, nil&#125; 我这里没毛病啊，万一你有问题你就咨询我 后记暂时先更这么多，这也不少了，大部分代码我都给出了具体实现，要是还不会就留言给我或者发邮件。 其实我特想对那些写几个爬虫在那里爬我博客的人说，你偷博客没所谓，复制也没所谓，不加名字说转载就很说不过去了，还TM标榜你是原创，脸呢？cnblog我会逐渐弃掉，因为我有我自己的博客了，我也在逐渐搞迁移，把我原来写的博客都迁移到我自己的博客上去，未来我的cnblog博客将逐渐少更或者停更，就算更我也会用英语/日语双更，我让你TM抄我东西不说，fuck off bitch。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang封装Elasticsearch常用功能","slug":"Golang封装Elasticsearch常用功能","date":"2020-05-14T01:45:49.000Z","updated":"2020-05-14T01:50:26.323Z","comments":true,"path":"2020/05/14/Golang封装Elasticsearch常用功能/","link":"","permalink":"https://yemilice.com/2020/05/14/Golang%E5%B0%81%E8%A3%85Elasticsearch%E5%B8%B8%E7%94%A8%E5%8A%9F%E8%83%BD/","excerpt":"","text":"前言（为什么要写这篇文章）首先看过我博客的都应该知道，我去年发了一篇Python封装Elasticsearch的文章。但那是去年了，今年我将我的检索服务后端用Golang全部重写了一波，相当于用Go重构了以前的Python代码，不过我个人感觉Golang的效率还是高于Python的，而且我还加了一些异常判断和处理，这次的代码只会比以前更好更牛逼，为了纪念这一个多月的重构历程，我将关键功能记录下来，方便自己复习和各位兄弟姐妹查看。 使用的Go包我的Elasticsearch版本是6.3.2，6系列了，现在（2020-05-13）最新版本应该是7，不过新版本和旧版本应该就是少了Type，我的6版本代码，请各位自己自行斟酌使用。安装指定的Go包 olivere/elastic，现在有官方驱动的包了，但是我这篇文章用的包是 olivere/elastic，所以一切的代码都是以olivere为主。 1go get github.com/olivere/elastic 基础的使用（Simple的使用）接下来我举几个例子来说下这个golang 如何驱动 elasticsearch的 连接Elasticserach1234567891011121314151617181920212223package elasticdbimport ( \"context\" \"fmt\" \"github.com/olivere/elastic\")func main() &#123; //连接127.0.0.1 client, err := elastic.NewClient(elastic.SetURL(\"http://127.0.0.1:9200\")) if err != nil &#123; fmt.Println(err) return &#125; //检查健康的状况，ping指定ip，不通报错 _, _, err = client.Ping(ip).Do(context.Background()) if err != nil &#123; fmt.Println(err) return &#125;&#125; 创建一个index索引这里我默认你们都有一定的Es基础，其实你把index想成Mysql里面的表就可以了。 123456789//indexname 你可以想成表名func CreateIndex(indexname string) &#123; client, err := elastic.NewClient(elastic.SetURL(\"http://127.0.0.1:9200\")) if err != nil &#123; fmt.Println(err) return &#125; client.CreateIndex(indexname).Do(context.Background())&#125; 删除一个index索引想成删除一张表 123456789//indexname 你可以想成表名func CreateIndex(indexname string) &#123; client, err := elastic.NewClient(elastic.SetURL(\"http://127.0.0.1:9200\")) if err != nil &#123; fmt.Println(err) return &#125; client.DeleteIndex(indexname).Do(context.Background())&#125; 往指定的index当中导一条数据想成往一张表里面导入一条数据，在Golang中，我们可以导入json的字符串，我们也可以导入golang的struct类型，例如 1234567//结构体type Task struct &#123; Taskid string `json:\"taskid\"` Taskname string `json:\"taskname\"`&#125;//字符串jsonmsg := `&#123;\"taskid\":\"123456\", \"taskname\":\"lwb\"&#125;` 1234567891011121314151617181920212223//导入数据，你需要index名，index的type，导入的数据func PutData(index string, typ string, bodyJSON interface&#123;&#125;) bool &#123; client, _ := elastic.NewClient(elastic.SetURL(\"http://127.0.0.1:9200\")) _, err := client.Index(). Index(index). Type(typ). BodyJson(bodyJSON). Do(context.Background()) if err != nil &#123; //验证是否导入成功 fmt.Sprintf(\"&lt;Put&gt; some error occurred when put. err:%s\", err.Error()) return false &#125; return true&#125;func main() &#123; //json字符串导入 jsonmsg = `&#123;\"taskid\":\"123456\", \"taskname\":\"hahah\"&#125;` status := PutData(\"test\", \"doc\", jsonmsg) //struct结构体导入 task := Task&#123;Taskid: \"123\", Taskname: \"hahah\"&#125; status := PutData(\"test\", \"doc\", task)&#125; 删除一条数据删除数据需要ID，这个ID是个啥玩意儿呢。。。就是咱们不是刚导了一条数据进去么，你可以设置这数据的唯一ID，也可以让Elasticsearch帮你自动生成一个，一般没事儿干谁自己设置啊，还容易重复，一重复就报错。。我在这里把这个删除的方法教给大家，记住这个ID一定是唯一的 12345678func DeleteData(index, typ, id string) &#123; client, _ := elastic.NewClient(elastic.SetURL(\"http://127.0.0.1:9200\")) _, err := client.Delete().Index(index).Type(typ).Id(id).Do(context.Background()) if err != nil &#123; fmt.Println(err) return &#125;&#125; 高阶使用（条件查询／封装等）简单讲了一下增删改，现在我们来讲一下高阶用法，高级增删改查吧，其实官方的文档讲的还算是比较清楚，不过我等大中华程序狗的姿势水平。。。至少我是图样图森破，看英文也算是废了九牛二虎之力，算是捋出来了一些高阶用法，顺手自己造了个轮子，现在我就来挑几点来说下吧。 自动选择可用的Es节点配合olivere的ping机制，可以做一个自动检测Es ip 是否可用的逻辑，这样可以增加我们put，updatge时候的稳定性 自动检测节点Elasticseach的IP是否可用olivere的Elasticserach sdk 限定了只能用一个ip，类似“http://127.0.0.1:9200”这样，我对原本的逻辑进行了一点改造，改成支持一个ip list，依次检测Es ip 是否可用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package elasticdbimport ( \"context\" \"fmt\" \"github.com/olivere/elastic\")//Elastic es的连接，type Elastic struct &#123; Client *elastic.Client host string&#125;//Connect 基础的连接代码func Connect(ip string) (*Elastic, error) &#123; //引入IP client, err := elastic.NewClient(elastic.SetURL(ip)) if err != nil &#123; return nil, err &#125; //Ping 的方式检查是否可用 _, _, err = client.Ping(ip).Do(context.Background()) if err != nil &#123; return nil, err &#125; //输出一个struct类型，可以被继承 es := &amp;Elastic&#123; Client: client, host: ip, &#125; return es, nil&#125;//InitES 初始化Es连接func InitES() (*Elastic, error) &#123; //host是一个列表 host := []string&#123;\"http://10.0.6.245:9200\",\"http://10.0.6.246:9200\",\"http://10.0.6.247:9200\"&#125; //统计host的数量 Eslistsnum := len(host) //如果为零就不继续接下来的逻辑 if Eslistsnum == 0 &#123; return nil, fmt.Errorf(\"Cluster Not Es Node\") &#125; //创建新的连接 for i, ip := range host &#123; //判断是不是最后一个节点ip if (Eslistsnum - 1) != i &#123; es, err := Connect(ip) //如果连接出错，则跳过 if err != nil &#123; fmt.Println(err) continue &#125; return es, nil //如果是最后一个节点 &#125; else &#123; es, err := Connect(ip) //输出错误 if err != nil &#123; return nil, err &#125; return es, nil &#125; &#125; return nil, nil&#125; 后续我们可以采用继承的方法调用Es的client的连接，这个在后面我就不详细说了，聪明的你，看代码一定能整明白，再整不明白，你就直接上Git拷贝我的代码就得了。 条件查询以前我写过一个Python的Elasticsearch Sdk，那里面的查询基本都用了query，简单来说，就是你，给Es的api发一个query，es给你返回一个查询结果。这里我会举几个常用的条件查询例子，然后用golang封装一波。这里我先定义一下数据结构，假设我们的Elasticsearch中，有一个叫做Task的index(索引)，其中存储着很多task的运行日志，它们的数据格式如下: 12345678&#123; \"taskid\": \"081c255b-936c-11ea-8001-000000000000\", \"starttime\": \"2020/05/13 18:38:21\", \"endtime\": \"2020/05/13 18:38:47\", \"name\": \"cifs01\", \"status\": 1, \"count\": 365&#125; 我们现在要做的就是围绕task这个index和其中的数据做条件查找的例子，我说的很明白了吧？开工了！ 查询时间范围/年龄大小的条件查询方法在业务需求中，我们经常会检索各种各样的数据，其中，范围查找应该是用的比较多的，所以我把它放到了最前面。 12345678910111213141516171819202122type Task struct &#123; TaskID string `json:\"taskid\"` StartTime string `json:\"starttime\"` EndTime string `json:\"endtime\"` Name string `json:\"name\"` Status int `json:\"status\"` Count int `json:\"count\"`&#125;//查找时间范围大于2020/05/13 18:38:21，并且小于2020/05/14 18:38:21的数据func (Es *Elastic) FindTime() &#123; var typ Task boolQ := elastic.NewBoolQuery() //生成查询语句，筛选starttime字段，查找大于2020/05/13 18:38:21，并且小于2020/05/14 18:38:21的数据 boolQ.Filter(elastic.NewRangeQuery(\"starttime\").Gte(\"2020/05/13 18:38:21\"), elastic.NewRangeQuery(\"starttime\").Lte(\"2020/05/14 18:38:21\")) res, _ := Es.Client.Search(\"task\").Type(\"doc\").Query(boolQ).Do(context.Background()) //从搜索结果中取数据的方法 for _, item := range res.Each(reflect.TypeOf(typ)) &#123; if t, ok := item.(Task); ok &#123; fmt.Println(t) &#125; &#125;&#125; 查询包含关键字的查询方法我们经常遇到那种，搜那么一两个字，让你展示所有包含这一两个字的结果，就像百度，你搜个”开发”，就能搜出来例如”软件开发”,”硬件开发”等。接下来咱们也实现一个这个功能 1234567891011121314//查找包含\"cifs\"的所有数据func (Es *Elastic) FindKeyword() &#123; //因为不确定cifs如何出现，可能是cifs01，也可能是01cifs，所以采用这种方法 keyword := \"cifs\" keys := fmt.Sprintf(\"name:*%s*\", keyword) boolQ.Filter(elastic.NewQueryStringQuery(keys)) res, _ := Es.Client.Search(\"task\").Type(\"doc\").Query(boolQ).Do(context.Background()) //从搜索结果中取数据的方法 for _, item := range res.Each(reflect.TypeOf(typ)) &#123; if t, ok := item.(Task); ok &#123; fmt.Println(t) &#125; &#125;&#125; 多条件查询如果说我们现在不仅仅需要找到符合时间的，也需要找到符合关键字的查询，那么就需要在查询条件上做文章。 12345678910111213func (Es *Elastic) FindAll() &#123; //因为不确定cifs如何出现，可能是cifs01，也可能是01cifs，所以采用这种方法 keyword := \"cifs\" keys := fmt.Sprintf(\"name:*%s*\", keyword) boolQ.Filter(elastic.NewRangeQuery(\"starttime\").Gte(\"2020/05/13 18:38:21\"), elastic.NewRangeQuery(\"starttime\").Lte(\"2020/05/14 18:38:21\"), elastic.NewQueryStringQuery(keys)) res, err := Es.Client.Search(\"task\").Type(\"doc\").Query(boolQ).Do(context.Background()) //从搜索结果中取数据的方法 for _, item := range res.Each(reflect.TypeOf(typ)) &#123; if t, ok := item.(Task); ok &#123; fmt.Println(t) &#125; &#125;&#125; 统计数量/多条件统计数量有些时候我们需要去统计符合查询条件的结果数量，做统计用，这里也有直接可用的Sdk 12345678910func (Es *Elastic) GetTaskLogCount() (int, error) &#123; boolQ := elastic.NewBoolQuery() boolQ.Filter(elastic.NewRangeQuery(\"starttime\").Gte(\"2020/05/13 18:38:21\"), elastic.NewRangeQuery(\"starttime\").Lte(\"2020/05/14 18:38:21\")) //统计count count, err := Es.Client.Count(\"task\").Type(\"doc\").Query(boolQ).Do(context.Background()) if err != nil &#123; return 0, nil &#125; return int(count), nil&#125; 总结我这边完成了几个查询/导入的基础功能，当然，我的代码大部分都放置在了github当中放置在: https://github.com/Alexanderklau/Go_poject/tree/master/Go-Elasticdb/Elasticsearch_sdk最近项目比较忙，我打算月中写一篇我开发的时候使用的一些Go特性，或者高级用法。如果喜欢的话麻烦Star我！最近压力颇大，想要换一个地方生活，所以也要准备离开了。如果大家有什么问题，可以直接给我提问，我看到了就会帮助大家的。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"这次绩效考评会成为压垮我的稻草么？","slug":"这次绩效考评会成为压垮我的稻草么？","date":"2020-04-14T02:06:30.000Z","updated":"2020-04-14T02:07:17.819Z","comments":true,"path":"2020/04/14/这次绩效考评会成为压垮我的稻草么？/","link":"","permalink":"https://yemilice.com/2020/04/14/%E8%BF%99%E6%AC%A1%E7%BB%A9%E6%95%88%E8%80%83%E8%AF%84%E4%BC%9A%E6%88%90%E4%B8%BA%E5%8E%8B%E5%9E%AE%E6%88%91%E7%9A%84%E7%A8%BB%E8%8D%89%E4%B9%88%EF%BC%9F/","excerpt":"","text":"写这篇文章的原因按理说，你们看过我博客的人，都知道，我是一个相当乐观的人，我从来都不会怎么丧气一些事儿，特别是在工作上，我永远都是顶在最前面，有困难bug我来，有难题我来攻关，按理说我就像是一个长者，身经百战，见的多了！那些naive的问题，我都不放在心上，可今天，恩，一个绩效考评，算是让我有了一些感到心累或者说是心寒吧。 发生了什么事儿说起来也是很尴尬，大家都知道，因为疫情，我整个二月和三月都在家办公，我那电脑没带回家，我用我家旧电脑和我舅舅的电脑，算是拼了个单片机，没图形界面那种，这是前提啊！本来我这边在开发一个比较大的项目，这项目，怎么说呢，用许嵩那句话就是 “作词作曲都是我自己”，咱不说别的，从策划，到架构涉及包括一些有的没的，都是我一个人搞定，那家伙，就差说我是CTO了哈哈，再一个，我作为整个项目组排头兵，第一个吃螃蟹涉足Golang开发，从一无所有，到文档齐备，就用了1月底，到2月底，这一个月时间，在家开发，日夜不眠不休，真正996，头发都给我掉了多少哈啊哈。这转折来了嘿，3月初，我有天正干活儿呢，你们知道，那开发机，一个人分好几台，我在我那几台开发机上正挥汗如雨呢，结果突然黑屏了，那一瞬间，我还傻x的拍了一下我电脑的后盖，我一寻思，不对啊，这不是电视，黑屏那就得是出事儿！果不其然，我把记录一发群里，才知道原来测试那边儿，有人在清理集群！一不小心把开发集群给清了！我勒个大擦！我寻思你这是灭霸啊，人灭霸打个响指，害得摆个造型。你这不声不响的，按个enter，就给我一个多月努力干没了，你可真是现代爆破专家啊你。这TM叫删库，你丫想跑路了吧！ 我当时的想法我当时脑子里先是一片空白，然后我脑子里一直弥漫着老八那句话，奥莉给！干他就完事儿了！是，我当时那个气啊，我就想给他丫干了，X的，小爷不说别的，以前也算是胡同口拍黑砖第一人啊！然后我的老大，紧急发来微信，问，你备份了吗？我说，没，那集群20多台机器呢，我在其中几台配了定时同步。我老大说，完了。我知道，我被删库了。 删库的损失不说别的，项目代码损失是最大的，2w行代码，一个月不眠不休的成果，完蛋了，等于这个月白干，是呗，是我倒霉么？人一倒霉，喝凉水都塞牙，给我气的。同时丢失的，还有Elasticsearch的work脚本，优化过后的ETCD封装代码，大部分文档，编译机的环境和包。 为什么不备份？首先开发集群有20多台机器，其中我的机器就用将近8台，8台机器啊老铁们，你会想到它们一瞬间都被干死么？好吧，我承认，我那个黑不溜秋的单片机linux只能处理一些逻辑问题，30G硬盘，安个Golang，python，jre都够呛了，害得跑个带gopls的Vim，备份？我这不寻思我过两天回去了备份么！ 绩效的定义写这个原因是，今儿（2020-4-13），考评下来，我老大找我谈话，说这次考评给了我C。也就是我绩效考核，3月份是C。我当时就疑惑了，删库的第一不是我，第二我不眠不休写的东西被人删了，我TM才是受害者！it‘s me！你给受害者考勤打C？我的项目都进测试部分了，你把开发机测试机一起干死了，当中是有我没备份的原因，但是你直接给我打C？？？我一打听，删库的人也是C，我勒个去，你这什么意思，删库的人和我都是C的评级？？那你是真的牛皮，感情我被删库我还成C了是吧！那你要追究责任，怎么不追究运维，为什么他会给删库的人那么大权限？让我背锅也太无耻了吧！ 结尾这次我感觉我有点寒心，是真的，我平常都写技术，很少写这种令人难过的玩意儿，但是我今天真的感觉心很累，也很寒心。看起来总是要人背锅，也就只有我了呗。呵呵。晚安了啊，如果哪位技术大佬或者是HR看到这篇文章，请不要误会，这只是我对这件事的一种寒心，我还是会继续输出高质量文章的。over","categories":[],"tags":[{"name":"杂七杂八","slug":"杂七杂八","permalink":"https://yemilice.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"}],"keywords":[]},{"title":"Golang调用Rabbitmq消息队列和封装","slug":"Golang调用Rabbitmq消息队列和封装","date":"2020-04-13T02:11:00.000Z","updated":"2020-04-13T02:19:34.927Z","comments":true,"path":"2020/04/13/Golang调用Rabbitmq消息队列和封装/","link":"","permalink":"https://yemilice.com/2020/04/13/Golang%E8%B0%83%E7%94%A8Rabbitmq%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%92%8C%E5%B0%81%E8%A3%85/","excerpt":"","text":"前言介绍RabbimqRabbitmq消息队列是干嘛的？简单的说，消息队列，引申一下就是传递消息用的队列，也可以称为传递消息的通信方法。用争抢订单的快车举个例子，假如，A用户发送了一个用车的消息，那么消息队列要做的就是把A用户用车的这个消息广而告之，发送到一个公用队列当中，司机只管取到消息，而不管是谁发布的，这就是一个简单的消息队列例子，Rabbitmq其实就是消息队列的一种，用的比较多的还可能有Redis，kafka，ActiceMq等等，这个后面的博文里面我会说，这次我们只说Rabbimq消息队列 Rabbitmq消息队列的好处是什么？为什么我们要用他？这个网上有很多类似的玩意，我不说太多，就只说我在使用中感觉比较好的地方。 分布式，多节点部署。一个集群，保证消息的持久化和高可用，某节点挂了，其他节点可以结力。 路由Exchange，这个已经提供了内部的几种实现方法，可以指定路由，也就是指定传递的地址。 多语言支持，我以前干活儿用Python，现在用Go和java，人家无缝对接，多牛逼！ Ack的消息确认机制，这样就保证了，任务下发时候的稳定性，ack消息确认可以手动，也可以自动，这样就保证了任务下发时候的可控和监控。 初步开始简单的生产者和消费者的模型讲那么多废话理论，还不如直接开始写代码更直观是吧，所以，奥莉给，干了兄弟们！我们实现一个简答的生产者，消费者模型。这个不用我多解释吧，基础的流程就是，我们定义一个生产者，生产信息到Rabbitmq中，然后再定义一个消费者，把数据从Rabbitmq中取出来，就这么简单，下面咱们就干了，先讲几个基础。 Rabbitmq的基础知识发送 Publish发送，你可以理解为上传，意思就是，上传一个消息到Rabbitmq当中。它这块的基础代码比较简单 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( \"log\" \"github.com/streadway/amqp\")func main() &#123; //初始化一个Rabbimtq连接，后跟ip，user，password conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") if err != nil &#123; return &#125; defer conn.Close() //创建一个channel的套接字连接 ch, _ := conn.Channel() //创建一个指定的队列 q, _ := ch.QueueDeclare( \"work\", // 队列名 false, // durable false, // 不使用删除？ false, // exclusive false, // 不必等待 nil, // arguments ) //定义上传的消息 body := \"work message\" //调用Publish上传消息1到指定的work队列当中 err = ch.Publish( \"\", // exchange \"work\", // 队列名 false, // mandatory false, // immediate amqp.Publishing &#123; ContentType: \"text/plain\", //[]byte化body Body: []byte(body), &#125;)&#125; 这样就完成了上传消息到work队列当中。 接收 Consume接收，顾名思义，就是接收到指定队列中的信息，信息存在队列当中，总要被拿出来用吧，放那里又不能下崽儿，所以，拿出来感觉用了才是最重要的。这块的基础代码如下 1234567891011121314151617181920212223242526272829303132333435363738package mainimport ( \"log\" \"github.com/streadway/amqp\")func main() &#123; //初始化一个Rabbimtq连接，后跟ip，user，password conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") if err != nil &#123; return &#125; defer conn.Close() //创建一个channel的套接字连接 ch, _ := conn.Channel() msgs, err := ch.Consume( \"work\" // 队列名 \"\", // consumer true, // auto-ack false, // exclusive false, // no-local false, // 不等待 nil, // args ) //定义一个forever，让他驻留在后台，等待消息，来了就消费 forever := make(chan bool) //执行一个go func 完成任务消费 go func() &#123; for d := range msgs &#123; //打印body log.Printf(\"message %s\", d.Body) &#125; &#125;() &lt;-forever&#125; 生产者／消费者模型上面简单说了一下rabbimq的发送和接收，这下咱们就要实现一个生产者消费者模型了，这个模型的主要逻辑，就是生产者发送任务到指定的队列，有一个，或者多个消费者，会在此留守，一有任务，就争抢并且消费。 生产者逻辑其实生产者逻辑和上面的发送逻辑差不多，这里给出写法。 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( \"log\" \"github.com/streadway/amqp\")func main() &#123; //初始化一个Rabbimtq连接，后跟ip，user，password conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") if err != nil &#123; return &#125; defer conn.Close() //创建一个channel的套接字连接 ch, _ := conn.Channel() //创建一个指定的队列 q, _ := ch.QueueDeclare( \"work\", // 队列名 false, // durable false, // 不使用删除？ false, // exclusive false, // 不必等待 nil, // arguments ) //定义上传的消息 body := \"work message\" //调用Publish上传消息1到指定的work队列当中 err = ch.Publish( \"\", // exchange \"work\", // 队列名 false, // mandatory false, // immediate amqp.Publishing &#123; ContentType: \"text/plain\", //[]byte化body Body: []byte(body), &#125;)&#125; 消费者逻辑消费者逻辑这边，主要是加了一个qos控制和手动ack，代码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package mainimport ( \"log\" \"github.com/streadway/amqp\")func main() &#123; //初始化一个Rabbimtq连接，后跟ip，user，password conn, err := amqp.Dial(\"amqp://guest:guest@localhost:5672/\") if err != nil &#123; return &#125; defer conn.Close() //创建一个channel的套接字连接 ch, _ := conn.Channel() //创建一个qos控制 err = ch.Qos( 3, // 同时最大消费数量（意思就是最多能消费几个任务） 0, // prefetch size false, // 全局设定？ ) if err != nil &#123; return err &#125; msgs, err := ch.Consume( \"work\" // 队列名 \"\", // consumer true, // auto-ack false, // exclusive false, // no-local false, // 不等待 nil, // args ) //定义一个forever，让他驻留在后台，等待消息，来了就消费 forever := make(chan bool) //执行一个go func 完成任务消费 go func() &#123; for d := range msgs &#123; //打印body log.Printf(\"message %s\", string(d.Body)) //手动ack，不管是否发送完毕。 d.Ack(false) &#125; &#125;() &lt;-forever&#125; Golang封装Rabbitmq的基础接口Rabbitmq会用了吧，上面那个估计比较简单，但是估摸着你们还想要别的功能，好，那我就惯大家一次，干了兄弟们，奥莉给！ 初始化Rabbitmq连接为了避免每次重复调用Rabbitmq连接，我这里提供一个简单写法。 1234567891011121314151617181920212223242526package mainimport (\"context\"\"fmt\"\"github.com/streadway/amqp\")//Rabbitmq 初始化rabbitmq连接type Rabbitmq struct &#123; conn *amqp.Connection err error&#125;func New(ip string) (*Rabbitmq, error) &#123; amqps := fmt.Sprintf(\"amqp://guest:guest@%s:5672/\", ip) conn, err := amqp.Dial(amqps) if err != nil &#123; return nil, err &#125; rabbitmq := &amp;Rabbitmq&#123; conn: conn, &#125; return rabbitmq, nil&#125; 创建一个Queue队列12345678910111213141516171819func (rabbitmq *Rabbitmq) CreateQueue(id string) error &#123; ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return err &#125; _, err = ch.QueueDeclare( id, // name true, // durable false, // delete when unused false, // exclusive false, // no-wait nil, // arguments ) if err != nil &#123; return err &#125; return nil&#125; 上传消息到指定的queue中123456789101112131415161718192021func (rabbitmq *Rabbitmq) PublishQueue(id string, body string) error &#123; ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return err &#125; err = ch.Publish( \"\", // exchange id, // routing key false, // mandatory false, amqp.Publishing&#123; DeliveryMode: amqp.Persistent, ContentType: \"text/plain\", Body: []byte(body), &#125;) if err != nil &#123; return err &#125; return nil&#125; 从队列中取出消息并且消费123456789101112131415161718192021func (rabbitmq *Rabbitmq) PublishQueue(id string, body string) error &#123; ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return err &#125; err = ch.Publish( \"\", // exchange id, // routing key false, // mandatory false, amqp.Publishing&#123; DeliveryMode: amqp.Persistent, ContentType: \"text/plain\", Body: []byte(body), &#125;) if err != nil &#123; return err &#125; return nil&#125; 统计队列中预备消费的数据12345678910111213func (rabbitmq *Rabbitmq) GetReadyCount(id string) (int, error) &#123; count := 0 ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return count, err &#125; state, err := ch.QueueInspect(id) if err != nil &#123; return count, err &#125; return state.Messages, nil &#125; 统计消费者／正在消费的数据12345678910111213func (rabbitmq *Rabbitmq) GetConsumCount(id string) (int, error) &#123; count := 0 ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return count, err &#125; state, err := ch.QueueInspect(id) if err != nil &#123; return count, err &#125; return state.Consumers, nil&#125; 清理队列123456789101112func (rabbitmq *Rabbitmq) ClearQueue(id string) (string, error) &#123; ch, err := rabbitmq.conn.Channel() defer ch.Close() if err != nil &#123; return \"\", err &#125; _, err = ch.QueuePurge(id, false) if err != nil &#123; return \"\", err &#125; return \"Clear queue success\", nil&#125; 总结简单讲了一下Rabbimtq是啥，怎么用，我是怎么用的。完整代码请访问我的Github： https://github.com/Alexanderklau/Go_poject/blob/master/Go-Rabbitmq/rabbitmq.go如果有不懂的欢迎留言！如果能帮大家的我一定会帮！也希望你们指出我的错误！一起进步！","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang 完成一个 Crontab定时器（2）","slug":"Golang-完成一个-Crontab定时器（2）","date":"2020-03-23T01:14:40.000Z","updated":"2020-03-23T01:15:19.158Z","comments":true,"path":"2020/03/23/Golang-完成一个-Crontab定时器（2）/","link":"","permalink":"https://yemilice.com/2020/03/23/Golang-%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AA-Crontab%E5%AE%9A%E6%97%B6%E5%99%A8%EF%BC%882%EF%BC%89/","excerpt":"","text":"前言上篇文章，大概讲了一下robfig/cron 包的使用，怎么开始一个定时任务，那个东西比较简单，也就是调用函数而已，人家都给你把包都封装好了。鉴于上一章我没提到cron相关，这一章专门我写个cron相关，讲讲怎么cron语法，然后再实现一个自动生成cron语句的逻辑。 需求分析 cron的基础科普 根据时间自动生成可用的cron语句 Cron表达式的基础Go的Cron和linux的Cron的区别就是，linux只到分钟，但是Go的Cron可以通过我上一节描述的代码设置精确到秒。所以一般的Cron表达式就是 1* * * * * * command 可以看出来，这是一个时间集合，但是其中每个 * 代表什么含义呢？下面给出Golang的cron设置表 字段 需要的值 字符表示 秒 0-59 * / , - 分 0-59 * / , - 时 0-23 * / , - 日 1-31 * / , - 月 1-12 * / , - 星期 0-6 * / , - 下面举几个cron的具体例子每秒执行一次任务 1* * * * * * Command 每分钟执行一次任务 1* *／1 * * * * Command 每天12点执行一次任务 1* 0 12 * * * Command 每个月1号12点执行一次任务 1* 0 12 1 * * Command 2月14号12点执行一次任务（执行一次） 10 0 12 14 2 * Command 每周二12点执行一次任务 1* 0 12 * * 1 Command Golang 实现一个Cron表达式自动生成器Cron这个东西，其实没那么难，但是你每次让我们徒手撸，还是会有点烦，特别是现在网上基本没有在线自动生成Cron语法的网站了，所以我们还是站撸一个Cron自动生成器，首先咱们要明确一个重要东西,任务可能是循环的，也可能是只执行一次的，看到了么，这下我们就要针对不同的任务类型，输出不同的任务表达式。 规定输入的时间格式首先输入的时间有多种多样，我们没办法控制输入的时间表达，所以我在这里先行规定，我的代码也是按照这个规定来的，前提在此。 循环执行的任务对于循环执行的任务，可能有每月，每周，每日，每时等等，所以我在这里举例 每月3号12点执行 1m,03,12:00 每周三的12点执行 1w,3,12:00 每天的12点执行 1d,12:00 观察一下，聪明的你应该知道我要做什么，拿每天循环执行来举例 12345timelists := strings.Split(times, \",\")hours := strings.Split(timelists[1], \":\")[0]minutes := strings.Split(timelists[1], \":\")[1]crontab := fmt.Sprintf(\"* %s %s * * *\", minutes, hours)fmt.Println(crontab) 结合其他部分 1234567891011121314151617181920212223timelists := strings.Split(times, \",\")// 在这里判断类型，天，月，周if timelists[0] == \"d\" &#123; hours := strings.Split(timelists[1], \":\")[0] minutes := strings.Split(timelists[1], \":\")[1] crontab := fmt.Sprintf(\"* %s %s * * *\", minutes, hours) return crontab&#125; else if timelists[0] == \"w\" &#123; days := strings.Split(timelists[1], \",\")[0] hours := strings.Split(strings.Split(timelists[2], \",\")[0], \":\")[0] minutes := strings.Split(strings.Split(timelists[2], \",\")[0], \":\")[1] crontab := fmt.Sprintf(\"* %s %s * * %s\", minutes, hours, days) return crontab&#125; else if timelists[0] == \"m\" &#123; days := strings.Split(timelists[1], \",\")[0] hours := strings.Split(strings.Split(timelists[2], \",\")[0], \":\")[0] minutes := strings.Split(strings.Split(timelists[2], \",\")[0], \":\")[1] crontab := fmt.Sprintf(\"* %s %s %s * *\", minutes, hours, days) return crontab&#125; else &#123; crontab := \"* * * * * *\" return crontab&#125; 执行一发看看,生成个每月的cron表达式 1* 0 12 03 * * Command 诶，怎么多了个03。。。看起来咱们需要格式化一下，把它转换一下成可用的。 1234567891011121314func FkZero(times string) (fmttime string) &#123; // 如果第一个值不为0，直接认为是正常的 if string(times[0]) != \"0\" &#123; return times // 判断00的情况 &#125; else if strings.Split(times, \"0\")[1] == \"\" &#123; fkzero := \"0\" return fkzero // 清理03，为 3 &#125; else &#123; fkzero := strings.Split(times, \"0\")[1] return fkzero &#125;&#125; 执行一次的任务执行一次的任务表达方式 2020-03-20 12:00处理代码如下 12345678timelists := strings.Split(times, \" \")[0]month := strings.Split(timelists, \"-\")[1]day := strings.Split(timelists, \"-\")[2]timework := strings.Split(times, \" \")[1]hours := strings.Split(timework, \":\")[0]minutes := strings.Split(timework, \":\")[1]crontab := fmt.Sprintf(\"0 %s %s %s %s *\", minutes, hours, day, month)return crontab 总结其实这个代码主要就是一个strings的split切分，但是涉及到了crontab语言的输出，其实没那么难，也就是麻烦，我把它传到github上了，有需要可以自己get下来。https://github.com/Alexanderklau/Go_poject/tree/master/Go-Script/crontab","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang 完成一个 Crontab定时器（1）","slug":"Golang-完成一个-Crontab定时器（1）","date":"2020-03-23T01:12:36.000Z","updated":"2020-03-23T01:13:34.795Z","comments":true,"path":"2020/03/23/Golang-完成一个-Crontab定时器（1）/","link":"","permalink":"https://yemilice.com/2020/03/23/Golang-%E5%AE%8C%E6%88%90%E4%B8%80%E4%B8%AA-Crontab%E5%AE%9A%E6%97%B6%E5%99%A8%EF%BC%881%EF%BC%89/","excerpt":"","text":"前言Linux的Crontab定时器似乎已经足够强大，但是我认为还是没有办法满足我们所有的需求，例如定时器某一瞬间需要动态添加／删除任务的功能，例如定时器只能在指定的节点上启动（主节点），其他节点不需要定时服务，这种情况Linux自带的Crontab就不能够满足我们的需求了，所以这次要徒手定义一个Crontab定时器，作为自己的备用。 需求分析看我博客的基本也都知道，做任何事，都要进行一个需求分析。既然是一个定时器，那么应该支持的功能如下 定时启动任务（废话） 支持基础的Crontab语法 支持将时间转换为Crontab语法 支持Crontab语法校验 记录日志的功能 支持crontab任务到秒级 综合上面的需求，不难看出，其实最重要的功能就是实现一个定时启动任务的玩意儿，在Go开发当中，也就是在某个时间点执行某个Go函数。说的简单点，就是，定时跑Go函数。也就是定时go func而已。 robfig/cron 包的使用安装robfig/cron包我这里默认你们都有go 基础,先安装个包，这玩意儿是驱动Golang 驱动 Crontab的重要框架。 1go get github.com/robfig/cron robfig/cron的使用举例启动一个定时任务其实很简单 123job := cron.New()job.AddFunc(\"* * * * *\", func() &#123;fmt.Println(\"Start job....\")&#125;)job.Start() 一个定时任务就这样被写好了，其实仔细琢磨一下，添加任务的方式就是 123456// 新任务job := cron.New()///任务添加job.AddFunc(\"Cronta 语句\", func() &#123;执行函数（）&#125;)//任务开始job.Start() 这样就完成了一个定时任务的添加 支持crontab任务到秒级估计你们看到这里一脸懵逼，为啥你个单独到秒级的也要整出来呢？其实我也表示，我也不想啊！奈何一点，robfig/cron这玩意有个很奇葩的一点，它只支持的分钟级别的任务，不支持到秒级别！！！！，它只支持的分钟级别的任务，不支持到秒级别！！！！，它只支持的分钟级别的任务，不支持到秒级别！！！！，重要的事儿说三遍！这里需要你自己定义秒级别的任务，在翻了一下它的test源码之后，拉到最底下，看到这么一行代码。 1234// newWithSeconds returns a Cron with the seconds field enabled.func newWithSeconds() *Cron &#123; return New(WithParser(secondParser), WithChain())&#125; 这行代码啥意思呢，意思就是启用返回seconds字段的任务，说白了就是，你要加这个，才能开启秒级别的任务网上好多博客写的，都是你抄我，我抄你，抄来抄去，没一个代码能用的，大家如果发现抄网上那帮人的代码，跑不起来，那绝对就是这个原因！人家只支持到分钟，网上给出的例子全都是秒级别的，并且没打开秒级别任务定义，还能跑起来？我都怀疑你们怎么写的代码。定义秒级别任务代码这段代码主要的意思就是，开放到秒级别的任务支持，看到了second么，这段代码在源码包的test下有，你们可以自己去看看。 1234567891011121314151617181920func newWithSeconds() *cron.Cron &#123; secondParser := cron.NewParser(cron.Second | cron.Minute | cron.Hour | cron.Dom | cron.Month | cron.DowOptional | cron.Descriptor) return cron.New(cron.WithParser(secondParser), cron.WithChain())&#125;func main() &#123; // 使用秒级别任务 job := newWithSeconds() // 任务定义,3s输出一个j1 start job,不停循环 job.AddFunc(\"0/3 * * * * ? \", func() &#123; fmt.Println(\"j1 start job....\", time.Now().Format(\"2020-03-20 15:04:05\")) &#125;) // 任务定义，每分钟的第三秒执行任务 job.AddFunc(\"3 * * * * ? \", func() &#123; fmt.Println(\"j2 start job....\", time.Now().Format(\"2020-03-20 15:04:05\")) &#125;) //开始任务 job.Start() select &#123;&#125;&#125; 输出的结果 1234j1 start job.... 2020-03-21 17:09:36j1 start job.... 2020-03-21 17:09:39j1 start job.... 2020-03-21 17:09:42j1 start job.... 2020-03-21 17:09:45 总结初步完成了crontab的基础功能，这篇文章默认，你们都比较懂crontab语法和go开发了，如果不懂就请期待下一篇，实现crontab语法自动生成和自动加载任务吧。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang利用context实现一个任务并发框架","slug":"Golang利用context实现一个任务并发框架","date":"2020-03-20T07:57:48.000Z","updated":"2020-05-19T08:28:05.669Z","comments":true,"path":"2020/03/20/Golang利用context实现一个任务并发框架/","link":"","permalink":"https://yemilice.com/2020/03/20/Golang%E5%88%A9%E7%94%A8context%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E4%BB%BB%E5%8A%A1%E5%B9%B6%E5%8F%91%E6%A1%86%E6%9E%B6/","excerpt":"","text":"Golang利用context实现一个任务并发框架消失这么久的原因疫情太严重，哥们本来打算在新疆滑雪+吃烤肉度过一个美好的假期，结果没成想给困那里了，这不就尴尬了么，这不，博客没更新，现在我又回来了，哈哈哈哈！ 我要实现个什么玩意儿有一个需求，简单的说就是我要写一个任务管理框架，主要功能有任务开启，任务关闭，任务监控等等。说的抽象点，就是我要用Golang写一个任务管理的功能，任务很可能有多个，并且我想停任务就停任务，想开始任务我就开始任务！我不要你觉得，我要我觉得！ 为什么我要用Golang众所周知，golang这东西，有个黑科技，叫goroutine，这东西很牛逼，牛逼在哪儿呢？简单的说，快，小，短！协程切换快，占用资源少，并且，异步的，可以开多个，直接一个go 关键字就给人家打开了，多棒！ 实际需求分析结合我们上面的任务需求，实现一个任务开始，任务停止的逻辑，这就说明，任务肯定不只有一个，并且任务都在后台，我们该怎么去监控，或者去管理这个go任务，或者go函数呢，golang提供了很多解决办法，例如WaitGroup，context等方法。思考一下，我们的这个需求，任务都是跑在后台的异步并发逻辑，这就说明不只一个任务会被启动和停止，这样对我们的任务管理是一个很大的挑战，因为任务都是在后台隐秘执行的，如果是一般逻辑，我们要停止任务，首先要找到任务的pid，然后kill任务进程，这是一个完整的结束任务的流程。回到我们这个需求，基本的流程就是： 发送一个任务请求(开启任务/停止任务) -&gt; 接收到任务请求 -&gt; 执行任务请求 思考一下，如果，我们开启任务之后，任务进入后台，那么，我们在停止任务的时候，怎么保证，能够找到这个任务，精准的打击（停止）它呢？看了题目你应该就知道了，用context就好了。下面我就来介绍一下它吧。 主角context介绍网上很多博客介绍它，我粗粗看了一眼，非常抽象，很多人再一描述，就更麻烦更抽象了。我这里不说的太麻烦，简单描述一下，这个东西context，是干嘛呢，你们理解一下株连，连坐这两个词汇，这个东西相当于就是锁链，铁锁连舟，不进则退，说明白点，就是一个串连上下文的类似信号传递的玩意儿。每个调用链上的函数都要以它作为函数进行传递，举个例子,”株九族”这个词，是因为一个人犯罪，结果家人都因为他被砍了头，这个犯罪的人，就是父context，其他因为他被杀的人，就是子context，还可能有孙context，他被砍头了，其他人也得跟着一起死，用代码表示一波 12345678910111213141516171819202122232425262728// 这是儿子函数func gen(ctx context.Context) &lt;-chan int &#123; dst := make(chan int) n := 1 go func() &#123; for &#123; select &#123; // 接收到爹挂了的消息 case &lt;-ctx.Done(): fmt.Println(\"儿子被砍头了。\") // 退出任务 return case dst &lt;- n: n++ time.Sleep(time.Second * 1) &#125; &#125; &#125;() return dst&#125;// 这是爹函数fun test() &#123; ctx, cancel := context.WithCancel(context.Background()) // 让我造个儿子，给我儿子传个ctx intChan := gen(ctx) // 我被干了，cancel是结束 defer Cancel()&#125; 这下说的明白了么？其实context还有很多别的，例如timeout之类的，但是那个是我后面准备写的，这一节就不写这些了。 实现我们的需求我们的武器context已经准备好了，大概的使用逻辑我们也明白了，现在你们可以看到，我们只要拿到主函数（爹函数）的ctx和cancel，我们就可以控制子函数（儿子函数）的死活，我们在开发当中，任务的状态是不断在变化的，一个爹对应一个儿子，但是可能有多个任务，多个任务我们该怎么管理它？在一般的开发任务中，我们习惯将任务记录到数据库当中，然后在开发当中不停的遍历数据库，去判断任务的状态到底是开启还是停止，这里我们要考虑到，频繁遍历数据库，会不会带来大量的访问堆积？还是否有别的解决办法？ 我的解决方案这次开发中，我选择定义一个全局变量的主map，并且定义一个任务的struct类型，代码如下 123456789// 全局mapvar jobmap = make(map[string]interface&#123;&#125;)//Job 任务type Jobs struct &#123; ID string Status int Ctx context.Context Cancel context.CancelFunc&#125; 然后我选择在任务开始的时候（创造儿子的时候），将信息填充，修改test代码如下 123456789101112131415161718192021func test() &#123; var jobs Jobs ctx, cancel := context.WithCancel(context.Background()) // 造一个儿子 intChan := gen(ctx) // 任务开始了 fmt.Println(\"start job\") // 重要的东西传进去 jobs.Status = 1 jobs.Cancel = cancel jobs.Ctx = ctx // 定义一个任务id，这个可以用uuid，或者随便整个别的 jobs.ID = \"sdads\" m1[\"sdads\"] = jobs // 阻塞任务，假装任务执行很久 for n := range intChan &#123; fmt.Println(n) if n == 1000 &#123; break &#125; &#125; 再然后，我选择写一个停止函数（砍头函数） 123456789func stopGetmi(id string) &#123; //把任务停掉 fmt.Println(\"stop jobs\") jobss := m1[id] //interface 转 struct op, ok := jobss.(Jobs) // 调用砍头函数cancel defer op.Cancel()&#125; 进行测试 12345func main() &#123; go test() go stopGetmi(\"sdads\") time.Sleep(time.Second * 200)&#125; 发现任务执行结果这样你就完成了干掉老爹，也干掉儿子的素质操作。 总结主要是context的基础和说明，其实context我还是推荐大家去看看原版，我这里写的太过于简单，不过这篇博客，也是我记录一下自己开发中遇到的难题，当时看网上没有类似的说明，于是写了这篇博客，希望大家多多包涵。祝大家都能躲过瘟疫，我们终究会在春花花开的地方相见。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"ETCD分布式锁实现选主机制(Golang)","slug":"ETCD分布式锁实现选主机制-Golang","date":"2019-12-13T07:41:04.000Z","updated":"2019-12-13T07:44:02.059Z","comments":true,"path":"2019/12/13/ETCD分布式锁实现选主机制-Golang/","link":"","permalink":"https://yemilice.com/2019/12/13/ETCD%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0%E9%80%89%E4%B8%BB%E6%9C%BA%E5%88%B6-Golang/","excerpt":"","text":"ETCD分布式锁实现选主机制(Golang)为什么要写这篇文章做架构的时候，涉及到系统的一个功能，有一个服务必须在指定的节点执行，并且需要有个节点来做任务分发，想了半天，那就搞个主节点做这事呗，所以就有了这篇文章的诞生，我把踩的坑和收获记录下来，方便未来查看和各位兄弟们参考。 选主机制是什么举个例子，分布式系统内，好几台机器，总得分个三六九等，发号施令的时候总得有个带头大哥站出来，告诉其他小弟我们今天要干嘛干嘛之类的，这个大哥就是master节点，master节点一般都是做信息处理分发，或者重要服务运行之类的。所以，选主机制就是，选一个master出来，这个master可用，并且可以顺利发消息给其他小弟，其他小弟也认为你是master，就可以了。 ETCD的分布式锁是什么首先认为一点，它是唯一的，全局的，一个key值为什么一定要强调这个唯一和全局呢，因为分布式锁就是指定只能让一个客户端访问这个key值，其他的没法访问，这样才能保证它的唯一性。再一个，认为分布式锁是一个限时的，会过期的的key值你创建了一个key，要保证访问它的客户端时刻online，类似一个“心跳”的机制，如果持有锁的客户端崩溃了，那么key值在过期后会被删除，其他的客户端也可以继续抢key，继续接力，实现高可用。 选主机制怎么设计其实主要的逻辑前面都说清楚了，我在这里叙述下我该怎么做。我们假设有三个节点，node1,node2,node3 三个节点都去创建一个全局的唯一key /dev/lock 谁先创建成功谁就是master主节点 其他节点持续待命继续获取，主节点继续续租key值（key值会过期） 持有key的节点down机，key值过期被删，其他节点创key成功，继续接力。ETCD分布式锁简单实现看一下ETCD的golang代码，还是给出了如何去实现一个分布式锁，这个比较简单，我先写一个简单的Demo说下几个接口的功能 创建锁123456789kv = clientv3.NewKV(client)txn = kv.Txn(context.TODO())txn.If(clientv3.Compare(clientv3.CreateRevision(\"/dev/lock\"),\"=\",0)).Then(clientv3.OpPut(\"/dev/lock\",\"占用\",clientv3.WithLease(leaseId))).Else(clientv3.OpGet(\"/dev/lock\"))txnResponse,err = txn.Commit()if err !=nil&#123; fmt.Println(err) return &#125; 判断是否抢到锁12345if txnResponse.Succeeded &#123; fmt.Println(\"抢到锁了\") &#125; else &#123; fmt.Println(\"没抢到锁\",txnResponse.Responses[0].GetResponseRange().Kvs[0].Value) &#125; 续租逻辑1234567891011for &#123; select &#123; case leaseKeepAliveResponse = &lt;-leaseKeepAliveChan: if leaseKeepAliveResponse != nil&#123; fmt.Println(\"续租成功,leaseID :\",leaseKeepAliveResponse.ID) &#125;else &#123; fmt.Println(\"续租失败\") &#125; &#125; time.Sleep(time.Second*1) &#125; 我的实现逻辑首先我的逻辑就是，大家一起抢，谁抢到谁就一直续，要是不续了就另外的老哥上，能者居之嘛！我上一下我的实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116package mainimport ( \"fmt\" \"context\" \"time\" //\"reflect\" \"go.etcd.io/etcd/clientv3\")var ( lease clientv3.Lease ctx context.Context cancelFunc context.CancelFunc leaseId clientv3.LeaseID leaseGrantResponse *clientv3.LeaseGrantResponse leaseKeepAliveChan &lt;-chan *clientv3.LeaseKeepAliveResponse leaseKeepAliveResponse *clientv3.LeaseKeepAliveResponse txn clientv3.Txn txnResponse *clientv3.TxnResponse kv clientv3.KV)type ETCD struct &#123; client *clientv3.Client cfg clientv3.Config err error&#125;// 创建ETCD连接服务func New(endpoints ...string) (*ETCD, error) &#123; cfg := clientv3.Config&#123; Endpoints: endpoints, DialTimeout: time.Second * 5, &#125; client, err := clientv3.New(cfg) if err != nil &#123; fmt.Println(\"连接ETCD失败\") return nil, err &#125; etcd := &amp;ETCD&#123; cfg: cfg, client: client, &#125; fmt.Println(\"连接ETCD成功\") return etcd, nil&#125;// 抢锁逻辑func (etcd *ETCD) Newleases_lock(ip string) (error) &#123; lease := clientv3.NewLease(etcd.client) leaseGrantResponse, err := lease.Grant(context.TODO(), 5) if err != nil &#123; fmt.Println(err) return err &#125; leaseId := leaseGrantResponse.ID ctx, cancelFunc := context.WithCancel(context.TODO()) defer cancelFunc() defer lease.Revoke(context.TODO(), leaseId) leaseKeepAliveChan, err := lease.KeepAlive(ctx, leaseId) if err != nil &#123; fmt.Println(err) return err &#125; // 初始化锁 kv := clientv3.NewKV(etcd.client) txn := kv.Txn(context.TODO()) txn.If(clientv3.Compare(clientv3.CreateRevision(\"/dev/lock\"), \"=\", 0)).Then( clientv3.OpPut(\"/dev/lock\", ip, clientv3.WithLease(leaseId))).Else( clientv3.OpGet(\"/dev/lock\")) txnResponse, err := txn.Commit() if err != nil &#123; fmt.Println(err) return err &#125; // 判断是否抢锁成功 if txnResponse.Succeeded &#123; fmt.Println(\"抢到锁了\") fmt.Println(\"选定主节点\", ip) // 续租节点 for &#123; select &#123; case leaseKeepAliveResponse = &lt;-leaseKeepAliveChan: if leaseKeepAliveResponse != nil &#123; fmt.Println(\"续租成功,leaseID :\", leaseKeepAliveResponse.ID) &#125; else &#123; fmt.Println(\"续租失败\") &#125; &#125; &#125; &#125; else &#123; // 继续回头去抢，不停请求 fmt.Println(\"没抢到锁\", txnResponse.Responses[0].GetResponseRange().Kvs[0].Value) fmt.Println(\"继续抢\") time.Sleep(time.Second * 1) &#125; return nil&#125;func main()&#123; // 连接ETCD etcd, err := New(\"xxxxxxxx:2379\") if err != nil &#123; fmt.Println(err) &#125; // 设定无限循环 for &#123; etcd.Newleases_lock(\"node1\") &#125;&#125; 总结相关代码写入到github当中，其中的地址是https://github.com/Alexanderklau/Go_poject/tree/master/Go-Etcd/lock_work实现这个功能废了不少功夫，好久没写go了，自己太菜了，如果有老哥发现问题请联系我，好改正。","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"算法笔记-入门-数据结构篇","slug":"算法笔记-入门-数据结构篇","date":"2019-11-13T03:26:18.000Z","updated":"2020-05-19T07:42:52.708Z","comments":true,"path":"2019/11/13/算法笔记-入门-数据结构篇/","link":"","permalink":"https://yemilice.com/2019/11/13/%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0-%E5%85%A5%E9%97%A8-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AF%87/","excerpt":"","text":"算法笔记-入门-数据结构篇从大学毕业之后就没研究过算法，都快忘光了，现在开个新坑，从头学起算法，哈哈，希望自己能够坚持住，不过我一定可以坚持住的，我就像易筋洗髓一样，将自己全身打断，重塑自己的一切，回归初心，以一个听者的名义对待一切，因为我做的都是我自己喜欢的事儿。 基本的数据结构类型什么是数据结构说白了很简单，数据存计算机里，总得有个存放规律，不能乱来，就像你查字典，你可以一页一页翻着找字儿，你也可以直接按拼音跳转找字儿，这就是查字典的数据结构，数据结构就是决定数据顺序和位置的关系。 数据结构的子类-链表链表，这玩意儿理解起来会抽象一些，大学课本上表示它的数据是一个线性排列的，要我说不用这么麻烦，链表其实就是一列火车，举例来说，现在有4节车厢，你必须通过一节车厢才能到下一节去，也就是说，车厢（链表）都有一个指示牌（指针），你必须一个个往下，到达下面的车厢（指向下一个地址）。链表这玩意儿吧，慢，查东西你得一个个往下，添加，删除数据都先要改变指针。查一个东西，拿大O表示法，它的复杂度是O(n)，算是相当慢的一种算法了。 数据结构的子类-数组数组，也是线性排列的数据结构，还记得链表么，链表是靠指针指向，告诉你我下一个老哥是谁，但是数组不一样，它是靠一个叫数组下标的东西来告诉你，我是第几个，在Python中，这玩意儿被运用在列表里，就像a = [1,2,3,4,5] 这种形式，a[0] = 1, a[1] = 2…….其实你想查一个数组里面的东西，一般都是随机访问，可以直接去访问数组下标，这东西就相当于你吃饭取的号儿，到你了，人家就喊“XXX号用餐了！”数组下标就这个功能。数组里面，你要添加或者删除一个元素，那可有点麻烦，你要先在数组尾部，加一个多的存储空间，总不可能让新元素没地方去吧，然后你要让旧元素给新朋友腾个位置，然后把旧朋友往后面赶，然后新朋友才能顺利插队。。。 数据结构的子类-栈栈这位老哥会理解麻烦一点，这么想，你随时随地都能吃到最新鲜的水果，每天都有新的水果，你总能拿到新水果，旧水果就只有在下面，所以你如果想吃旧水果，你就要把水果箱子一点点拿出来，被称为出栈，把水果放回去，叫进栈，这个东西就是你只能拿最新的，后进先出，LIFO结构，这玩意儿还是挺不方便的。不过在业务中，如果你需要时刻保持最新数据在前面，例如，时事热点，附近的人等等，拿这玩意儿就好用多了。 数据结构的子类-队列和上面的栈老哥相反，队列的意思就是，你先进来的啊，你边儿待着，该需要的时候要我旧数据先上，拿数据从最老的数据拿，新数据一边玩去。想拿新数据？不好意思，一个个出来吧你，直到该你出去为止。 数据结构的子类-哈希表这个在这说有点那啥，但是啊，你们写过Python的应该知到，Python里面有个dict（字典），字典这玩意儿就是一个key 对应 一个value，例如 1234&#123; &quot;蔡徐坤&quot; ：&quot;篮球&quot;， &quot;吴亦凡&quot; ：&quot;说唱&quot;&#125; 这就实现了一个字典，你会问，这和TM哈希表有啥关系，哈希表这玩意儿，是存dict的东西，它是个类数组的东西，但是存的东西很变态，一般我们会用hash函数，计算”蔡徐坤”的键,也就是”蔡徐坤”的哈希值，然后我们将得到的哈希值除以数组长度（哈希表长）取余数，计算出”蔡徐坤”在数组中的位置，然后把它放进去。这里比较抽象，后面会专门讲一下哈希这个算法。那么怎么查呢，首先我们拿到”蔡徐坤”的哈希值，然后通过刚才的计算就能找到”蔡徐坤”在哈希表中的位置了。 数据结构的子类-堆重头戏来了，这玩意儿是一个树形结构，树形，顾名思义，是分叉的，想象一下，一棵树的样子，这玩意儿是拿来搞优先队列用的，堆里面有个老大，叫结点，所有的数据都是结点的小弟，受他罩着，其中他有多个手下，叫子结点，子结点一般比父结点大，最小的值一般都在堆的顶点。堆中最顶端的数据始终最小，所以无论数据量有多少，取出最小值的时间复杂度都 为 O(1)。另外，因为取出数据后需要将最后的数据移到最顶端，然后一边比较它与子结点数据 的大小，一边往下移动，所以取出数据需要的运行时间和树的高度成正比。假设数据量为 n，根据堆的形状特点可知树的高度为 log2n ，那么重构树的时间复杂度便为 O(logn)。添加数据也一样。在堆的最后添加数据后，数据会一边比较它与父结点数据的大 小，一边往上移动，直到满足堆的条件为止，所以添加数据需要的运行时间与树的高度 成正比，也是 O(logn） 数据结构的子类-二叉查找树和楼上那位一样，也是个树形结构，不一样的是，二叉树每个结点的值大于左子树上任意一个结点的值，比较抽象对吧，来看个图意思就是，无论怎么样，左边老哥总会比我小。第二个分歧就是，右边老哥总比我大，继续看图这就是一部分基础，做了粗略写作，写得不好，见谅，over！","categories":[],"tags":[{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"},{"name":"算法","slug":"算法","permalink":"https://yemilice.com/tags/%E7%AE%97%E6%B3%95/"}],"keywords":[]},{"title":"Python高效率遍历文件夹寻找重复文件","slug":"Python高效率遍历文件夹寻找重复文件","date":"2019-10-28T04:31:15.000Z","updated":"2019-10-28T04:59:05.962Z","comments":true,"path":"2019/10/28/Python高效率遍历文件夹寻找重复文件/","link":"","permalink":"https://yemilice.com/2019/10/28/Python%E9%AB%98%E6%95%88%E7%8E%87%E9%81%8D%E5%8E%86%E6%96%87%E4%BB%B6%E5%A4%B9%E5%AF%BB%E6%89%BE%E9%87%8D%E5%A4%8D%E6%96%87%E4%BB%B6/","excerpt":"","text":"前言为什么要写这篇文章呢。。。主要还是业务中有个需求，遍历一个将近200w数据的文件夹，大部分还都是视频文件那种，但是这玩意用的次数还不多，做文件夹index也不是很ok，所以写了一个脚本来处理这个问题，从而发现了自己的一些薄弱点，将其记录下来，方便自己，也方便未来其他的兄弟使用 基本需求 把文件夹中的重复文件找出来 找出来之后用csv输出，左边是源文件，右边是重复文件 效率不能差，不能直接撑爆内存，不能占用过多资源 检测的文件夹和存放csv的地方可以自己定义，加上终端交互 重复文件筛选支持md5，大小等方式需求分析首先要分析一点，就是我们该如何去做重复文件的对比，并且效率还要高，首先网上过多的递归，os.walk的方法不可用，因为他们都会把遍历到的内容直接做成一个大列表，塞到内存里面，数据量大很容易爆掉，并且还要进行MD5，或者是大小比对，这个就非常难缠了。基础想法其实说白了，拿到所有文件列表file_list，把文件依次对比，这里我们可以用dict，分两种情况 按照文件名和大小设定两个dict，例如record和dup，遍历file_list,生成一个数组，比对其中的文件名和大小按照大小和MD5值设定两个dict，例如record和dup，遍历file_list,生成一个数组，比对其中的md5值和大小具体代码闲话休提，我们开始写代码吧定义遍历函数代码首先定义遍历文件夹的部分diskwalk.py 12345678910111213141516# coding: utf-8__author__ = \"lau.wenbo\"import os,sysclass diskwalk(object): def __init__(self, path): self.path = path def paths(self): path = self.path # 这里用了一个迭代器逻辑，防止所有数据塞内存爆掉 path_collection = (os.path.join(root,fn) for root,dirs,files in os.walk(path) for fn in files) return path_collection 定义检查md5值代码接着我们定义检查md5值的一个逻辑checksum.py 12345678910111213141516171819# coding: utf-8__author__ = \"lau.wenbo\"import hashlib,sys# 分块读MD，速度快def create_checksum(path): fp = open(path) checksum = hashlib.md5() while True: buffer = fp.read(8192) if not buffer: break checksum.update(buffer) fp.close() checksum = checksum.digest() return checksum 定义主函数代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# coding: utf-8__author__ = \"lau.wenbo\"from checksum import create_checksumfrom diskwalk import diskwalkfrom os.path import getsizeimport csvimport osimport sysreload(sys)sys.setdefaultencoding('utf8')def findDupes(path): record = &#123;&#125; dup = &#123;&#125; d = diskwalk(path) files = d.paths() for file in files: try: # 这里使用了大小，文件名的对比方式，如果你需要MD5值的对比方式，可以打开下面的注释 #compound_key = (getsize(file),create_checksum(file)) compound_key = (getsize(file), file.split(\"/\")[-1]) if compound_key in record: dup[file] = record[compound_key] else: record[compound_key]=file except: continue return dupif __name__ == '__main__': path = sys.argv[1] csv_path = sys.argv[2] if not os.path.isdir(path) or not os.path.isdir(csv_path) or csv_path[-1] != \"/\": print u\"参数不是一个有效的文件夹！\" exit() else: path = path.decode(\"utf-8\") print u\"待检测的文件夹为&#123;path&#125;\".format(path=path) with open(u\"&#123;csv_path&#125;重复文件.csv\".format(csv_path=csv_path),\"w+\") as csvfile: # 源文件 重复文件 header = [\"Source\", \"Duplicate\"] writer = csv.DictWriter(csvfile, fieldnames=header) writer.writeheader() print u\"开始遍历文件夹，寻找重复文件，请等待.........\" print u\"开始写入CSV文件，请等待........\" for file in findDupes(path).items(): writer.writerow(&#123;\"Source\":file[1],\"Duplicate\":file[0]&#125;) 结语实现了哪些功能呢，哈哈，结尾来说一下，其实核心就是我用了一个列表生成器，加了一个迭代器，迭代器可是好东西，不会撑内存，不错了，效率也还可以，200w数据判定也就20多分钟，支持大数据量，如果有什么不懂的，可以邮件联系我或者等待我的评论系统搞完，overgithub地址在这: https://github.com/Alexanderklau/Amusing_python/tree/master/File_operation/repeat","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"},{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"keywords":[]},{"title":"Elasticsearch for python API模块化封装","slug":"Elasticsearch-for-python-API模块化封装","date":"2019-10-25T01:57:50.000Z","updated":"2020-04-14T12:03:27.332Z","comments":true,"path":"2019/10/25/Elasticsearch-for-python-API模块化封装/","link":"","permalink":"https://yemilice.com/2019/10/25/Elasticsearch-for-python-API%E6%A8%A1%E5%9D%97%E5%8C%96%E5%B0%81%E8%A3%85/","excerpt":"","text":"Elasticsearch for python API模块化封装模块的具体功能 检测Elasticsearch节点是否畅通 查询Elasticsearch节点健康状态 查询包含的关键字的日志（展示前10条） 查询指定的索引下的数据，并且分页 输出所有日志(输出全部) 输出去重后的日志(分页，带关键字） 删除指定索引的值 往索引中添加数据 获取指定index、type、id对应的数据 更新指定index、type、id所对应的数据 批量插入数据 使用方法一般作为独立的包进行导入，并且对其进行了大数据预览的优化和处理作为一个独立Python模块进行导入，并且调取接口使用。调用方法 12import elasticdb.es_sysdb as esesdb = es.Es() 使用举例打印出索引（表）内的所有数据：需要index名，也就是指定索引名，在这里，假设我要查所有的monlog数据，那么查询语句如: 123a = esdb.search_all(client=esdb.conn, index=monlog, type=\"doc\")for i in a: c.append(i[\"_source\"][\"message\"]) 接口详情接口参数说明 参数 必选 类型 说明 index ture str 索引名 ，可认为是数据库 type true str 索引类型，可认为是表名 keywords ture str 关键字 page ture str 页数，分页逻辑 size ture str 每页展示条数，分页逻辑使用 查询包含的关键字的日志（展示前10条）123a = esdb.search_searchdoc(index=monlog, type=\"doc\", keywords=\"cpu\")for i in a: print i[\"_source\"][\"message\"] 查询指定的索引下的数据，并且分页示例：查询index为”oplog-2018-08,oplog-2018-12”，并且每页展示（size）5条，输出第二页（page） 12for i in esdb.serch_by_index(index=\"oplog-2018-08,oplog-2018-12\", page=2, size=5)[\"hits\"][\"hits\"]: print(i[\"_source\"][\"message\"]) 输出所有日志(输出全部)12for i in esdb.search_all(client=esdb.conn, index=\"monlog-*\", type=\"doc\"): print i 输出去重后的日志(分页，带关键字）示例：关键字为空，搜索monlog的所有数据，展示第一页，并且每页展示10条 12for i in esdb.serch_es_count(keywords = \"\", index=\"monlog-*\", type=\"doc\",page=1, size=10): print i 删除指定索引的值示例：删除monlog的所有值 1esdb.delete_all_index(index=\"monlog-*\", type=\"doc\") 查询集群健康状态1esdb.check_health() 往索引中添加数据12body = &#123;\"name\": 'lucy2', 'sex': 'female', 'age': 10&#125;print esdb.insertDocument(index='demo', type='test', body=body) 获取指定index、type、id对应的数据1print esdb.getDocById(index='demo', type='test', id='6gsqT2ABSm0tVgi2UWls') 更新指定index、type、id所对应的数据12body = &#123;\"doc\": &#123;\"name\": 'jackaaa'&#125;&#125;#修改部分字段print esdb.updateDocById('demo', 'test', 'z', body) 批量插入数据12345678910_index = 'demo'_type = 'test_df'import pandas as pdframe = pd.DataFrame(&#123;'name': ['tomaaa', 'tombbb', 'tomccc'], 'sex': ['male', 'famale', 'famale'], 'age': [3, 6, 9], 'address': [u'合肥', u'芜湖', u'安徽']&#125;)print esAction.insertDataFrame(_index, _type, frame) 代码示例1234567891011121314151617181920212223242526272829303132333435363738394041424344from elasticsearch import Elasticsearchfrom elasticsearch import helpersclass Es: def __init__(self): self.hosts = \"127.0.0.1\" self.conn = Elasticsearch(hosts=self.hosts, port=9200) def check(self): ''' 输出当前系统的ES信息 ''' return self.conn.info() def ping(self): return self.conn.ping() def check_health(self): ''' 检查集群的健康状态 :return: ''' status = self.conn.transport.perform_request('GET', '/_cluster/health', params=None)[\"status\"] return statuu def get_index(self): return self.conn.indices.get_alias(\"*\") def search_specify(self, index=None, type=None, keywords=None, page=None, size=None): # 查询包含的关键字的日志 query = &#123; 'query': &#123; 'match': &#123; 'message': keywords &#125; &#125;, 'from':page * size, 'size':size &#125; message = self.searchDoc(index, type, query) return message 完整的代码地址：https://github.com/Alexanderklau/elasticdb","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"Golang 调用 aws-sdk 操作 S3对象存储","slug":"Golang-调用-aws-sdk-操作-S3对象存储","date":"2019-10-25T01:55:52.000Z","updated":"2019-10-25T02:33:06.939Z","comments":true,"path":"2019/10/25/Golang-调用-aws-sdk-操作-S3对象存储/","link":"","permalink":"https://yemilice.com/2019/10/25/Golang-%E8%B0%83%E7%94%A8-aws-sdk-%E6%93%8D%E4%BD%9C-S3%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8/","excerpt":"","text":"Golang 调用 aws-sdk 操作 S3对象存储前言因为业务问题，要写一个S3对象存储管理代码，由于一直写Go，所以这次采用了Go，Go嘛，快，自带多线程，这种好处就不用多说了吧。 基础的功能 查看S3中包含的bucket bucket中的文件/文件夹 bucket的删除 bucket的创建 bucket的文件上传 bucket的文件下载 bucket的文件删除 aws-sdk 的安装玩Golang你还能不会那啥？对吧，那啥？那飞机！那飞机场，安上~ 1go get github.com/aws/aws-sdk-go aws-sdk-go 的基础使用构建基础的S3连接访问S3的时候，咱们需要access_key，secret_key，对象存储访问IP这三个参数，我们首先要创建一个aws的config，说白了，我们需要定义aws的配置，这样它才知道要怎么访问，去哪里访问等问题。构建一个S3连接代码如下 123456789101112131415161718192021222324package mainimport ( \"fmt\" \"os\" \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/credentials\" _ \"github.com/aws/aws-sdk-go/service/s3/s3manager\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/service/s3\")func main() &#123; access_key := \"xxxxxxxxxxxxx\" secret_key := \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\" end_point := \"http://xx.xx.xx.xx:7480\" //endpoint设置，不要动 sess, err := session.NewSession(&amp;aws.Config&#123; Credentials: credentials.NewStaticCredentials(access_key, secret_key, \"\"), Endpoint: aws.String(end_point), Region: aws.String(\"us-east-1\"), DisableSSL: aws.Bool(true), S3ForcePathStyle: aws.Bool(false), //virtual-host style方式，不要修改 &#125;)&#125; 这时候需要你自己去定义一下access_key，secret_key，end_point这三个参数接下来所有的代码，都是以这个连接模板，为核心，后面我就用同上代替配置，请注意！所有的代码都传到GIT上了，到时候会给出地址，不懂得copy下来吧！ 查看S3中包含的bucket查看所有的bucket 1234567891011121314151617181920212223242526272829303132package mainimport ( 导入包同上)func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 svc := s3.New(sess) result, err := svc.ListBuckets(nil) if err != nil &#123; exitErrorf(\"Unable to list buckets, %v\", err) &#125; fmt.Println(\"Buckets:\") for _, b := range result.Buckets &#123; fmt.Printf(\"* %s created on %s\\n\", aws.StringValue(b.Name), aws.TimeValue(b.CreationDate)) &#125; for _, b := range result.Buckets &#123; fmt.Printf(\"%s\\n\", aws.StringValue(b.Name)) &#125; &#125; 列出bucket中的文件/文件夹查看某个bucket中包含的文件/文件夹 1234567891011121314151617181920212223242526272829303132333435363738394041424344package mainimport ( \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/aws/credentials\" \"github.com/aws/aws-sdk-go/service/s3\" \"fmt\" \"os\")func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 // bucket后跟，go run ....go bucketname bucket := os.Args[1] fmt.Printf(bucket) fmt.Printf(\"\\n\") svc := s3.New(sess) params := &amp;s3.ListObjectsInput&#123; Bucket: aws.String(bucket), &#125; resp, err := svc.ListObjects(params) if err != nil &#123; exitErrorf(\"Unable to list items in bucket %q, %v\", bucket, err) &#125; for _, item := range resp.Contents &#123; fmt.Println(\"Name: \", *item.Key) fmt.Println(\"Last modified:\", *item.LastModified) fmt.Println(\"Size: \", *item.Size) fmt.Println(\"Storage class:\", *item.StorageClass) fmt.Println(\"\") &#125; &#125; bucket的创建创建bucket 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( 导包同上)func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 bucket := os.Args[1] if len(os.Args) != 2 &#123; exitErrorf(\"Bucket name required\\nUsage: %s bucket_name\", os.Args[0]) &#125; // Create S3 service client svc := s3.New(sess) params := &amp;s3.CreateBucketInput&#123; Bucket: aws.String(bucket), &#125; _, err = svc.CreateBucket(params) if err != nil &#123; exitErrorf(\"Unable to create bucket %q, %v\", bucket, err) &#125; // Wait until bucket is created before finishing fmt.Printf(\"Waiting for bucket %q to be created...\\n\", bucket) err = svc.WaitUntilBucketExists(&amp;s3.HeadBucketInput&#123; Bucket: aws.String(bucket), &#125;) if err != nil &#123; exitErrorf(\"Error occurred while waiting for bucket to be created, %v\", bucket) &#125; fmt.Printf(\"Bucket %q successfully created\\n\", bucket)&#125; bucket的文件上传往某个固定的bucket里传文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package mainimport ( \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/aws/credentials\" \"github.com/aws/aws-sdk-go/service/s3/s3manager\" \"fmt\" \"os\")func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 if len(os.Args) != 3 &#123; exitErrorf(\"bucket and file name required\\nUsage: %s bucket_name filename\", os.Args[0]) &#125; bucket := os.Args[1] filename := os.Args[2] file, err := os.Open(filename) if err != nil &#123; exitErrorf(\"Unable to open file %q, %v\", err) &#125; defer file.Close() uploader := s3manager.NewUploader(sess) _, err = uploader.Upload(&amp;s3manager.UploadInput&#123; Bucket: aws.String(bucket), Key: aws.String(filename), Body: file, &#125;) if err != nil &#123; // Print the error and exit. exitErrorf(\"Unable to upload %q to %q, %v\", filename, bucket, err) &#125; fmt.Printf(\"Successfully uploaded %q to %q\\n\", filename, bucket)&#125; bucket的文件下载下载某个bucket中的某个文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package mainimport ( \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/aws/credentials\" \"github.com/aws/aws-sdk-go/service/s3\" \"github.com/aws/aws-sdk-go/service/s3/s3manager\" \"fmt\" \"os\")func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 if len(os.Args) != 3 &#123; exitErrorf(\"Bucket and item names required\\nUsage: %s bucket_name item_name\", os.Args[0]) &#125; bucket := os.Args[1] item := os.Args[2] file, err := os.Create(item) if err != nil &#123; exitErrorf(\"Unable to open file %q, %v\", err) &#125; defer file.Close() downloader := s3manager.NewDownloader(sess) numBytes, err := downloader.Download(file, &amp;s3.GetObjectInput&#123; Bucket: aws.String(bucket), Key: aws.String(item), &#125;)if err != nil &#123; exitErrorf(\"Unable to download item %q, %v\", item, err)&#125;fmt.Println(\"Downloaded\", file.Name(), numBytes, \"bytes\")&#125; bucket的文件删除删除某个bucket里面的某个文件 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( \"github.com/aws/aws-sdk-go/aws\" \"github.com/aws/aws-sdk-go/aws/session\" \"github.com/aws/aws-sdk-go/aws/credentials\" \"github.com/aws/aws-sdk-go/service/s3\" \"fmt\" \"os\")func exitErrorf(msg string, args ...interface&#123;&#125;) &#123; fmt.Fprintf(os.Stderr, msg+\"\\n\", args...) os.Exit(1)&#125;func main() &#123; 配置同上 if len(os.Args) != 3 &#123; exitErrorf(\"Bucket and object name required\\nUsage: %s bucket_name object_name\", os.Args[0]) &#125; bucket := os.Args[1] obj := os.Args[2] svc := s3.New(sess) _, err = svc.DeleteObject(&amp;s3.DeleteObjectInput&#123;Bucket: aws.String(bucket), Key: aws.String(obj)&#125;) if err != nil &#123; exitErrorf(\"Unable to delete object %q from bucket %q, %v\", obj, bucket, err) &#125; err = svc.WaitUntilObjectNotExists(&amp;s3.HeadObjectInput&#123; Bucket: aws.String(bucket), Key: aws.String(obj), &#125;) fmt.Printf(\"Object %q successfully deleted\\n\", obj)&#125; 代码所在地https://github.com/Alexanderklau/Go_poject/tree/master/Go-Storage","categories":[],"tags":[{"name":"前后端","slug":"前后端","permalink":"https://yemilice.com/tags/%E5%89%8D%E5%90%8E%E7%AB%AF/"}],"keywords":[]},{"title":"程序员如何锻炼自己的产品思维","slug":"程序员如何锻炼自己的产品思维","date":"2019-10-25T01:46:55.000Z","updated":"2019-10-25T02:33:21.668Z","comments":true,"path":"2019/10/25/程序员如何锻炼自己的产品思维/","link":"","permalink":"https://yemilice.com/2019/10/25/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A6%82%E4%BD%95%E9%94%BB%E7%82%BC%E8%87%AA%E5%B7%B1%E7%9A%84%E4%BA%A7%E5%93%81%E6%80%9D%E7%BB%B4/","excerpt":"","text":"程序员如何锻炼自己的产品思维写作目的源于一次需求会议被怼，大老板总是说我以技术思维决定一切。后来我一思考，卧槽，果然是这样，每次我都是非常纠结于技术实现和技术细节，总是纠缠在业务实现里面，所以渐渐就养成了那个习惯。思考了一下，有些地方也的确是应该做出一点点改变了，老话说，种一棵树，最早是十年前，其次就是现在，那么我们就开始种树吧。趁着放假读几本产品思维的书，有一点点感悟，所以将此文写下，方便自己，也方便急于转型的各位程序员老哥。 个人技术背景1.菜逼一个，看博客就知道了。 2.掌握技术：后端： Python，Golang，Java移动端：OC（大学时候兼职IOS开发）前端：基础的React和Vue框架 3.算法技术：渣渣 4.没有任职过任何产品岗位 个人分析优点技术涉及面广，做项目多，一直在项目第一线，熟悉项目业务，思维活跃，善于解决和发现问题。 缺点算法能力差，前端能力差，抽象思维较弱，容易钻牛角尖，对项目整体了解不够透彻，只了解某些模块和部分。 什么是产品思维？理论上的产品思维1.把握关键点的能力 2.出方案，协调资源，说服团队把资源倾斜到关键点上的能力 3.评估关键点进展程度的能力 大白话解释1.首先用户就是一切，一切为了用户爽 2.反向思维，逆推解决问题 3.换位思考啊大哥，你不仅仅是产品人员，你还得是老板，用户，程序员balabala 4.脑子里对业务and产品都算是有了解（当然不能说像程序员一样） 其他来源对产品思维的解释1.从人性本质挖掘需求 说白了就是你要从人去思考问题，也就是说，你要人的表面挖掘到人的内心，类似挠痒痒，不能挠痒痒之后把皮整破了，这就是你满足了表面需求，但是破坏了底层需求2.从赚钱的角度思考 说白了就是追逐利益，想法儿怎么搞钱，例如扫码送东西，例如扫码给红旗，例如十一的时候给微信加国旗，这都是从逐利的思想去发觉需求3.沟通能力 我缺乏哪些技能？粗略看一下，其实缺乏的东西看起来很简单 对整体架构了解不多 逆向思维较差，不能从用户需求去理解问题，只单纯纠结能不能实现功能 评估项目和关键点能力不足 不能够和其他程序员有很好的沟通 平常和业务纠缠太多了，我这种Code monkey每天都去思考这个功能怎么实现，用什么技术更牛逼，怎么优化之类的，纠结技术，功能，细节等等。举个例子，我作为一个代码工程师工程师思维关注技术至上，技术水平代表实力，向于在产品中使用先进、流行的技术，因为掌握先进主流的技术可以提高他的身价。产品思维关注的是，这技术能给用户带来什么价值？有什么商业价值？所以我需要跳出这个怪圈，学会用产品的思维去思考问题，这样也能够开拓自己的眼界，无论是技术还是其他的路，都可以走的更远。 我该如何去补强这些技能？我理解的产品思维每一个项目都是产品。我们可以把工作当中的任何一个输出成果当做产品，用产品思维来完成这个成果。比如，我现在正在开发一个分布式的同步备份工程，将之称为产品。按照产品思维来策划这个工程，你要思考：我为什么要做这个产品？希望得到什么？用户是谁？谁在用这个？他们希望怎么去用？干系人有哪些？他们的期待是？使用场景：现有的web？还是独立开发APP？或者是普通的云计算服务？或者是普通存储服务？或者是类似同步服务？用户的关注点：怎么用？好操控么？用着舒服么？界面看着开心么？思考一下，产品思维的确和工程师思维不太一样，我也不能总是在工程师思维这个怪圈中徘徊 理论上的补强手段保持自己对于不同产品、不同领域的好奇心和敏感度很多时候我都忙于自己当下的工作，很难有机会接触到不同领域不同产品。很可能渐渐地就失去了对于产品的好奇心和敏感度，所以必须要让自己走出去，多去接触，或者看一看别人的产品or项目如何设计，思考他们是怎么做产品的？他们为什么这么做 ？如果我来做能怎样做？通过这样的思考和练习，来保持自己对产品的好奇心和敏感度 向上拓展自己的能力，不能停留于技术人员or产品经理一直纠缠与技术实现细节，总归是只有一层，如果满足这一层，也就是写代码的工具，或者是模块添加人员，也就没有办法建立起来自己的核心竞争力，笑傲江湖里面，剑宗气宗之争也是这一点，剑气双休才是最重要的。所以不仅仅是技术要抓，思想也要抓。 强化自己逻辑思维分析能力在逻辑思维方面，我想没有谁比得过程序员，程序员本来就是逻辑性很强的工作，这一点其实我认为更重要的是换位分析，易地而处的一种状态。我们往往分析自己的工作比较容易，但是涉及大局分析，就有些力不从心，这个我认为还是要针对性训练。 分解问题的能力其实这个在写代码的时候也经常预见到，不是么，一个大问题细化为好几个小问题，换算成产品思维也即是：1.产品有哪些功能？ 2.这些功能下面又分哪些模块？ 3.具体的应用场景在哪里？ 4.产品模块之间相互的联系是什么？ 5.谁在用这些产品？ 6.业务部门之间的需求是否互相耦合？是否已经存在重复需求？ 这里只是举个例子，具体问题具体分析，将自己想象成产品经理，先不要思考问题怎么解决，看看产品是怎么做的，再去对比思路思考解决问题。 用户行为分析能力什么是用户行为？关键就是用户用着你这个产品产生的行为，再去产生其他行为，这是用户增长和用产品化的重要组成部分。首先我们需要找出，关键用户行为，也就是，用户在使用产品时，是奔着你产品的什么方面来的，拿我正在做的项目举个例子，同步备份模块，干嘛的，同步备份文件的，特点呢？分布式，速度快，那不就完了！关键行为就是同步备份，这才是用户的关键行为。首先我们要考虑为什么会产生关键行为，也就输确定产品的价值，产品的价值就是用户愿不愿意给这个产品花钱，愿不愿意花钱去买我们的东西，解决痛点是第一位，但是在这之前，有没有类似的产品做了？人家做的好不好？谁的效率高？谁更牛逼？牛逼在哪？这才是要去分析的地方。 场景分析能力说白了，角色扮演，你把自己想象成一个用户，现在我想要一个产品，思考一下1.产品包含哪些场景 2.产品涉及哪些角色 3.场景会被第三方影响么？如果会，该如何去降低它？ 举个例子，同步备份的产品用在普通用户手中，普通用户的网很慢，同步时断时续，这就是第三方的缘故，但是我们的产品是单节点，也就是说只能一点点下，不能分布式，这就坑了，用户会觉得，你这怎么那么卡，你看看人迅雷，都能断点，都能分布式，你这个，get out，这就是第三方影响使用场景。再举个例子哈：朱啸虎先生在杭州的一次演讲中提到了维诺城。维诺城是在地铁口放置终端，用户出了地铁口之后可以在上面打印周围商家的优惠券。维诺城最初的生意非常好，因为地铁人流大，又是优惠券提供，在大众点评美团还没崛起的时候，它确实是很方便的产品。然而现在一方面因为美团这些APP的强势崛起，另一方面因为地铁提高了租金，更多的商家进场，甚至地铁公司本身都要来抢这个生意，维诺城的生意就下坡路了。 维诺城的例子说明什么？说明如果产品的主要场景容易受限于特殊的场地和时间特性，而这个场景进入的门槛比较低或是由第三方来控制，那么这个产品从场景上来说是有很高风险的；作为产品经理就要尝试思考有没有办法去降低这些影响，或是去发现自己产品不过度依赖这个场景的核心竞争力？ 数据分析能力数据这玩意，永远是支撑一个产品，或者是一个理论的重要依据。如何在通过数据去引导自己的产品思维 1、明确数据指标的定义、口径和使用场景。 要能清楚地和开发人员描述数据指标到底是什么，有哪些维度，在哪个页面或哪个场景之下发生； 2、层层剥离，穷举指标 产品经理为了保证数据的准确性，要尽可能地将指标拆解，拆解到不能拆解为止。同时也要分清哪些是核心指标，哪些是主要指标，哪些是次要指标； 3、数据指标和用户结合 新用户做了什么？老用户做了什么？付费用户做了什么？非付费用户又做了什么？流失用户在流失之前做了什么？要回答这些问题就要将数据指标和不同的用户结合起来分析","categories":[],"tags":[{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"keywords":[]},{"title":"新旧博客迁移的一点感悟","slug":"新旧博客迁移的一点感悟","date":"2019-10-24T09:50:37.000Z","updated":"2020-05-19T07:43:24.550Z","comments":true,"path":"2019/10/24/新旧博客迁移的一点感悟/","link":"","permalink":"https://yemilice.com/2019/10/24/%E6%96%B0%E6%97%A7%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E7%9A%84%E4%B8%80%E7%82%B9%E6%84%9F%E6%82%9F/","excerpt":"","text":"算是日记吧其实自己一直在cnblog上更新自己的博客，从16年3月入行到现在，已经过去了三个春秋，发觉自己的技术还是个渣渣，最近生活真的忙成一团，工作也很忙，生活也很忙，有时候饭都不容易吃上，感觉自己学习真的学不动了，不知道自己是不是懈怠了，运动，音乐什么的，也停下来了，感觉真的缺少了一点点乐趣。不过说真的，自己也真的该动起来了，因为时间不等人啊，已经入行这么久，跌跌撞撞像个摇摆人，所以未来我还是要多学习，多更新我的博客，将自己的技术或者是一些感悟，哪怕是一些灵光一闪的理想，都记录下来，哈哈，这样会不会好一些呢？会不会明天就是更好的那一天呢？ 算是自己我介绍吧渣渣一个，技术又全又杂，精通的少，各种都会一点，但是真正就是个渣渣，哈哈，现在孑然一生，18年年底被踹，重新出发，想想自己当时为了感情选择留在这个陌生的城市，现在已经爱上了这座城市，这座美丽的西南大都会。我想我会留下来的吧，我会留下来的？我也不确定吧，现在要慢慢出发，重新出发，我想我会越来越好的。 算是结尾吧可能你因为一些别的原因走到我博客来，其实欢迎你，欢迎你听一个24岁的家伙碎碎念那么久，未来大部分应该会更新技术，或者是我的一些奇特爱好，哈哈，希望你们会喜欢，我爱你们。","categories":[],"tags":[{"name":"其他技术","slug":"其他技术","permalink":"https://yemilice.com/tags/%E5%85%B6%E4%BB%96%E6%8A%80%E6%9C%AF/"}],"keywords":[]}]}